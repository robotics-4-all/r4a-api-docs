{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome! Welcome to R4A APIs! From here you can write applications that use a device's hardware, cloud services and generic functionalities. This is possible via the three distinct APIs (Robot, Cloud and Generic). Furthermore, you can write higher-level apps (FSM-like) using the TekNodes module. In this documentation you may find: Utilities: Various stuff, useful for writing applications. These are: Exceptions : How to capture exceptions from services/API calls. Messages : How to give input and take output from services/API calls. Memory : How to store and retrieve variables/data from device memory Conditions : How to create conditions that use variables or constants Enumerations : What variables and enumerations are available Robot API : Calls to manipulate Robots and Devices Cloud API : Calls to get information from cloud services Generic API : Generic functionality like delays etc. FSM-like applications : How to write applications using an FSM-like way Examples : Various examples Have a nice reading ;)","title":"Home"},{"location":"#welcome","text":"Welcome to R4A APIs! From here you can write applications that use a device's hardware, cloud services and generic functionalities. This is possible via the three distinct APIs (Robot, Cloud and Generic). Furthermore, you can write higher-level apps (FSM-like) using the TekNodes module. In this documentation you may find: Utilities: Various stuff, useful for writing applications. These are: Exceptions : How to capture exceptions from services/API calls. Messages : How to give input and take output from services/API calls. Memory : How to store and retrieve variables/data from device memory Conditions : How to create conditions that use variables or constants Enumerations : What variables and enumerations are available Robot API : Calls to manipulate Robots and Devices Cloud API : Calls to get information from cloud services Generic API : Generic functionality like delays etc. FSM-like applications : How to write applications using an FSM-like way Examples : Various examples Have a nice reading ;)","title":"Welcome!"},{"location":"buttons/","text":"Buttons API RobotAPI . getButtonChanges Gets button changes (pushes & releases) from memory. Input parameters An InputMessage , containing in data : deviceId : The id of a Devices.BUTTON device fromIndex : From what index the data will be retrieved toIndex : To what index the data will be retrieved Output An OutputMessage , containing in data : measurements: deviceId, timestamp, change","title":"Buttons API"},{"location":"buttons/#buttons-api","text":"","title":"Buttons API"},{"location":"buttons/#robotapigetbuttonchanges","text":"Gets button changes (pushes & releases) from memory.","title":"RobotAPI.getButtonChanges"},{"location":"buttons/#input-parameters","text":"An InputMessage , containing in data : deviceId : The id of a Devices.BUTTON device fromIndex : From what index the data will be retrieved toIndex : To what index the data will be retrieved","title":"Input parameters"},{"location":"buttons/#output","text":"An OutputMessage , containing in data : measurements: deviceId, timestamp, change","title":"Output"},{"location":"camera/","text":"Camera API RobotAPI . captureImage This call captures an image from the camera. Input arguments width : Desired width of captured image height : Desired height of captured image save_file_url : An absolute path for the image to be saved. If None , the image is not saved. Output / Variables The call returns an OutputMessage with the following data: deviceId : the id of the device, timestamp : the timestamp of the capture, image : the image as base 64 string, width : the width of the captured image, height : the height of the captured image, format : usually rgb , per_rows : True if stored by rows or by columns Examples import robot_api import utilities rapi = robot_api.RobotAPI() out = rapi.captureImage(utilities.InputMessage({ 'width': 800, 'height': 480, 'save_file_url': '/tmp/file.jpg' })) out.print() RobotAPI . getImages Retrieves images from memory. Input arguments fromIndex : The most recent index toIndex : The oldest index Output / Variables An OutputMessage as such: { 'measurements': [ { 'deviceId': ID, 'timestamp': 0, 'image': \"as base64 string format\", 'width': 0, 'height': 0, 'format': 'rgb', 'per_rows': True # If stored by rows or by columns }, ... ] } Examples import robot_api import utilities rapi = robot_api.RobotAPI() out = rapi.getImages(utilities.InputMessage({ 'fromIndex': 0, 'toIndex': 0 }))","title":"Camera API"},{"location":"camera/#camera-api","text":"","title":"Camera API"},{"location":"camera/#robotapicaptureimage","text":"This call captures an image from the camera.","title":"RobotAPI.captureImage"},{"location":"camera/#input-arguments","text":"width : Desired width of captured image height : Desired height of captured image save_file_url : An absolute path for the image to be saved. If None , the image is not saved.","title":"Input arguments"},{"location":"camera/#output-variables","text":"The call returns an OutputMessage with the following data: deviceId : the id of the device, timestamp : the timestamp of the capture, image : the image as base 64 string, width : the width of the captured image, height : the height of the captured image, format : usually rgb , per_rows : True if stored by rows or by columns","title":"Output / Variables"},{"location":"camera/#examples","text":"import robot_api import utilities rapi = robot_api.RobotAPI() out = rapi.captureImage(utilities.InputMessage({ 'width': 800, 'height': 480, 'save_file_url': '/tmp/file.jpg' })) out.print()","title":"Examples"},{"location":"camera/#robotapigetimages","text":"Retrieves images from memory.","title":"RobotAPI.getImages"},{"location":"camera/#input-arguments_1","text":"fromIndex : The most recent index toIndex : The oldest index","title":"Input arguments"},{"location":"camera/#output-variables_1","text":"An OutputMessage as such: { 'measurements': [ { 'deviceId': ID, 'timestamp': 0, 'image': \"as base64 string format\", 'width': 0, 'height': 0, 'format': 'rgb', 'per_rows': True # If stored by rows or by columns }, ... ] }","title":"Output / Variables"},{"location":"camera/#examples_1","text":"import robot_api import utilities rapi = robot_api.RobotAPI() out = rapi.getImages(utilities.InputMessage({ 'fromIndex': 0, 'toIndex': 0 }))","title":"Examples"},{"location":"cloud_age_detection/","text":"Age detection API CloudAPI . detectAgeFromImage Detects age using the camera. It captures an image, performs face detection and if a face is found it tries to detect its age. Input parameters An InputMessage , containing in data : file : The file path of the image Output The TekVariables affected are: TekVariables.AGE_DETECTION_DETECTED : Bool value denoting the detection success TekVariables.AGE_DETECTION : The age","title":"Age detection API"},{"location":"cloud_age_detection/#age-detection-api","text":"","title":"Age detection API"},{"location":"cloud_age_detection/#cloudapidetectagefromimage","text":"Detects age using the camera. It captures an image, performs face detection and if a face is found it tries to detect its age.","title":"CloudAPI.detectAgeFromImage"},{"location":"cloud_age_detection/#input-parameters","text":"An InputMessage , containing in data : file : The file path of the image","title":"Input parameters"},{"location":"cloud_age_detection/#output","text":"The TekVariables affected are: TekVariables.AGE_DETECTION_DETECTED : Bool value denoting the detection success TekVariables.AGE_DETECTION : The age","title":"Output"},{"location":"cloud_dominant_color/","text":"Dominant color detection API CloudAPI . detectDominantColor Captures an image and detects the dominant color in it. Input parameters An InputMessage , containing in data : file : The file path of the image Output The TekVariables affected are: TekVariables.DOMINANT_COLOR_RAW : The dominant color in raw form TekVariables.DOMINANT_COLOR : The dominant color in the form of Colors enum","title":"Dominant color API"},{"location":"cloud_dominant_color/#dominant-color-detection-api","text":"","title":"Dominant color detection API"},{"location":"cloud_dominant_color/#cloudapidetectdominantcolor","text":"Captures an image and detects the dominant color in it.","title":"CloudAPI.detectDominantColor"},{"location":"cloud_dominant_color/#input-parameters","text":"An InputMessage , containing in data : file : The file path of the image","title":"Input parameters"},{"location":"cloud_dominant_color/#output","text":"The TekVariables affected are: TekVariables.DOMINANT_COLOR_RAW : The dominant color in raw form TekVariables.DOMINANT_COLOR : The dominant color in the form of Colors enum","title":"Output"},{"location":"cloud_face_detection/","text":"Face detection API CloudAPI . detectFaceFromImage Detects human faces from camera. Input parameters An InputMessage , containing in data : file : The file path of the image Output The TekVariables affected are: TekVariables.DETECT_FACE_DETECTED : Bool value denoting the detection success TekVariables.DETECT_FACE_DETECTED_NFACES : The number of faces detected","title":"Face detection API"},{"location":"cloud_face_detection/#face-detection-api","text":"","title":"Face detection API"},{"location":"cloud_face_detection/#cloudapidetectfacefromimage","text":"Detects human faces from camera.","title":"CloudAPI.detectFaceFromImage"},{"location":"cloud_face_detection/#input-parameters","text":"An InputMessage , containing in data : file : The file path of the image","title":"Input parameters"},{"location":"cloud_face_detection/#output","text":"The TekVariables affected are: TekVariables.DETECT_FACE_DETECTED : Bool value denoting the detection success TekVariables.DETECT_FACE_DETECTED_NFACES : The number of faces detected","title":"Output"},{"location":"cloud_gender_detection/","text":"Gender detection API CloudAPI . detectSexFromImage Detects human gender from camera. Input parameters An InputMessage , containing in data : file : The file path of the image Output The TekVariables affected are: TekVariables.GENDER_DETECTION_DETECTED : Bool value denoting the detection success TekVariables.GENDER_DETECTION : The gender in the form of Sex enum","title":"Gender detection API"},{"location":"cloud_gender_detection/#gender-detection-api","text":"","title":"Gender detection API"},{"location":"cloud_gender_detection/#cloudapidetectsexfromimage","text":"Detects human gender from camera.","title":"CloudAPI.detectSexFromImage"},{"location":"cloud_gender_detection/#input-parameters","text":"An InputMessage , containing in data : file : The file path of the image","title":"Input parameters"},{"location":"cloud_gender_detection/#output","text":"The TekVariables affected are: TekVariables.GENDER_DETECTION_DETECTED : Bool value denoting the detection success TekVariables.GENDER_DETECTION : The gender in the form of Sex enum","title":"Output"},{"location":"cloud_language_detection/","text":"Language detection API CloudAPI . detectLanguage Detects the language from a given text or audio. Input parameters An InputMessage , containing in data : file : The file path of the text or audio Output The TekVariables affected are: TekVariables.LANGUAGE_DETECTION : The result of the detection","title":"Language detection API"},{"location":"cloud_language_detection/#language-detection-api","text":"","title":"Language detection API"},{"location":"cloud_language_detection/#cloudapidetectlanguage","text":"Detects the language from a given text or audio.","title":"CloudAPI.detectLanguage"},{"location":"cloud_language_detection/#input-parameters","text":"An InputMessage , containing in data : file : The file path of the text or audio","title":"Input parameters"},{"location":"cloud_language_detection/#output","text":"The TekVariables affected are: TekVariables.LANGUAGE_DETECTION : The result of the detection","title":"Output"},{"location":"cloud_motion_detection/","text":"Motion detection API CloudAPI . detectMotion Performs motion detection in a video file. Input parameters An InputMessage , containing in data : file : The file path of the video Output The TekVariables affected are: TekVariables.MOTION_DETECTION : Bool denoting the motion detection success","title":"Motion detection API"},{"location":"cloud_motion_detection/#motion-detection-api","text":"","title":"Motion detection API"},{"location":"cloud_motion_detection/#cloudapidetectmotion","text":"Performs motion detection in a video file.","title":"CloudAPI.detectMotion"},{"location":"cloud_motion_detection/#input-parameters","text":"An InputMessage , containing in data : file : The file path of the video","title":"Input parameters"},{"location":"cloud_motion_detection/#output","text":"The TekVariables affected are: TekVariables.MOTION_DETECTION : Bool denoting the motion detection success","title":"Output"},{"location":"cloud_ocr/","text":"OCR API CloudAPI . performOcr Performs OCR from camera Input parameters An InputMessage , containing in data : lang : Language in ISO639-1 standard file : The file path of the image Output The TekVariables affected are: TekVariables.OCR_DETECTION : The string result of OCR","title":"OCR API"},{"location":"cloud_ocr/#ocr-api","text":"","title":"OCR API"},{"location":"cloud_ocr/#cloudapiperformocr","text":"Performs OCR from camera","title":"CloudAPI.performOcr"},{"location":"cloud_ocr/#input-parameters","text":"An InputMessage , containing in data : lang : Language in ISO639-1 standard file : The file path of the image","title":"Input parameters"},{"location":"cloud_ocr/#output","text":"The TekVariables affected are: TekVariables.OCR_DETECTION : The string result of OCR","title":"Output"},{"location":"cloud_qr_barcode/","text":"QR/Barcode detection API CloudAPI . detectQr / CloudAPI . detectBarcode Detects QR codes / Barcodes from camera. Input parameters An InputMessage , containing in data : file : The file path of the image Output The TekVariables affected are: TekVariables.QR_DETECTION_DETECTED : Bool value denoting the detection success TekVariables.QR_DETECTION : The QR data TekVariables.BARCODE_DETECTION_DETECTED : The number of faces detected TekVariables.BARCODE_DETECTION : The Barcode data","title":"Cloud QR/Barcode API"},{"location":"cloud_qr_barcode/#qrbarcode-detection-api","text":"","title":"QR/Barcode detection API"},{"location":"cloud_qr_barcode/#cloudapidetectqr-cloudapidetectbarcode","text":"Detects QR codes / Barcodes from camera.","title":"CloudAPI.detectQr / CloudAPI.detectBarcode"},{"location":"cloud_qr_barcode/#input-parameters","text":"An InputMessage , containing in data : file : The file path of the image","title":"Input parameters"},{"location":"cloud_qr_barcode/#output","text":"The TekVariables affected are: TekVariables.QR_DETECTION_DETECTED : Bool value denoting the detection success TekVariables.QR_DETECTION : The QR data TekVariables.BARCODE_DETECTION_DETECTED : The number of faces detected TekVariables.BARCODE_DETECTION : The Barcode data","title":"Output"},{"location":"cloud_sentiment_detection/","text":"","title":"Sentiment detection API"},{"location":"cloud_sound_detection/","text":"Sound detection API CloudAPI . detectSound Performs sound detection from an audio file. Input parameters An InputMessage , containing in data : file : The file path of the sound Output The TekVariables affected are: TekVariables.DETECT_SOUND_DETECTED : Bool value denoting the detection result","title":"Sound detection API"},{"location":"cloud_sound_detection/#sound-detection-api","text":"","title":"Sound detection API"},{"location":"cloud_sound_detection/#cloudapidetectsound","text":"Performs sound detection from an audio file.","title":"CloudAPI.detectSound"},{"location":"cloud_sound_detection/#input-parameters","text":"An InputMessage , containing in data : file : The file path of the sound","title":"Input parameters"},{"location":"cloud_sound_detection/#output","text":"The TekVariables affected are: TekVariables.DETECT_SOUND_DETECTED : Bool value denoting the detection result","title":"Output"},{"location":"cloud_speech_to_text/","text":"Speech-2-text API CloudAPI . speechToText Performs automatic speech recognition in an audio file. Input parameters An InputMessage , containing in data : lang : The language of recognition file : The file path of the audio Output The TekVariables affected are: TekVariables.SPEECH_TO_TEXT : The string result of speech to text","title":"Speech-2-text API"},{"location":"cloud_speech_to_text/#speech-2-text-api","text":"","title":"Speech-2-text API"},{"location":"cloud_speech_to_text/#cloudapispeechtotext","text":"Performs automatic speech recognition in an audio file.","title":"CloudAPI.speechToText"},{"location":"cloud_speech_to_text/#input-parameters","text":"An InputMessage , containing in data : lang : The language of recognition file : The file path of the audio","title":"Input parameters"},{"location":"cloud_speech_to_text/#output","text":"The TekVariables affected are: TekVariables.SPEECH_TO_TEXT : The string result of speech to text","title":"Output"},{"location":"cloud_translate_from_audio/","text":"Translate audio API CloudAPI . translateAudio Translates the dictated text from a given audio. Input parameters An InputMessage , containing in data : file : The file path of the audio src : The source language in the form of Languages enum dest : The target language in the form of Languages enum Output The TekVariables affected are: TekVariables.TRANSLATE_AUDIO : The result of the translation","title":"Translate API"},{"location":"cloud_translate_from_audio/#translate-audio-api","text":"","title":"Translate audio API"},{"location":"cloud_translate_from_audio/#cloudapitranslateaudio","text":"Translates the dictated text from a given audio.","title":"CloudAPI.translateAudio"},{"location":"cloud_translate_from_audio/#input-parameters","text":"An InputMessage , containing in data : file : The file path of the audio src : The source language in the form of Languages enum dest : The target language in the form of Languages enum","title":"Input parameters"},{"location":"cloud_translate_from_audio/#output","text":"The TekVariables affected are: TekVariables.TRANSLATE_AUDIO : The result of the translation","title":"Output"},{"location":"cloud_weather/","text":"Weather report API CloudAPI . weatherReport Returns weather information for a specific area / country. Input parameters An InputMessage , containing in data : location : A location (e.g. a city) country_code : An ISO 3166 country code Output The TekVariables affected are: TekVariables.WEATHER_REPORT : The full weather report json TekVariables.WEATHER_REPORT_DESCRIPTION : A literal description TekVariables.WEATHER_REPORT_TEMPERATURE : The reported temperature TekVariables.WEATHER_REPORT_PRESSURE : The reported pressure TekVariables.WEATHER_REPORT_HUMIDITY : The reported humidity","title":"Weather API"},{"location":"cloud_weather/#weather-report-api","text":"","title":"Weather report API"},{"location":"cloud_weather/#cloudapiweatherreport","text":"Returns weather information for a specific area / country.","title":"CloudAPI.weatherReport"},{"location":"cloud_weather/#input-parameters","text":"An InputMessage , containing in data : location : A location (e.g. a city) country_code : An ISO 3166 country code","title":"Input parameters"},{"location":"cloud_weather/#output","text":"The TekVariables affected are: TekVariables.WEATHER_REPORT : The full weather report json TekVariables.WEATHER_REPORT_DESCRIPTION : A literal description TekVariables.WEATHER_REPORT_TEMPERATURE : The reported temperature TekVariables.WEATHER_REPORT_PRESSURE : The reported pressure TekVariables.WEATHER_REPORT_HUMIDITY : The reported humidity","title":"Output"},{"location":"cloudapi/","text":"The CloudAPI Cloud API offers cloud services / calls, with which you can add intelligence to your applications. As explained here , all calls get an InputMessage as input and an OutputMessage as output. The contents of this section are: Age detection Dominant color detection Face detection Gender detection Language detection Motion detection OCR Sound detection Speech-to-text Sentiment detection Translate Weather report QR/Barcode detection","title":"General"},{"location":"cloudapi/#the-cloudapi","text":"Cloud API offers cloud services / calls, with which you can add intelligence to your applications. As explained here , all calls get an InputMessage as input and an OutputMessage as output. The contents of this section are: Age detection Dominant color detection Face detection Gender detection Language detection Motion detection OCR Sound detection Speech-to-text Sentiment detection Translate Weather report QR/Barcode detection","title":"The CloudAPI"},{"location":"conditions/","text":"R4A Conditions In R4A APIs you can create conditions using two classes, Condition that denotes a single condition or ConditionGroup , denoting a composite condition. Let's see both of them in detail. The Condition class The Condition class implements a single condition. The constructor of the class is as follows: def __init__(self, left_operant = None, right_operant = None, operator = None, left_op_type = None, right_op_type = None, left_index = 0, right_index = 0) Let's discuss on each parameter: left_operant and right_operant are the two operants of the Condition. An operant can be either a constant value (number or string) a TekVariable or a counter variable. The specific type of each operant is declared via the left_op_type and right_op_type parameters, which must be of type OperantTypes enum . The possible items are: OperantTypes.CONSTANT OperantTypes.TEK_VARIABLE OperantTypes.COUNTER In case of the OperantTypes.COUNTER , the left/right_operant must be assigned the name of the counter. The operator parameter declares the logical operator and is of type RelationalOperators enum , with items: RelationalOperators.EQUAL RelationalOperators.SMALLER RelationalOperators.SMALLER_EQUAL RelationalOperators.LARGER RelationalOperators.LARGER_EQUAL RelationalOperators.NOT_EQUAL Finally, left/right_index parameters are used when an operant is of type OperantTypes.TEK_VARIABLE , specifying the index of the value that is going to be retrieved from memory (0 is the latest, -1 the previous etc.) Each condition is checked, using the check() method, returning either True or False. Some examples are: # Counter == 4 condition_cg62 = Condition ( left_operant = \"Counter\", left_op_type = OperantTypes.COUNTER, operator = RelationalOperators.EQUAL, right_operant = 4.0 ) # Latest face detection result == True condition_cg1012 = Condition ( left_operant = TekVariables.DETECT_FACE_DETECTED, left_index = 0, operator = RelationalOperators.EQUAL, right_operant = True ) The ConditionGroup class The ConditionGroup implements composite conditions, based on more than 1 Condition objects. This class takes a LogicalOperators enum parameter in its constructor: def __init__(self, type) Thus, type can be one of the following: LogicalOperators.AND LogicalOperators.OR LogicalOperators.XOR Furthermore, conditions can be added using the addCondition(condition, opp) member, where condition must be of type Condition or ConditionGroup and if opp is True, the negation of the condition shall be tested. An example is the following: condition_cg62 = Condition ( left_operant = \"Counter\", left_op_type = OperantTypes.COUNTER, operator = RelationalOperators.EQUAL, right_operant = 4.0 ) condition_cg1012 = Condition ( left_operant = TekVariables.DETECT_FACE_DETECTED, left_index = 0, operator = RelationalOperators.EQUAL, right_operant = True ) cond = ConditionGroup(type = LogicalOperators.AND) cond.addCondition(condition_cg62) cond.addCondition(condition_cg1012, opp = True) This condition evaluates to True if Counter is equal to 4 and face detection did not find a face in the previous check.","title":"Conditions"},{"location":"conditions/#r4a-conditions","text":"In R4A APIs you can create conditions using two classes, Condition that denotes a single condition or ConditionGroup , denoting a composite condition. Let's see both of them in detail.","title":"R4A Conditions"},{"location":"conditions/#the-condition-class","text":"The Condition class implements a single condition. The constructor of the class is as follows: def __init__(self, left_operant = None, right_operant = None, operator = None, left_op_type = None, right_op_type = None, left_index = 0, right_index = 0) Let's discuss on each parameter: left_operant and right_operant are the two operants of the Condition. An operant can be either a constant value (number or string) a TekVariable or a counter variable. The specific type of each operant is declared via the left_op_type and right_op_type parameters, which must be of type OperantTypes enum . The possible items are: OperantTypes.CONSTANT OperantTypes.TEK_VARIABLE OperantTypes.COUNTER In case of the OperantTypes.COUNTER , the left/right_operant must be assigned the name of the counter. The operator parameter declares the logical operator and is of type RelationalOperators enum , with items: RelationalOperators.EQUAL RelationalOperators.SMALLER RelationalOperators.SMALLER_EQUAL RelationalOperators.LARGER RelationalOperators.LARGER_EQUAL RelationalOperators.NOT_EQUAL Finally, left/right_index parameters are used when an operant is of type OperantTypes.TEK_VARIABLE , specifying the index of the value that is going to be retrieved from memory (0 is the latest, -1 the previous etc.) Each condition is checked, using the check() method, returning either True or False. Some examples are: # Counter == 4 condition_cg62 = Condition ( left_operant = \"Counter\", left_op_type = OperantTypes.COUNTER, operator = RelationalOperators.EQUAL, right_operant = 4.0 ) # Latest face detection result == True condition_cg1012 = Condition ( left_operant = TekVariables.DETECT_FACE_DETECTED, left_index = 0, operator = RelationalOperators.EQUAL, right_operant = True )","title":"The Condition class"},{"location":"conditions/#the-conditiongroup-class","text":"The ConditionGroup implements composite conditions, based on more than 1 Condition objects. This class takes a LogicalOperators enum parameter in its constructor: def __init__(self, type) Thus, type can be one of the following: LogicalOperators.AND LogicalOperators.OR LogicalOperators.XOR Furthermore, conditions can be added using the addCondition(condition, opp) member, where condition must be of type Condition or ConditionGroup and if opp is True, the negation of the condition shall be tested. An example is the following: condition_cg62 = Condition ( left_operant = \"Counter\", left_op_type = OperantTypes.COUNTER, operator = RelationalOperators.EQUAL, right_operant = 4.0 ) condition_cg1012 = Condition ( left_operant = TekVariables.DETECT_FACE_DETECTED, left_index = 0, operator = RelationalOperators.EQUAL, right_operant = True ) cond = ConditionGroup(type = LogicalOperators.AND) cond.addCondition(condition_cg62) cond.addCondition(condition_cg1012, opp = True) This condition evaluates to True if Counter is equal to 4 and face detection did not find a face in the previous check.","title":"The ConditionGroup class"},{"location":"encoders/","text":"Encoders API RobotAPI . getEncoderMeasurement Retrieves encoders information from memory. Input parameters An InputMessage , containing in data : deviceId : The id of a Devices.BUTTON device fromIndex : From what index the data will be retrieved toIndex : To what index the data will be retrieved Output An OutputMessage , containing in data : measurements: deviceId, timestamp, value","title":"Encoders API"},{"location":"encoders/#encoders-api","text":"","title":"Encoders API"},{"location":"encoders/#robotapigetencodermeasurement","text":"Retrieves encoders information from memory.","title":"RobotAPI.getEncoderMeasurement"},{"location":"encoders/#input-parameters","text":"An InputMessage , containing in data : deviceId : The id of a Devices.BUTTON device fromIndex : From what index the data will be retrieved toIndex : To what index the data will be retrieved","title":"Input parameters"},{"location":"encoders/#output","text":"An OutputMessage , containing in data : measurements: deviceId, timestamp, value","title":"Output"},{"location":"enums/","text":"Enumerations and Variables R4A APIs contain a lot of variables, as well as enumerations, to handle specific values. Their description follows. All of these are called as such: If the name of the class is Class and the member is member , you can get the specific item by Class.member . Devices enum Holds the different device types (sensors / effectors) that R4A API enables. The possible items are: Devices.SONAR Devices.IR Devices.TOF Devices.ENV Devices.IMU Devices.MICROPHONE Devices.SPEAKERS Devices.CAMERA Devices.MOTION Devices.PAN_TILT Devices.LED Devices.LINE_FOLLOWER Devices.SCREEN Devices.TOUCH_SCREEN Devices.ENCODER Devices.BUTTON Devices.UNKNOWN Devices enum offers the getTypeFromString static function that takes as input one string and returns the type. An example follows: from utilities import Devices str = \"SONAR\" item = Devices.getTypeFromString(str) print(item) The result is <Devices.SONAR: sonar > . DevicePlacement enum Holds the different placements of the devices that may have on the robot. The possible places follow. For the next items, F stands for Front, L for Left, R for Right, B for Back and G for Generic. DevicePlacement.F DevicePlacement.FL DevicePlacement.FR DevicePlacement.B DevicePlacement.BL DevicePlacement.BR DevicePlacement.R DevicePlacement.L DevicePlacement.G1 DevicePlacement.G2 DevicePlacement.G3 DevicePlacement.G4 DevicePlacement.FRONT DevicePlacement.CENTER DevicePlacement.RIGHT DevicePlacement.LEFT DevicePlacement.BACK DevicePlacement.UNDER DevicePlacement.PAN_TILT DevicePlacement.UNKNOWN Directions enum Directions hold the different directions to be used either from sensors or effectors. The different options are: Directions.FORWARDS Directions.BACKWARDS Directions.LEFT Directions.RIGHT Directions.UP Directions.DOWN Directions.NEUTRAL DetectionType enum This is used in order to specify input type for specific algorithms. The options here are: DetectionType.IMAGE DetectionType.AUDIO MotionType enum Holds the possible motion types of the robot or of specific parts of it. The options are: MotionType.BASIC MotionType.SPEED_BASED MotionType.FOLLOW_LINE MotionType.ANGLE_BASED MotionType.TIME_BASED Languages enum Holds the different languages R4A API supports. For now we have: Languages.EL Languages.EN Sentiments enum Holds the different sentiments used by the algorithms. These are: Sentiments.HAPPY Sentiments.SAD Sentiments.CRYING Sentiments.NEUTRAL Sentiments.DELIGHTED Colors enum Holds the different colors supported by the R4A API. There are: Colors.RED Colors.WHITE Colors.GREEN Colors.BLUE Colors.BLACK Colors.YELLOW Colors.MAGENTA Colors.CYAN Colors.UNKNOWN Sex enum Holds the different sexes. These are: Sex.MALE Sex.FEMALE Resolutions enum Holds the different resolutions the camera supports. These are: Resolutions.R_800_480 Resolutions.R_640_480 Format enum Holds the different formats an image may have. These are: Format.JPG Format.PNG Sonars enum Holds the different sonar placements (specific to TekTrain project). These are: Sonars.FL Sonars.FR Sonars.BR Sonars.BL Sonars.R Sonars.L Tofs enum Holds the different Time of Flight sensor placements (specific to TekTrain project). These are: Tofs.F Irs enum Holds the different IR sensor placements (specific to TekTrain project). These are: Irs.F Irs.B Irs.R Irs.L Tactile enum Holds the different tactile (buttons) positions (specific to TekTrain project). These are: Tactile.F Tactile.FL Tactile.FR Tactile.B Tactile.BL Tactile.BR Tactile.R Tactile.L Tactile.G1 Tactile.G2 Tactile.G3 Tactile.G4 TekVariables enum Apart from the above enumeration, there is a large enumeration that holds all the variables that are stored in memory . All data is stored in Redis and the keys the variables are stored in exist next to the variables in the list below. These variables are: Robot motion related TekVariables.MOTION_DISTANCE_THRES = variables.motion.distance_thres TekVariables.MOTION_DURATION_THRES = variables.motion.duration_thres TekVariables.MOTION_LINEAR = variables.motion.linear TekVariables.MOTION_ROTATIONAL = variables.motion.rotational TekVariables.MOTION_DIRECTION = variables.motion.direction TekVariables.MOTION_SPEED = variables.motion.speed TekVariables.MOTION_TYPE = variables.motion.type Robot turn related TekVariables.MOTION_TURN_TYPE = variables.motion_turn.type TekVariables.MOTION_TURN_ANGLE = variables.motion_turn.angle TekVariables.MOTION_TURN_DIRECTION = variables.motion_turn.direction TekVariables.MOTION_TURN_SPEED = variables.motion_turn.speed TekVariables.MOTION_TURN_DURATION = variables.motion_turn.duration Sleep related TekVariables.SLEEP_DURATION = variables.sleep.duration Talk related TekVariables.TALK_TEXTS = variables.talk.texts TekVariables.TALK_LANGUAGE = variables.talk.language TekVariables.TALK_VOLUME = variables.talk.volume LEDs related TekVariables.LEDS_COLOR = variables.leds.color TekVariables.LEDS_BRIGHTNESS = variables.leds.brightness Detect touch related TekVariables.DETECT_TOUCH_PARTS = variables.detect_touch.parts TekVariables.DETECT_TOUCH_DURATION = variables.detect_touch.duration TekVariables.DETECT_TOUCH_DETECTED = variables.detect_touch.detected TekVariables.DETECT_TOUCH_F = variables.detect_touch.f TekVariables.DETECT_TOUCH_FL = variables.detect_touch.fl TekVariables.DETECT_TOUCH_FR = variables.detect_touch.fr TekVariables.DETECT_TOUCH_B = variables.detect_touch.b TekVariables.DETECT_TOUCH_BR = variables.detect_touch.br TekVariables.DETECT_TOUCH_BL = variables.detect_touch.bl TekVariables.DETECT_TOUCH_L = variables.detect_touch.l TekVariables.DETECT_TOUCH_R = variables.detect_touch.r TekVariables.DETECT_TOUCH_G1 = variables.detect_touch.g1 TekVariables.DETECT_TOUCH_G2 = variables.detect_touch.g2 TekVariables.DETECT_TOUCH_G3 = variables.detect_touch.g3 TekVariables.DETECT_TOUCH_G4 = variables.detect_touch.g4 TekVariables.DETECT_TOUCH_PRESSED_PART = variables.detect_touch.pressed_part Camera motion related TekVariables.CAMERA_MOTION_DIRECTION = variables.camera_motion.direction TekVariables.CAMERA_MOTION_YAW = variables.camera_motion.yaw TekVariables.CAMERA_MOTION_PITCH = variables.camera_motion.pitch Record sound related TekVariables.RECORD_SOUND_NAME = variables.record_sound.name TekVariables.RECORD_SOUND_DURATION = variables.record_sound.duration TekVariables.RECORD_SOUND_PART = variables.record_sound.part Replay sound related TekVariables.REPLAY_SOUND_NAME = variables.replay_sound.name TekVariables.REPLAY_SOUND_VOLUME = variables.replay_sound.volume Display emotion related TekVariables.DISPLAY_EMOTION_EMOTION = variables.display_emotion.emotion Weather report related: TekVariables.WEATHER_REPORT = variables.cloud.weather_report Detect face related TekVariables.DETECT_FACE_DURATION = variables.detect_face.duration TekVariables.DETECT_FACE_DETECTED = variables.detect_face.detected TekVariables.DETECT_FACE_DETECTED_FACES = variables.detect_face.faces TekVariables.FACE_DETECTION_NFACES = variables.cloud.face_detection.number TekVariables.FACE_DETECTION_COORDS = variables.cloud.face_detection.coords Detect age/gender related TekVariables.AGE_DETECTION = variables.cloud.age_detection TekVariables.GENDER_DETECTION = variables.cloud.gender_detection OCR detection related TekVariables.OCR_DETECTION = variables.cloud.ocr_detection QR/Barcode detection related TekVariables.QR_DETECTION = variables.cloud.qr_detection TekVariables.BARCODE_DETECTION = variables.cloud.barcode_detection Detect sentiment related TekVariables.DETECT_SENTIMENT_TYPE = variables.detect_sentiment.type TekVariables.DETECT_SENTIMENT_DURATION = variables.detect_sentiment.duration TekVariables.DETECT_SENTIMENT_DETECTED = variables.detect_sentiment.detected TekVariables.DETECT_SENTIMENT_DETECTED_SENTIMENT = variables.detect_sentiment.detected_sentiment TekVariables.DETECT_SENTIMENT_DETECTED_SENTIMENT_IMAGE = variables.detect_sentiment.detected_sentiment.image TekVariables.DETECT_SENTIMENT_DETECTED_SENTIMENT_SOUND = variables.detect_sentiment.detected_sentiment.sound TekVariables.DETECT_SENTIMENT_DETECTED_SENTIMENT_TEXT = variables.detect_sentiment.detected_sentiment.text Detect sound related TekVariables.DETECT_SOUND_DURATION = variables.detect_sound.duration TekVariables.DETECT_SOUND_DETECTED = variables.detect_sound.detected TekVariables.SOUND_DETECTION = variables.cloud.sound_detection Detect motion related TekVariables.DETECT_MOTION_DURATION = variables.detect_motion.duration TekVariables.DETECT_MOTION_DETECTED = variables.detect_motion.detected Detect dominant color related TekVariables.DETECT_DOMINANT_COLOR_DETECTED_COLOR = variables.detect_dominant_color.color TekVariables.DOMINANT_COLOR_RAW = variables.cloud.dominant_color.raw TekVariables.DOMINANT_COLOR = variables.cloud.dominant_color.parsed TekVariables.MOTION_DETECTION = variables.cloud.motion_detection Speech to text related TekVariables.SPEECH_TO_TEXT = variables.cloud.speech_to_text HW related TekVariables.HW_BUTTON_PRESS = variables.hw.button_press TekVariables.HW_CAMERA_IMAGE = variables.hw.camera_image TekVariables.HW_ENCODER = variables.hw.encoder TekVariables.HW_ENV_TEMPERATURE = variables.hw.env.temperature TekVariables.HW_ENV_HUMIDITY = variables.hw.env.humidity TekVariables.HW_ENV_PRESSURE = variables.hw.env.pressure TekVariables.HW_ENV_GAS = variables.hw.env.gas TekVariables.HW_ACCELERATION_X = variables.hw.imu.acceleration.x TekVariables.HW_ACCELERATION_Y = variables.hw.imu.acceleration.y TekVariables.HW_ACCELERATION_Z = variables.hw.imu.acceleration.z TekVariables.HW_COMPASS_YAW = variables.hw.imu.compass.yaw TekVariables.HW_COMPASS_PITCH = variables.hw.imu.compass.pitch TekVariables.HW_COMPASS_ROLL = variables.hw.imu.compass.roll TekVariables.HW_GYROSCOPE_YAW = variables.hw.imu.gyro.yaw TekVariables.HW_GYROSCOPE_PITCH = variables.hw.imu.gyro.pitch TekVariables.HW_GYROSCOPE_ROLL = variables.hw.imu.gyro.roll TekVariables.HW_IR = variables.hw.ir TekVariables.HW_SONAR = variables.hw.sonar TekVariables.HW_TOF = variables.hw.tof TekVariables.HW_LEDS_SET = variables.hw.leds.set TekVariables.HW_LEDS_WIPE = variables.hw.leds.wipe","title":"Enumerations"},{"location":"enums/#enumerations-and-variables","text":"R4A APIs contain a lot of variables, as well as enumerations, to handle specific values. Their description follows. All of these are called as such: If the name of the class is Class and the member is member , you can get the specific item by Class.member .","title":"Enumerations and Variables"},{"location":"enums/#devices-enum","text":"Holds the different device types (sensors / effectors) that R4A API enables. The possible items are: Devices.SONAR Devices.IR Devices.TOF Devices.ENV Devices.IMU Devices.MICROPHONE Devices.SPEAKERS Devices.CAMERA Devices.MOTION Devices.PAN_TILT Devices.LED Devices.LINE_FOLLOWER Devices.SCREEN Devices.TOUCH_SCREEN Devices.ENCODER Devices.BUTTON Devices.UNKNOWN Devices enum offers the getTypeFromString static function that takes as input one string and returns the type. An example follows: from utilities import Devices str = \"SONAR\" item = Devices.getTypeFromString(str) print(item) The result is <Devices.SONAR: sonar > .","title":"Devices enum"},{"location":"enums/#deviceplacement-enum","text":"Holds the different placements of the devices that may have on the robot. The possible places follow. For the next items, F stands for Front, L for Left, R for Right, B for Back and G for Generic. DevicePlacement.F DevicePlacement.FL DevicePlacement.FR DevicePlacement.B DevicePlacement.BL DevicePlacement.BR DevicePlacement.R DevicePlacement.L DevicePlacement.G1 DevicePlacement.G2 DevicePlacement.G3 DevicePlacement.G4 DevicePlacement.FRONT DevicePlacement.CENTER DevicePlacement.RIGHT DevicePlacement.LEFT DevicePlacement.BACK DevicePlacement.UNDER DevicePlacement.PAN_TILT DevicePlacement.UNKNOWN","title":"DevicePlacement enum"},{"location":"enums/#directions-enum","text":"Directions hold the different directions to be used either from sensors or effectors. The different options are: Directions.FORWARDS Directions.BACKWARDS Directions.LEFT Directions.RIGHT Directions.UP Directions.DOWN Directions.NEUTRAL","title":"Directions enum"},{"location":"enums/#detectiontype-enum","text":"This is used in order to specify input type for specific algorithms. The options here are: DetectionType.IMAGE DetectionType.AUDIO","title":"DetectionType enum"},{"location":"enums/#motiontype-enum","text":"Holds the possible motion types of the robot or of specific parts of it. The options are: MotionType.BASIC MotionType.SPEED_BASED MotionType.FOLLOW_LINE MotionType.ANGLE_BASED MotionType.TIME_BASED","title":"MotionType enum"},{"location":"enums/#languages-enum","text":"Holds the different languages R4A API supports. For now we have: Languages.EL Languages.EN","title":"Languages enum"},{"location":"enums/#sentiments-enum","text":"Holds the different sentiments used by the algorithms. These are: Sentiments.HAPPY Sentiments.SAD Sentiments.CRYING Sentiments.NEUTRAL Sentiments.DELIGHTED","title":"Sentiments enum"},{"location":"enums/#colors-enum","text":"Holds the different colors supported by the R4A API. There are: Colors.RED Colors.WHITE Colors.GREEN Colors.BLUE Colors.BLACK Colors.YELLOW Colors.MAGENTA Colors.CYAN Colors.UNKNOWN","title":"Colors enum"},{"location":"enums/#sex-enum","text":"Holds the different sexes. These are: Sex.MALE Sex.FEMALE","title":"Sex enum"},{"location":"enums/#resolutions-enum","text":"Holds the different resolutions the camera supports. These are: Resolutions.R_800_480 Resolutions.R_640_480","title":"Resolutions enum"},{"location":"enums/#format-enum","text":"Holds the different formats an image may have. These are: Format.JPG Format.PNG","title":"Format enum"},{"location":"enums/#sonars-enum","text":"Holds the different sonar placements (specific to TekTrain project). These are: Sonars.FL Sonars.FR Sonars.BR Sonars.BL Sonars.R Sonars.L","title":"Sonars enum"},{"location":"enums/#tofs-enum","text":"Holds the different Time of Flight sensor placements (specific to TekTrain project). These are: Tofs.F","title":"Tofs enum"},{"location":"enums/#irs-enum","text":"Holds the different IR sensor placements (specific to TekTrain project). These are: Irs.F Irs.B Irs.R Irs.L","title":"Irs enum"},{"location":"enums/#tactile-enum","text":"Holds the different tactile (buttons) positions (specific to TekTrain project). These are: Tactile.F Tactile.FL Tactile.FR Tactile.B Tactile.BL Tactile.BR Tactile.R Tactile.L Tactile.G1 Tactile.G2 Tactile.G3 Tactile.G4","title":"Tactile enum"},{"location":"enums/#tekvariables-enum","text":"Apart from the above enumeration, there is a large enumeration that holds all the variables that are stored in memory . All data is stored in Redis and the keys the variables are stored in exist next to the variables in the list below. These variables are: Robot motion related TekVariables.MOTION_DISTANCE_THRES = variables.motion.distance_thres TekVariables.MOTION_DURATION_THRES = variables.motion.duration_thres TekVariables.MOTION_LINEAR = variables.motion.linear TekVariables.MOTION_ROTATIONAL = variables.motion.rotational TekVariables.MOTION_DIRECTION = variables.motion.direction TekVariables.MOTION_SPEED = variables.motion.speed TekVariables.MOTION_TYPE = variables.motion.type Robot turn related TekVariables.MOTION_TURN_TYPE = variables.motion_turn.type TekVariables.MOTION_TURN_ANGLE = variables.motion_turn.angle TekVariables.MOTION_TURN_DIRECTION = variables.motion_turn.direction TekVariables.MOTION_TURN_SPEED = variables.motion_turn.speed TekVariables.MOTION_TURN_DURATION = variables.motion_turn.duration Sleep related TekVariables.SLEEP_DURATION = variables.sleep.duration Talk related TekVariables.TALK_TEXTS = variables.talk.texts TekVariables.TALK_LANGUAGE = variables.talk.language TekVariables.TALK_VOLUME = variables.talk.volume LEDs related TekVariables.LEDS_COLOR = variables.leds.color TekVariables.LEDS_BRIGHTNESS = variables.leds.brightness Detect touch related TekVariables.DETECT_TOUCH_PARTS = variables.detect_touch.parts TekVariables.DETECT_TOUCH_DURATION = variables.detect_touch.duration TekVariables.DETECT_TOUCH_DETECTED = variables.detect_touch.detected TekVariables.DETECT_TOUCH_F = variables.detect_touch.f TekVariables.DETECT_TOUCH_FL = variables.detect_touch.fl TekVariables.DETECT_TOUCH_FR = variables.detect_touch.fr TekVariables.DETECT_TOUCH_B = variables.detect_touch.b TekVariables.DETECT_TOUCH_BR = variables.detect_touch.br TekVariables.DETECT_TOUCH_BL = variables.detect_touch.bl TekVariables.DETECT_TOUCH_L = variables.detect_touch.l TekVariables.DETECT_TOUCH_R = variables.detect_touch.r TekVariables.DETECT_TOUCH_G1 = variables.detect_touch.g1 TekVariables.DETECT_TOUCH_G2 = variables.detect_touch.g2 TekVariables.DETECT_TOUCH_G3 = variables.detect_touch.g3 TekVariables.DETECT_TOUCH_G4 = variables.detect_touch.g4 TekVariables.DETECT_TOUCH_PRESSED_PART = variables.detect_touch.pressed_part Camera motion related TekVariables.CAMERA_MOTION_DIRECTION = variables.camera_motion.direction TekVariables.CAMERA_MOTION_YAW = variables.camera_motion.yaw TekVariables.CAMERA_MOTION_PITCH = variables.camera_motion.pitch Record sound related TekVariables.RECORD_SOUND_NAME = variables.record_sound.name TekVariables.RECORD_SOUND_DURATION = variables.record_sound.duration TekVariables.RECORD_SOUND_PART = variables.record_sound.part Replay sound related TekVariables.REPLAY_SOUND_NAME = variables.replay_sound.name TekVariables.REPLAY_SOUND_VOLUME = variables.replay_sound.volume Display emotion related TekVariables.DISPLAY_EMOTION_EMOTION = variables.display_emotion.emotion Weather report related: TekVariables.WEATHER_REPORT = variables.cloud.weather_report Detect face related TekVariables.DETECT_FACE_DURATION = variables.detect_face.duration TekVariables.DETECT_FACE_DETECTED = variables.detect_face.detected TekVariables.DETECT_FACE_DETECTED_FACES = variables.detect_face.faces TekVariables.FACE_DETECTION_NFACES = variables.cloud.face_detection.number TekVariables.FACE_DETECTION_COORDS = variables.cloud.face_detection.coords Detect age/gender related TekVariables.AGE_DETECTION = variables.cloud.age_detection TekVariables.GENDER_DETECTION = variables.cloud.gender_detection OCR detection related TekVariables.OCR_DETECTION = variables.cloud.ocr_detection QR/Barcode detection related TekVariables.QR_DETECTION = variables.cloud.qr_detection TekVariables.BARCODE_DETECTION = variables.cloud.barcode_detection Detect sentiment related TekVariables.DETECT_SENTIMENT_TYPE = variables.detect_sentiment.type TekVariables.DETECT_SENTIMENT_DURATION = variables.detect_sentiment.duration TekVariables.DETECT_SENTIMENT_DETECTED = variables.detect_sentiment.detected TekVariables.DETECT_SENTIMENT_DETECTED_SENTIMENT = variables.detect_sentiment.detected_sentiment TekVariables.DETECT_SENTIMENT_DETECTED_SENTIMENT_IMAGE = variables.detect_sentiment.detected_sentiment.image TekVariables.DETECT_SENTIMENT_DETECTED_SENTIMENT_SOUND = variables.detect_sentiment.detected_sentiment.sound TekVariables.DETECT_SENTIMENT_DETECTED_SENTIMENT_TEXT = variables.detect_sentiment.detected_sentiment.text Detect sound related TekVariables.DETECT_SOUND_DURATION = variables.detect_sound.duration TekVariables.DETECT_SOUND_DETECTED = variables.detect_sound.detected TekVariables.SOUND_DETECTION = variables.cloud.sound_detection Detect motion related TekVariables.DETECT_MOTION_DURATION = variables.detect_motion.duration TekVariables.DETECT_MOTION_DETECTED = variables.detect_motion.detected Detect dominant color related TekVariables.DETECT_DOMINANT_COLOR_DETECTED_COLOR = variables.detect_dominant_color.color TekVariables.DOMINANT_COLOR_RAW = variables.cloud.dominant_color.raw TekVariables.DOMINANT_COLOR = variables.cloud.dominant_color.parsed TekVariables.MOTION_DETECTION = variables.cloud.motion_detection Speech to text related TekVariables.SPEECH_TO_TEXT = variables.cloud.speech_to_text HW related TekVariables.HW_BUTTON_PRESS = variables.hw.button_press TekVariables.HW_CAMERA_IMAGE = variables.hw.camera_image TekVariables.HW_ENCODER = variables.hw.encoder TekVariables.HW_ENV_TEMPERATURE = variables.hw.env.temperature TekVariables.HW_ENV_HUMIDITY = variables.hw.env.humidity TekVariables.HW_ENV_PRESSURE = variables.hw.env.pressure TekVariables.HW_ENV_GAS = variables.hw.env.gas TekVariables.HW_ACCELERATION_X = variables.hw.imu.acceleration.x TekVariables.HW_ACCELERATION_Y = variables.hw.imu.acceleration.y TekVariables.HW_ACCELERATION_Z = variables.hw.imu.acceleration.z TekVariables.HW_COMPASS_YAW = variables.hw.imu.compass.yaw TekVariables.HW_COMPASS_PITCH = variables.hw.imu.compass.pitch TekVariables.HW_COMPASS_ROLL = variables.hw.imu.compass.roll TekVariables.HW_GYROSCOPE_YAW = variables.hw.imu.gyro.yaw TekVariables.HW_GYROSCOPE_PITCH = variables.hw.imu.gyro.pitch TekVariables.HW_GYROSCOPE_ROLL = variables.hw.imu.gyro.roll TekVariables.HW_IR = variables.hw.ir TekVariables.HW_SONAR = variables.hw.sonar TekVariables.HW_TOF = variables.hw.tof TekVariables.HW_LEDS_SET = variables.hw.leds.set TekVariables.HW_LEDS_WIPE = variables.hw.leds.wipe","title":"TekVariables enum"},{"location":"env/","text":"Environmental sensor API RobotAPI . getTemperatureMeasurement Gets temperature measurements from memory. Input parameters An InputMessage , containing in data : deviceId : The id of a Devices.ENV device fromIndex : From what index the data will be retrieved toIndex : To what index the data will be retrieved Output An OutputMessage , containing in data : measurements: deviceId, timestamp, value RobotAPI . getHumidityMeasurement Gets humidity measurements from memory. Input parameters An InputMessage , containing in data : deviceId : The id of a Devices.ENV device fromIndex : From what index the data will be retrieved toIndex : To what index the data will be retrieved Output An OutputMessage , containing in data : measurements: deviceId, timestamp, value RobotAPI . getPressureMeasurement Gets pressure measurements from memory. Input parameters An InputMessage , containing in data : deviceId : The id of a Devices.ENV device fromIndex : From what index the data will be retrieved toIndex : To what index the data will be retrieved Output An OutputMessage , containing in data : measurements: deviceId, timestamp, value RobotAPI . getGasMeasurement Gets gas measurements from memory. Input parameters An InputMessage , containing in data : deviceId : The id of a Devices.ENV device fromIndex : From what index the data will be retrieved toIndex : To what index the data will be retrieved Output An OutputMessage , containing in data : measurements: deviceId, timestamp, value","title":"Environmental API"},{"location":"env/#environmental-sensor-api","text":"","title":"Environmental sensor API"},{"location":"env/#robotapigettemperaturemeasurement","text":"Gets temperature measurements from memory.","title":"RobotAPI.getTemperatureMeasurement"},{"location":"env/#input-parameters","text":"An InputMessage , containing in data : deviceId : The id of a Devices.ENV device fromIndex : From what index the data will be retrieved toIndex : To what index the data will be retrieved","title":"Input parameters"},{"location":"env/#output","text":"An OutputMessage , containing in data : measurements: deviceId, timestamp, value","title":"Output"},{"location":"env/#robotapigethumiditymeasurement","text":"Gets humidity measurements from memory.","title":"RobotAPI.getHumidityMeasurement"},{"location":"env/#input-parameters_1","text":"An InputMessage , containing in data : deviceId : The id of a Devices.ENV device fromIndex : From what index the data will be retrieved toIndex : To what index the data will be retrieved","title":"Input parameters"},{"location":"env/#output_1","text":"An OutputMessage , containing in data : measurements: deviceId, timestamp, value","title":"Output"},{"location":"env/#robotapigetpressuremeasurement","text":"Gets pressure measurements from memory.","title":"RobotAPI.getPressureMeasurement"},{"location":"env/#input-parameters_2","text":"An InputMessage , containing in data : deviceId : The id of a Devices.ENV device fromIndex : From what index the data will be retrieved toIndex : To what index the data will be retrieved","title":"Input parameters"},{"location":"env/#output_2","text":"An OutputMessage , containing in data : measurements: deviceId, timestamp, value","title":"Output"},{"location":"env/#robotapigetgasmeasurement","text":"Gets gas measurements from memory.","title":"RobotAPI.getGasMeasurement"},{"location":"env/#input-parameters_3","text":"An InputMessage , containing in data : deviceId : The id of a Devices.ENV device fromIndex : From what index the data will be retrieved toIndex : To what index the data will be retrieved","title":"Input parameters"},{"location":"env/#output_3","text":"An OutputMessage , containing in data : measurements: deviceId, timestamp, value","title":"Output"},{"location":"examples/","text":"Simple talk application #!/usr/bin/python # -*- coding: utf-8 -*- import sys import os import logging from r4a_apis.utilities import * from r4a_apis.tek_nodes import * from r4a_apis.robot_api import RobotAPI from r4a_apis.cloud_api import CloudAPI from r4a_apis.generic_api import GenericAPI try: log = Logger(allow_cutelog = False, level = logging.INFO) TekNode.logger = log TekNode.robot_api = RobotAPI(logger = log) TekNode.cloud_api = CloudAPI(memory = TekNode.robot_api.memory, logger = log) TekNode.generic_api = GenericAPI(memory = TekNode.robot_api.memory, logger = log) Condition.memory = TekNode.robot_api.memory Condition.logger = log InputMessage.logger = log OutputMessage.logger = log TekException.logger = log NodeExecutor.logger = log log.debug('main', \"Hey, app is starting\") nodes = {} nodes[0] = StartTekNode(0) nodes[1] = TalkTekNode(1) nodes[1].setParameters(language = Languages.EN, texts = [\"Hello!\"], volume = 100) nodes[2] = StopTekNode(2) # Conditions # Transitions nodes[0].setNextNode(id = 1) nodes[1].setNextNode(id = 2) # Thread executors # Main execution main_executor = NodeExecutor(exe_id = 0) main_executor.addNode(id = 0, node = nodes[0]) main_executor.addNode(id = 1, node = nodes[1]) main_executor.addNode(id = 2, node = nodes[2]) main_executor.setStartingNode(id = 0) # Go for it main_executor.execute() except TekException: pass Draw a rectangle #!/usr/bin/python # -*- coding: utf-8 -*- import sys import os import logging from r4a_apis.utilities import * from r4a_apis.tek_nodes import * from r4a_apis.robot_api import RobotAPI from r4a_apis.cloud_api import CloudAPI from r4a_apis.generic_api import GenericAPI try: log = Logger(allow_cutelog = False, level = logging.INFO) TekNode.logger = log TekNode.robot_api = RobotAPI(logger = log) TekNode.cloud_api = CloudAPI(memory = TekNode.robot_api.memory, logger = log) TekNode.generic_api = GenericAPI(memory = TekNode.robot_api.memory, logger = log) Condition.memory = TekNode.robot_api.memory Condition.logger = log InputMessage.logger = log OutputMessage.logger = log TekException.logger = log NodeExecutor.logger = log log.debug('main', \"Hey, app is starting\") nodes = {} nodes[0] = StartTekNode(0) nodes[2] = StopTekNode(2) nodes[3] = RobotMotionTekNode(3) nodes[3].setParameters(distance = None, duration = 5.0, direction = Directions.FORWARDS, speed = 0.2, type = MotionType.BASIC) nodes[4] = CounterTekNode(4) nodes[4].setParameters(name = \"Counter\", set_value = 0, change_by = 1) nodes[5] = RobotTurnTekNode(5) nodes[5].setParameters(type = MotionType.BASIC, direction = Directions.RIGHT) nodes[6] = TransitionTekNode(6) nodes[7] = TransitionTekNode(7) # Conditions cg62 = ConditionGroup(type = LogicalOperators.AND) condition_cg62 = Condition ( left_operant = \"Counter\", left_index = 0, left_op_type = OperantTypes.COUNTER, operator = RelationalOperators.EQUAL, right_operant = 4.0, right_index = 0 ) cg62.addCondition(condition_cg62) cg67 = ConditionGroup(type = LogicalOperators.AND) condition_cg67 = Condition ( left_operant = \"Counter\", left_index = 0, left_op_type = OperantTypes.COUNTER, operator = RelationalOperators.NOT_EQUAL, right_operant = 4.0, right_index = 0 ) cg67.addCondition(condition_cg67) # Transitions nodes[0].setNextNode(id = 4) nodes[3].setNextNode(id = 5) nodes[4].setNextNode(id = 3) nodes[5].setNextNode(id = 6) nodes[6].setNextNode(id = 2, condition = cg62) nodes[6].setNextNode(id = 7, condition = cg67) nodes[7].setNextNode(id = 4) # Thread executors # Main execution main_executor = NodeExecutor(exe_id = 0) main_executor.addNode(id = 0, node = nodes[0]) main_executor.addNode(id = 2, node = nodes[2]) main_executor.addNode(id = 3, node = nodes[3]) main_executor.addNode(id = 4, node = nodes[4]) main_executor.addNode(id = 5, node = nodes[5]) main_executor.addNode(id = 6, node = nodes[6]) main_executor.addNode(id = 7, node = nodes[7]) main_executor.setStartingNode(id = 0) # Go for it main_executor.execute() except TekException: pass Search for face and randomly move in parallel #!/usr/bin/python # -*- coding: utf-8 -*- import sys import os import logging from r4a_apis.utilities import * from r4a_apis.tek_nodes import * from r4a_apis.robot_api import RobotAPI from r4a_apis.cloud_api import CloudAPI from r4a_apis.generic_api import GenericAPI try: log = Logger(allow_cutelog = False, level = logging.INFO) TekNode.logger = log TekNode.robot_api = RobotAPI(logger = log) TekNode.cloud_api = CloudAPI(memory = TekNode.robot_api.memory, logger = log) TekNode.generic_api = GenericAPI(memory = TekNode.robot_api.memory, logger = log) Condition.memory = TekNode.robot_api.memory Condition.logger = log InputMessage.logger = log OutputMessage.logger = log TekException.logger = log NodeExecutor.logger = log log.debug('main', \"Hey, app is starting\") nodes = {} nodes[0] = StartTekNode(0) nodes[1] = ThreadsTekNode(1) nodes[3] = DiceTekNode(3) nodes[4] = RobotMotionTekNode(4) nodes[4].setParameters(distance = None, duration = 5.0, direction = Directions.FORWARDS, speed = 0.2, type = MotionType.BASIC) nodes[5] = RobotTurnTekNode(5) nodes[5].setParameters(type = MotionType.BASIC, direction = Directions.RIGHT) nodes[6] = SleepTekNode(6) nodes[6].setParameters(duration = 1.0) nodes[7] = TransitionTekNode(7) nodes[8] = TransitionTekNode(8) nodes[9] = DetectFaceTekNode(9) nodes[9].setParameters(duration = 5.0) nodes[10] = TransitionTekNode(10) nodes[11] = TransitionTekNode(11) nodes[12] = PreemptorTekNode(12) nodes[12].setParameters(preempt_executors = [3]) nodes[13] = StopTekNode(13) # Conditions cg1012 = ConditionGroup(type = LogicalOperators.AND) condition_cg1012 = Condition ( left_operant = TekVariables.DETECT_FACE_DETECTED, left_index = 0, operator = RelationalOperators.EQUAL, right_operant = True, right_index = 0 ) cg1012.addCondition(condition_cg1012) cg1011 = ConditionGroup(type = LogicalOperators.AND) condition_cg1011 = Condition ( left_operant = TekVariables.DETECT_FACE_DETECTED, left_index = 0, operator = RelationalOperators.EQUAL, right_operant = False, right_index = 0 ) cg1011.addCondition(condition_cg1011) # Transitions nodes[0].setNextNode(id = 1) nodes[1].setNextNode(id = 13) nodes[3].setNextNodeProbabilistic(id = 4, weight = 50.0) nodes[3].setNextNodeProbabilistic(id = 5, weight = 50.0) nodes[4].setNextNode(id = 6) nodes[5].setNextNode(id = 7) nodes[6].setNextNode(id = 8) nodes[7].setNextNode(id = 6) nodes[8].setNextNode(id = 3) nodes[9].setNextNode(id = 10) nodes[10].setNextNode(id = 12, condition = cg1012) nodes[10].setNextNode(id = 11, condition = cg1011) nodes[11].setNextNode(id = 9) # Thread executors executors_th_1 = {} executors_th_1[3] = NodeExecutor(exe_id = 3) executors_th_1[3].addNode(id = 3, node = nodes[3]) executors_th_1[3].addNode(id = 4, node = nodes[4]) executors_th_1[3].addNode(id = 6, node = nodes[6]) executors_th_1[3].addNode(id = 8, node = nodes[8]) executors_th_1[3].addNode(id = 5, node = nodes[5]) executors_th_1[3].addNode(id = 7, node = nodes[7]) executors_th_1[3].setStartingNode(id = 3) executors_th_1[9] = NodeExecutor(exe_id = 9) executors_th_1[9].addNode(id = 9, node = nodes[9]) executors_th_1[9].addNode(id = 10, node = nodes[10]) executors_th_1[9].addNode(id = 12, node = nodes[12]) executors_th_1[9].addNode(id = 11, node = nodes[11]) executors_th_1[9].setStartingNode(id = 9) nodes[1].setParameters(executors = executors_th_1) # Main execution main_executor = NodeExecutor(exe_id = 0) main_executor.addNode(id = 0, node = nodes[0]) main_executor.addNode(id = 1, node = nodes[1]) main_executor.addNode(id = 13, node = nodes[13]) main_executor.setStartingNode(id = 0) # Go for it main_executor.execute() except TekException: pass","title":"Examples"},{"location":"examples/#simple-talk-application","text":"#!/usr/bin/python # -*- coding: utf-8 -*- import sys import os import logging from r4a_apis.utilities import * from r4a_apis.tek_nodes import * from r4a_apis.robot_api import RobotAPI from r4a_apis.cloud_api import CloudAPI from r4a_apis.generic_api import GenericAPI try: log = Logger(allow_cutelog = False, level = logging.INFO) TekNode.logger = log TekNode.robot_api = RobotAPI(logger = log) TekNode.cloud_api = CloudAPI(memory = TekNode.robot_api.memory, logger = log) TekNode.generic_api = GenericAPI(memory = TekNode.robot_api.memory, logger = log) Condition.memory = TekNode.robot_api.memory Condition.logger = log InputMessage.logger = log OutputMessage.logger = log TekException.logger = log NodeExecutor.logger = log log.debug('main', \"Hey, app is starting\") nodes = {} nodes[0] = StartTekNode(0) nodes[1] = TalkTekNode(1) nodes[1].setParameters(language = Languages.EN, texts = [\"Hello!\"], volume = 100) nodes[2] = StopTekNode(2) # Conditions # Transitions nodes[0].setNextNode(id = 1) nodes[1].setNextNode(id = 2) # Thread executors # Main execution main_executor = NodeExecutor(exe_id = 0) main_executor.addNode(id = 0, node = nodes[0]) main_executor.addNode(id = 1, node = nodes[1]) main_executor.addNode(id = 2, node = nodes[2]) main_executor.setStartingNode(id = 0) # Go for it main_executor.execute() except TekException: pass","title":"Simple talk application"},{"location":"examples/#draw-a-rectangle","text":"#!/usr/bin/python # -*- coding: utf-8 -*- import sys import os import logging from r4a_apis.utilities import * from r4a_apis.tek_nodes import * from r4a_apis.robot_api import RobotAPI from r4a_apis.cloud_api import CloudAPI from r4a_apis.generic_api import GenericAPI try: log = Logger(allow_cutelog = False, level = logging.INFO) TekNode.logger = log TekNode.robot_api = RobotAPI(logger = log) TekNode.cloud_api = CloudAPI(memory = TekNode.robot_api.memory, logger = log) TekNode.generic_api = GenericAPI(memory = TekNode.robot_api.memory, logger = log) Condition.memory = TekNode.robot_api.memory Condition.logger = log InputMessage.logger = log OutputMessage.logger = log TekException.logger = log NodeExecutor.logger = log log.debug('main', \"Hey, app is starting\") nodes = {} nodes[0] = StartTekNode(0) nodes[2] = StopTekNode(2) nodes[3] = RobotMotionTekNode(3) nodes[3].setParameters(distance = None, duration = 5.0, direction = Directions.FORWARDS, speed = 0.2, type = MotionType.BASIC) nodes[4] = CounterTekNode(4) nodes[4].setParameters(name = \"Counter\", set_value = 0, change_by = 1) nodes[5] = RobotTurnTekNode(5) nodes[5].setParameters(type = MotionType.BASIC, direction = Directions.RIGHT) nodes[6] = TransitionTekNode(6) nodes[7] = TransitionTekNode(7) # Conditions cg62 = ConditionGroup(type = LogicalOperators.AND) condition_cg62 = Condition ( left_operant = \"Counter\", left_index = 0, left_op_type = OperantTypes.COUNTER, operator = RelationalOperators.EQUAL, right_operant = 4.0, right_index = 0 ) cg62.addCondition(condition_cg62) cg67 = ConditionGroup(type = LogicalOperators.AND) condition_cg67 = Condition ( left_operant = \"Counter\", left_index = 0, left_op_type = OperantTypes.COUNTER, operator = RelationalOperators.NOT_EQUAL, right_operant = 4.0, right_index = 0 ) cg67.addCondition(condition_cg67) # Transitions nodes[0].setNextNode(id = 4) nodes[3].setNextNode(id = 5) nodes[4].setNextNode(id = 3) nodes[5].setNextNode(id = 6) nodes[6].setNextNode(id = 2, condition = cg62) nodes[6].setNextNode(id = 7, condition = cg67) nodes[7].setNextNode(id = 4) # Thread executors # Main execution main_executor = NodeExecutor(exe_id = 0) main_executor.addNode(id = 0, node = nodes[0]) main_executor.addNode(id = 2, node = nodes[2]) main_executor.addNode(id = 3, node = nodes[3]) main_executor.addNode(id = 4, node = nodes[4]) main_executor.addNode(id = 5, node = nodes[5]) main_executor.addNode(id = 6, node = nodes[6]) main_executor.addNode(id = 7, node = nodes[7]) main_executor.setStartingNode(id = 0) # Go for it main_executor.execute() except TekException: pass","title":"Draw a rectangle"},{"location":"examples/#search-for-face-and-randomly-move-in-parallel","text":"#!/usr/bin/python # -*- coding: utf-8 -*- import sys import os import logging from r4a_apis.utilities import * from r4a_apis.tek_nodes import * from r4a_apis.robot_api import RobotAPI from r4a_apis.cloud_api import CloudAPI from r4a_apis.generic_api import GenericAPI try: log = Logger(allow_cutelog = False, level = logging.INFO) TekNode.logger = log TekNode.robot_api = RobotAPI(logger = log) TekNode.cloud_api = CloudAPI(memory = TekNode.robot_api.memory, logger = log) TekNode.generic_api = GenericAPI(memory = TekNode.robot_api.memory, logger = log) Condition.memory = TekNode.robot_api.memory Condition.logger = log InputMessage.logger = log OutputMessage.logger = log TekException.logger = log NodeExecutor.logger = log log.debug('main', \"Hey, app is starting\") nodes = {} nodes[0] = StartTekNode(0) nodes[1] = ThreadsTekNode(1) nodes[3] = DiceTekNode(3) nodes[4] = RobotMotionTekNode(4) nodes[4].setParameters(distance = None, duration = 5.0, direction = Directions.FORWARDS, speed = 0.2, type = MotionType.BASIC) nodes[5] = RobotTurnTekNode(5) nodes[5].setParameters(type = MotionType.BASIC, direction = Directions.RIGHT) nodes[6] = SleepTekNode(6) nodes[6].setParameters(duration = 1.0) nodes[7] = TransitionTekNode(7) nodes[8] = TransitionTekNode(8) nodes[9] = DetectFaceTekNode(9) nodes[9].setParameters(duration = 5.0) nodes[10] = TransitionTekNode(10) nodes[11] = TransitionTekNode(11) nodes[12] = PreemptorTekNode(12) nodes[12].setParameters(preempt_executors = [3]) nodes[13] = StopTekNode(13) # Conditions cg1012 = ConditionGroup(type = LogicalOperators.AND) condition_cg1012 = Condition ( left_operant = TekVariables.DETECT_FACE_DETECTED, left_index = 0, operator = RelationalOperators.EQUAL, right_operant = True, right_index = 0 ) cg1012.addCondition(condition_cg1012) cg1011 = ConditionGroup(type = LogicalOperators.AND) condition_cg1011 = Condition ( left_operant = TekVariables.DETECT_FACE_DETECTED, left_index = 0, operator = RelationalOperators.EQUAL, right_operant = False, right_index = 0 ) cg1011.addCondition(condition_cg1011) # Transitions nodes[0].setNextNode(id = 1) nodes[1].setNextNode(id = 13) nodes[3].setNextNodeProbabilistic(id = 4, weight = 50.0) nodes[3].setNextNodeProbabilistic(id = 5, weight = 50.0) nodes[4].setNextNode(id = 6) nodes[5].setNextNode(id = 7) nodes[6].setNextNode(id = 8) nodes[7].setNextNode(id = 6) nodes[8].setNextNode(id = 3) nodes[9].setNextNode(id = 10) nodes[10].setNextNode(id = 12, condition = cg1012) nodes[10].setNextNode(id = 11, condition = cg1011) nodes[11].setNextNode(id = 9) # Thread executors executors_th_1 = {} executors_th_1[3] = NodeExecutor(exe_id = 3) executors_th_1[3].addNode(id = 3, node = nodes[3]) executors_th_1[3].addNode(id = 4, node = nodes[4]) executors_th_1[3].addNode(id = 6, node = nodes[6]) executors_th_1[3].addNode(id = 8, node = nodes[8]) executors_th_1[3].addNode(id = 5, node = nodes[5]) executors_th_1[3].addNode(id = 7, node = nodes[7]) executors_th_1[3].setStartingNode(id = 3) executors_th_1[9] = NodeExecutor(exe_id = 9) executors_th_1[9].addNode(id = 9, node = nodes[9]) executors_th_1[9].addNode(id = 10, node = nodes[10]) executors_th_1[9].addNode(id = 12, node = nodes[12]) executors_th_1[9].addNode(id = 11, node = nodes[11]) executors_th_1[9].setStartingNode(id = 9) nodes[1].setParameters(executors = executors_th_1) # Main execution main_executor = NodeExecutor(exe_id = 0) main_executor.addNode(id = 0, node = nodes[0]) main_executor.addNode(id = 1, node = nodes[1]) main_executor.addNode(id = 13, node = nodes[13]) main_executor.setStartingNode(id = 0) # Go for it main_executor.execute() except TekException: pass","title":"Search for face and randomly move in parallel"},{"location":"exceptions/","text":"The TekException class We also have custom exceptions that handle errors that occur in the R4A API. These are TekException objects that exist in the utilities module. In order to raise an exception you can write: from utilities import TekException raise TekException(\"String that explains the error\") In order to catch TekExceptions you can write something like this: try: pass # Code here except TekException: pass # Catches only TekExceptions except Exception: pass # Catches all other exceptions Each time a TekException is raised, a message is printed in console, containing information about which function raised the exception, in what line and what is the error message.","title":"Exceptions"},{"location":"exceptions/#the-tekexception-class","text":"We also have custom exceptions that handle errors that occur in the R4A API. These are TekException objects that exist in the utilities module. In order to raise an exception you can write: from utilities import TekException raise TekException(\"String that explains the error\") In order to catch TekExceptions you can write something like this: try: pass # Code here except TekException: pass # Catches only TekExceptions except Exception: pass # Catches all other exceptions Each time a TekException is raised, a message is printed in console, containing information about which function raised the exception, in what line and what is the error message.","title":"The TekException class"},{"location":"generic_counter/","text":"Counter API GenericAPI . counter Implements a counter functionality. Input parameters An InputMessage , containing in data : name : The name fo the counter set_value : The initial value of the counter change_by : The counter change The first time the GenericAPI . counter call is invoked with a specific counter name, this counter is initialized and set_value is given. Every next time, the specific counter's value changes by change_by . Output Alters the memory, under this key: counters.NAME , where the counter's value is kept.","title":"Counter API"},{"location":"generic_counter/#counter-api","text":"","title":"Counter API"},{"location":"generic_counter/#genericapicounter","text":"Implements a counter functionality.","title":"GenericAPI.counter"},{"location":"generic_counter/#input-parameters","text":"An InputMessage , containing in data : name : The name fo the counter set_value : The initial value of the counter change_by : The counter change The first time the GenericAPI . counter call is invoked with a specific counter name, this counter is initialized and set_value is given. Every next time, the specific counter's value changes by change_by .","title":"Input parameters"},{"location":"generic_counter/#output","text":"Alters the memory, under this key: counters.NAME , where the counter's value is kept.","title":"Output"},{"location":"generic_sleep/","text":"Sleep API GenericAPI . sleep Sleeps for an amount of time. Input parameters An InputMessage , containing in data : duration : The duration of sleep Output None","title":"Sleep API"},{"location":"generic_sleep/#sleep-api","text":"","title":"Sleep API"},{"location":"generic_sleep/#genericapisleep","text":"Sleeps for an amount of time.","title":"GenericAPI.sleep"},{"location":"generic_sleep/#input-parameters","text":"An InputMessage , containing in data : duration : The duration of sleep","title":"Input parameters"},{"location":"generic_sleep/#output","text":"None","title":"Output"},{"location":"genericapi/","text":"Generic API Generic API offers services / calls, with which you can perform generic tasks. As explained here , all calls get an InputMessage as input and an OutputMessage as output. This section contents are: Sleep API Counter API","title":"General"},{"location":"genericapi/#generic-api","text":"Generic API offers services / calls, with which you can perform generic tasks. As explained here , all calls get an InputMessage as input and an OutputMessage as output. This section contents are: Sleep API Counter API","title":"Generic API"},{"location":"imu/","text":"IMU API RobotAPI . getImuMeasurement Gets last IMU measurements from memory. Input parameters An InputMessage , containing in data : deviceId : The id of a Devices.IMU device fromIndex : From what index the data will be retrieved toIndex : To what index the data will be retrieved Output An OutputMessage , containing in data : measurements: [ deviceId, timestamp, acceleration: { x, y, z } compass: { yaw, pitch, roll } gyroscope: { yaw, pitch, roll } ]","title":"IMU API"},{"location":"imu/#imu-api","text":"","title":"IMU API"},{"location":"imu/#robotapigetimumeasurement","text":"Gets last IMU measurements from memory.","title":"RobotAPI.getImuMeasurement"},{"location":"imu/#input-parameters","text":"An InputMessage , containing in data : deviceId : The id of a Devices.IMU device fromIndex : From what index the data will be retrieved toIndex : To what index the data will be retrieved","title":"Input parameters"},{"location":"imu/#output","text":"An OutputMessage , containing in data : measurements: [ deviceId, timestamp, acceleration: { x, y, z } compass: { yaw, pitch, roll } gyroscope: { yaw, pitch, roll } ]","title":"Output"},{"location":"irs/","text":"IRs API RobotAPI . getIrMeasurement Gets IR sensors distance measurements from memory. Input parameters An InputMessage , containing in data : deviceId : The id of a Devices.IR device fromIndex : From what index the data will be retrieved toIndex : To what index the data will be retrieved Output An OutputMessage , containing in data : measurements: deviceId, timestamp, value","title":"Infrared API"},{"location":"irs/#irs-api","text":"","title":"IRs API"},{"location":"irs/#robotapigetirmeasurement","text":"Gets IR sensors distance measurements from memory.","title":"RobotAPI.getIrMeasurement"},{"location":"irs/#input-parameters","text":"An InputMessage , containing in data : deviceId : The id of a Devices.IR device fromIndex : From what index the data will be retrieved toIndex : To what index the data will be retrieved","title":"Input parameters"},{"location":"irs/#output","text":"An OutputMessage , containing in data : measurements: deviceId, timestamp, value","title":"Output"},{"location":"leds/","text":"LEDs API RobotAPI . lightLeds Lights a number of LEDS on the device. Input parameters An InputMessage , containing in data : devices : List containing: deviceId : The id of the specific LED r : Red component of light g : Green component of light b : Blue component of light intensity : The light's intensity Output Physical: The LEDs corresponding to the devices provided light up. RobotAPI . ledsColorWipe Lights all leds in a wiping manner. Input parameters An InputMessage , containing in data : r : Red component of light g : Green component of light b : Blue component of light brightness : The light's intensity Output Physical: All LEDs light up. RobotAPI . getLeds Gets data from leds activations which are stored in memory. Input parameters An InputMessage , containing in data : deviceId : The id of a Devices.SPEAKERS device fromIndex : From what index the data will be retrieved toIndex : To what index the data will be retrieved Output An OutputMessage , containing in data : measurements: deviceId, timestamp, value: r, g, b, intensity","title":"LEDs API"},{"location":"leds/#leds-api","text":"","title":"LEDs API"},{"location":"leds/#robotapilightleds","text":"Lights a number of LEDS on the device.","title":"RobotAPI.lightLeds"},{"location":"leds/#input-parameters","text":"An InputMessage , containing in data : devices : List containing: deviceId : The id of the specific LED r : Red component of light g : Green component of light b : Blue component of light intensity : The light's intensity","title":"Input parameters"},{"location":"leds/#output","text":"Physical: The LEDs corresponding to the devices provided light up.","title":"Output"},{"location":"leds/#robotapiledscolorwipe","text":"Lights all leds in a wiping manner.","title":"RobotAPI.ledsColorWipe"},{"location":"leds/#input-parameters_1","text":"An InputMessage , containing in data : r : Red component of light g : Green component of light b : Blue component of light brightness : The light's intensity","title":"Input parameters"},{"location":"leds/#output_1","text":"Physical: All LEDs light up.","title":"Output"},{"location":"leds/#robotapigetleds","text":"Gets data from leds activations which are stored in memory.","title":"RobotAPI.getLeds"},{"location":"leds/#input-parameters_2","text":"An InputMessage , containing in data : deviceId : The id of a Devices.SPEAKERS device fromIndex : From what index the data will be retrieved toIndex : To what index the data will be retrieved","title":"Input parameters"},{"location":"leds/#output_2","text":"An OutputMessage , containing in data : measurements: deviceId, timestamp, value: r, g, b, intensity","title":"Output"},{"location":"linefollower/","text":"Line follower API RobotAPI . getLineFollowerMeasurement fromIndex toindex","title":"Linefollower"},{"location":"linefollower/#line-follower-api","text":"","title":"Line follower API"},{"location":"linefollower/#robotapigetlinefollowermeasurement","text":"fromIndex toindex","title":"RobotAPI.getLineFollowerMeasurement"},{"location":"memory/","text":"The Memory In order to locally store a) all information generated from the sensors of the device, b) all input information from the app's calls and c) whatever the user that creates apps wants, we have created a key/value storage, using Redis . The memory object is initialized when a RobotAPI object is created and can be found as such: import robot_api r_api = robot_api.RobotAPI() memory = r_api.memory All data are written under a key , which which you can retrieve the data. Also each key denotes a topic in memory, which holds a queue of 10 items. So when you write a piece of data, it is written in place 0 and the item in place -9 is destroyed. Robot memory offers the following functionalities: Memory.listGet listGet retrieves data from memory using a key. - Input arguments key : A string denoting the key that identifies the data frm : The most recent index of the desired data to : The oldest index of the desired - Output Output is a list containing the data, along with the timestamp of the storage. - Example from robot_api import RobotAPI robot_api = RobotAPI() robot_api.memory.setKey(key = 'test', value = 1) robot_api.memory.setKey(key = 'test', value = 2) # Asking for the last two values o = robot_api.memory.listGet(key = 'test', frm = 0, to = -1) print(o) The output is [{'data': 2, 'timestamp': 1575364271.5788426}, {'data': 1, 'timestamp': 1575364271.5521088}] Memory.setKey This call either sets a new key or writes in an already existent key. - Input arguments key : A string denoting the key that identifies the data value : The value to be written. This value should be JSON serializable - Example from robot_api import RobotAPI robot_api = RobotAPI() robot_api.memory.setKey(key = 'test', value = 1) robot_api.memory.setKey(key = 'test', value = 2) Memory.getKey This call retrieves the last piece of data from memory using a key. - Input arguments key : A string denoting the key that identifies the data - Output Output is a list of size 1, along with the timestamp of the storage. - Example from robot_api import RobotAPI robot_api = RobotAPI() robot_api.memory.setKey(key = 'test', value = 1) robot_api.memory.setKey(key = 'test', value = 2) o = robot_api.memory.getKey(key = 'test') print(o) The output is: [{'data': 2, 'timestamp': 1575365240.3306623}] Memory.setVariable This call sets a TekVariable . - Input arguments variable : The TekVariable identifying the data value : The value to be written. This value should be JSON serializable - Example from utilities import TekVariables from robot_api import RobotAPI robot_api = RobotAPI() robot_api.memory.setVariable(variable = TekVariables.SLEEP_DURATION, value = 1) Memory.getVariable This call gets a TekVariable from the memory. - Input arguments variable : The TekVariable identifying the data - Output Output is a list of size 1, along with the timestamp of the storage. - Example from utilities import TekVariables from robot_api import RobotAPI robot_api = RobotAPI() robot_api.memory.setVariable(variable = TekVariables.SLEEP_DURATION, value = 1) o = robot_api.memory.getVariable(variable = TekVariables.SLEEP_DURATION) The output is: [{'data': 1, 'timestamp': 1575366048.6832085}]","title":"Memory"},{"location":"memory/#the-memory","text":"In order to locally store a) all information generated from the sensors of the device, b) all input information from the app's calls and c) whatever the user that creates apps wants, we have created a key/value storage, using Redis . The memory object is initialized when a RobotAPI object is created and can be found as such: import robot_api r_api = robot_api.RobotAPI() memory = r_api.memory All data are written under a key , which which you can retrieve the data. Also each key denotes a topic in memory, which holds a queue of 10 items. So when you write a piece of data, it is written in place 0 and the item in place -9 is destroyed. Robot memory offers the following functionalities:","title":"The Memory"},{"location":"memory/#memorylistget","text":"listGet retrieves data from memory using a key.","title":"Memory.listGet"},{"location":"memory/#-input-arguments","text":"key : A string denoting the key that identifies the data frm : The most recent index of the desired data to : The oldest index of the desired","title":"- Input arguments"},{"location":"memory/#-output","text":"Output is a list containing the data, along with the timestamp of the storage.","title":"- Output"},{"location":"memory/#-example","text":"from robot_api import RobotAPI robot_api = RobotAPI() robot_api.memory.setKey(key = 'test', value = 1) robot_api.memory.setKey(key = 'test', value = 2) # Asking for the last two values o = robot_api.memory.listGet(key = 'test', frm = 0, to = -1) print(o) The output is [{'data': 2, 'timestamp': 1575364271.5788426}, {'data': 1, 'timestamp': 1575364271.5521088}]","title":"- Example"},{"location":"memory/#memorysetkey","text":"This call either sets a new key or writes in an already existent key.","title":"Memory.setKey"},{"location":"memory/#-input-arguments_1","text":"key : A string denoting the key that identifies the data value : The value to be written. This value should be JSON serializable","title":"- Input arguments"},{"location":"memory/#-example_1","text":"from robot_api import RobotAPI robot_api = RobotAPI() robot_api.memory.setKey(key = 'test', value = 1) robot_api.memory.setKey(key = 'test', value = 2)","title":"- Example"},{"location":"memory/#memorygetkey","text":"This call retrieves the last piece of data from memory using a key.","title":"Memory.getKey"},{"location":"memory/#-input-arguments_2","text":"key : A string denoting the key that identifies the data","title":"- Input arguments"},{"location":"memory/#-output_1","text":"Output is a list of size 1, along with the timestamp of the storage.","title":"- Output"},{"location":"memory/#-example_2","text":"from robot_api import RobotAPI robot_api = RobotAPI() robot_api.memory.setKey(key = 'test', value = 1) robot_api.memory.setKey(key = 'test', value = 2) o = robot_api.memory.getKey(key = 'test') print(o) The output is: [{'data': 2, 'timestamp': 1575365240.3306623}]","title":"- Example"},{"location":"memory/#memorysetvariable","text":"This call sets a TekVariable .","title":"Memory.setVariable"},{"location":"memory/#-input-arguments_3","text":"variable : The TekVariable identifying the data value : The value to be written. This value should be JSON serializable","title":"- Input arguments"},{"location":"memory/#-example_3","text":"from utilities import TekVariables from robot_api import RobotAPI robot_api = RobotAPI() robot_api.memory.setVariable(variable = TekVariables.SLEEP_DURATION, value = 1)","title":"- Example"},{"location":"memory/#memorygetvariable","text":"This call gets a TekVariable from the memory.","title":"Memory.getVariable"},{"location":"memory/#-input-arguments_4","text":"variable : The TekVariable identifying the data","title":"- Input arguments"},{"location":"memory/#-output_2","text":"Output is a list of size 1, along with the timestamp of the storage.","title":"- Output"},{"location":"memory/#-example_4","text":"from utilities import TekVariables from robot_api import RobotAPI robot_api = RobotAPI() robot_api.memory.setVariable(variable = TekVariables.SLEEP_DURATION, value = 1) o = robot_api.memory.getVariable(variable = TekVariables.SLEEP_DURATION) The output is: [{'data': 1, 'timestamp': 1575366048.6832085}]","title":"- Example"},{"location":"messages/","text":"Input and Output messages There are two classes to handle input and output, which can be found in the utilities module. These are InputMessage and OutputMessage . InputMessage class You can create an input message as such: from utilities import InputMessage i = InputMessage() Every input message contains the following: timestamp : Contains the timestamp of the message's creation data : The data. This usually is a Python dictionary. print() : Function to print the input message An example follows: from utilities import InputMessage i = InputMessage({'duration': 3}) i.data['another'] = 2 i.print() The output in console is: Input message: [1575288958.9064102] Data: {'duration': 3, 'another': 2} OutputMessage class Every call of the Robot, Cloud or Generic API returns an OutputMessage . Each output message contains: timestamp : Contains the timestamp of the message's creation sequence : A unique number that characterizes the message errors : A list of possible errors logs : A list of logs. Usually contains trace-back information. data : The data that the message contains print() : Prints the output message An example code that utilizes an output message is the following: from utilities import Devices, InputMessage from robot_api import RobotAPI rapi = RobotAPI() rapi.devicesObj.enableDevicesType(Devices.TOUCH_SCREEN) out = rapi.showOptions(InputMessage({ 'options': ['Option 1', 'Option 2'], 'duration': 5 })) out.print() This snippet initializes a touch screen, shows 2 options and waits for 5 seconds for the user to select one. The output is: Output message: [1575290784.5641167] #5 {'reaction_time': 0.9212639331817627, 'selected': 'Option 1'} Errors: Logs: [1575290784.5652816] setOptions @ RobotAPITouchScreenController [1575290784.5658484] showOptions @ RobotAPI","title":"Messages"},{"location":"messages/#input-and-output-messages","text":"There are two classes to handle input and output, which can be found in the utilities module. These are InputMessage and OutputMessage .","title":"Input and Output messages"},{"location":"messages/#inputmessage-class","text":"You can create an input message as such: from utilities import InputMessage i = InputMessage() Every input message contains the following: timestamp : Contains the timestamp of the message's creation data : The data. This usually is a Python dictionary. print() : Function to print the input message An example follows: from utilities import InputMessage i = InputMessage({'duration': 3}) i.data['another'] = 2 i.print() The output in console is: Input message: [1575288958.9064102] Data: {'duration': 3, 'another': 2}","title":"InputMessage class"},{"location":"messages/#outputmessage-class","text":"Every call of the Robot, Cloud or Generic API returns an OutputMessage . Each output message contains: timestamp : Contains the timestamp of the message's creation sequence : A unique number that characterizes the message errors : A list of possible errors logs : A list of logs. Usually contains trace-back information. data : The data that the message contains print() : Prints the output message An example code that utilizes an output message is the following: from utilities import Devices, InputMessage from robot_api import RobotAPI rapi = RobotAPI() rapi.devicesObj.enableDevicesType(Devices.TOUCH_SCREEN) out = rapi.showOptions(InputMessage({ 'options': ['Option 1', 'Option 2'], 'duration': 5 })) out.print() This snippet initializes a touch screen, shows 2 options and waits for 5 seconds for the user to select one. The output is: Output message: [1575290784.5641167] #5 {'reaction_time': 0.9212639331817627, 'selected': 'Option 1'} Errors: Logs: [1575290784.5652816] setOptions @ RobotAPITouchScreenController [1575290784.5658484] showOptions @ RobotAPI","title":"OutputMessage class"},{"location":"microphone/","text":"Microphone API RobotAPI . recordSound This call records a sound from a microphone. Input arguments duration : How many seconds the recording will be name : A name to store the sound (can be later used to retrieve it) save_file_url : Absolute path to store the sound as a wav. If None , the sound is not locally stored. Output / Variables This call returns an OutputMessage , containing the following data: { 'record': The base64 encoded sound file } In does not change any TekVariables . Examples import robot_api import utilities rapi = robot_api.RobotAPI() out = rapi.recordSound(utilities.InputMessage({ 'name': 'test_sound_1', 'duration': 3, 'save_file_url': '/tmp/tmp.wav' })) sound_str = out.data['record']","title":"Microphone API"},{"location":"microphone/#microphone-api","text":"","title":"Microphone API"},{"location":"microphone/#robotapirecordsound","text":"This call records a sound from a microphone.","title":"RobotAPI.recordSound"},{"location":"microphone/#input-arguments","text":"duration : How many seconds the recording will be name : A name to store the sound (can be later used to retrieve it) save_file_url : Absolute path to store the sound as a wav. If None , the sound is not locally stored.","title":"Input arguments"},{"location":"microphone/#output-variables","text":"This call returns an OutputMessage , containing the following data: { 'record': The base64 encoded sound file } In does not change any TekVariables .","title":"Output / Variables"},{"location":"microphone/#examples","text":"import robot_api import utilities rapi = robot_api.RobotAPI() out = rapi.recordSound(utilities.InputMessage({ 'name': 'test_sound_1', 'duration': 3, 'save_file_url': '/tmp/tmp.wav' })) sound_str = out.data['record']","title":"Examples"},{"location":"motion/","text":"Body motion API RobotAPI . moveBody Moves the robot's chassis Input parameters An InputMessage , containing in data : linearVelocity : Linear velocity of the differential wheels vehicle rotationalVelocity : Rotational velocity of the differential wheels vehicle Output Physical: The robot moves. RobotAPI . getBodyVelocities Gets last chassis velocities from memory. Input parameters An InputMessage , containing in data : deviceId : The id of a Devices.MOTION device fromIndex : From what index the data will be retrieved toIndex : To what index the data will be retrieved Output An OutputMessage , containing in data : measurements: deviceId, timestamp, linearVelocity, rotationalVelocity","title":"Body motion API"},{"location":"motion/#body-motion-api","text":"","title":"Body motion API"},{"location":"motion/#robotapimovebody","text":"Moves the robot's chassis","title":"RobotAPI.moveBody"},{"location":"motion/#input-parameters","text":"An InputMessage , containing in data : linearVelocity : Linear velocity of the differential wheels vehicle rotationalVelocity : Rotational velocity of the differential wheels vehicle","title":"Input parameters"},{"location":"motion/#output","text":"Physical: The robot moves.","title":"Output"},{"location":"motion/#robotapigetbodyvelocities","text":"Gets last chassis velocities from memory.","title":"RobotAPI.getBodyVelocities"},{"location":"motion/#input-parameters_1","text":"An InputMessage , containing in data : deviceId : The id of a Devices.MOTION device fromIndex : From what index the data will be retrieved toIndex : To what index the data will be retrieved","title":"Input parameters"},{"location":"motion/#output_1","text":"An OutputMessage , containing in data : measurements: deviceId, timestamp, linearVelocity, rotationalVelocity","title":"Output"},{"location":"nodes/","text":"Node-based app creation The R4A API allows for high-level application creation, using an enhanced FSM-like structure, denoting nodes and transitions. Abstract Node Class The main element of the R4A FSM-like app creation is the Node . All possible nodes must inherit from the TekNode class, and implement the following methods (with bold the methods which MUST be implemented): setParameters() : This method sets the proper parameters for a node to correctly operate parametersChecks() : Implements sanity, type or value checks for input parameters preempt() : Dictates how the node stops when preempted setStartingCondition(condition) : The node will start when the condition is true setNextNode(id, condition) : Sets a next node to transition to, based on a condition execute() : Just executes the node and returns the next node, based on the conditions set internalExecute() : Here add the node's core code Node executor Nodes are being executed in a serialized fashion, using a Node executor, i.e. objects of the NodeExecutor class. This class contains the following methods: __init__(exe_id) : Contructor, taking a unique id as input addNode(id, node) : Adds a node in the execution list, either by id or by reference (node object) setStartingNode(id) : Denotes the node id to start the execution with execute() : Just executes the node executor. The nodes are executed, based on their setNextNode given ids. threadedExecute() : Just initiates the execution in a thread An example of a node executor follows: #!/usr/bin/python # -*- coding: utf-8 -*- import sys import os import logging from r4a_apis.utilities import * from r4a_apis.tek_nodes import * from r4a_apis.robot_api import RobotAPI from r4a_apis.cloud_api import CloudAPI from r4a_apis.generic_api import GenericAPI try: log = Logger(allow_cutelog = True, level = logging.INFO) TekNode.logger = log TekNode.robot_api = RobotAPI(logger = log) TekNode.cloud_api = CloudAPI(memory = TekNode.robot_api.memory, logger = log) TekNode.generic_api = GenericAPI(memory = TekNode.robot_api.memory, logger = log) Condition.memory = TekNode.robot_api.memory Condition.logger = log InputMessage.logger = log OutputMessage.logger = log TekException.logger = log NodeExecutor.logger = log log.debug('main', \"Hey, app is starting\") nodes = {} nodes[0] = StartTekNode(0) nodes[1] = RobotMotionTekNode(1) nodes[1].setParameters(distance = None, duration = 5.0, direction = Directions.FORWARDS, speed = 0.2, type = MotionType.BASIC) nodes[2] = RobotTurnTekNode(2) nodes[2].setParameters(type = MotionType.BASIC, direction = Directions.RIGHT) nodes[3] = CameraMotionTekNode(3) nodes[3].setParameters(direction = Directions.NEUTRAL, yaw = None, pitch = None) nodes[4] = TalkTekNode(4) nodes[4].setParameters(language = Languages.EL, texts = [\"\u0393\u03b5\u03b9\u03b1 \u03c3\u03bf\u03c5\"], volume = 100) nodes[5] = RecordSoundTekNode(5) nodes[5].setParameters(name = \"Sound\", duration = 5.0) nodes[6] = ReplaySoundTekNode(6) nodes[6].setParameters(name = \"Sound\", volume = 100) nodes[7] = TurnLedsOnTekNode(7) nodes[7].setParameters(brightness = 100, color = Colors.WHITE) nodes[8] = TurnLedsOffTekNode(8) nodes[9] = StopTekNode(9) # Transitions nodes[0].setNextNode(id = 1) nodes[1].setNextNode(id = 2) nodes[2].setNextNode(id = 3) nodes[3].setNextNode(id = 4) nodes[4].setNextNode(id = 5) nodes[5].setNextNode(id = 6) nodes[6].setNextNode(id = 7) nodes[7].setNextNode(id = 8) nodes[8].setNextNode(id = 9) # Main execution main_executor = NodeExecutor(exe_id = 0) for i in nodes: main_executor.addNode(id = i, node = nodes[i]) main_executor.setStartingNode(id = 0) # Go for it main_executor.execute() log.debug('main', \"App is done\") except TekException: pass Next, the individual Nodes shall be presented. TekNodes \u2611 Camera motion Node Moves the pan-tilt servo motors on top of which is the camera. Code template: from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = CameraMotionTekNode(_id) n.setParameters(yaw = _yaw, pitch = _pitch, direction = _direction) n.execute() Parameters _id : Just an integer, denoting the id of the node. Must be unique. _yaw : Yaw angle in rads _pitch : Pitch angle in rads _direction : Direction of type DetectionType Low-level calls RobotAPI.movePanTilt Affected Redis variables None \u2611 Counter Node Implements a counter with a specific name. The first time this node's execute is called, the initial value is given. Each next time, it is increased by change_by . Code template: from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = CounterTekNode(_id) n.setParameters(name = _name, set_value = _set_value, change_by = _change_by) n.execute() Parameters _id : Just an integer, denoting the id of the node. Must be unique. _name : The name of the counter. Must be unique among the counters. _set_value : The initial value of the counter _change_by : The step to increase/decrease Low-level calls Counter API Affected Redis variables counters.NAME \u2611 Detect age Node Detects age using the camera. It captures an image, performs face detection and if a face is found it tries to detect its age. Code template: from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = DetectAgeTekNode(_id) n.execute() Parameters _id : Just an integer, denoting the id of the node. Must be unique. Low-level calls Age detection API Affected Redis variables variables.cloud.age variables.cloud.age.detected \u2611 Detect barcode Node Detects a barcode using the camera. Code template: from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = DetectBarcodeTekNode(_id) n.execute() Parameters _id : Just an integer, denoting the id of the node. Must be unique. Low-level calls QR/Barcode API Affected Redis variables variables.cloud.barcode.detected variables.cloud.barcode.text \u2611 Detect dominant color Node Captures an image and detects the dominant color in it. Code template: from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = DetectDominantColorTekNode(_id) n.execute() Parameters _id : Just an integer, denoting the id of the node. Must be unique. Low-level calls Dominant color API Affected Redis variables variables.cloud.detect_dominant_color.color variables.cloud.detect_dominant_color.raw \u2611 Detect face Node Detects human faces from camera. Code template: from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = DetectFaceTekNode(_id) n.setParameters(duration = _duration) n.execute() Parameters _id : Just an integer, denoting the id of the node. Must be unique. _duration : Amount of time to search for face Low-level calls Face detection API Affected Redis variables variables.cloud.detect_face.detected variables.cloud.detect_face.faces \u2611 Detect gender Node Detects human gender from camera. Code template: from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = DetectGenderTekNode(_id) n.execute() Parameters _id : Just an integer, denoting the id of the node. Must be unique. Low-level calls Gender detection API Affected Redis variables variables.cloud.gender variables.cloud.gender.detected Detect language from audio Node Captures an audio and detects the spoken language. Code template: from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = DetectLanguageFromAudioTekNode(_id) n.setParameters(duration = _duration) n.execute() Parameters _id : Just an integer, denoting the id of the node. Must be unique. _duration : Duration of the captured audio. Low-level calls Language detection Affected Redis variables variables.cloud.language_detection.audio Detect language from text Node Takes as input a string and outputs the language. Code template: from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = DetectLanguageFromTextTekNode(_id) n.setParameters(text = _text) n.execute() Parameters _id : Just an integer, denoting the id of the node. Must be unique. _text : The text for which language will be detected. Low-level calls Language detection Affected Redis variables variables.cloud.language_detection.text Detect motion Node Captures a series of frames and executes motion detection. Code template: from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = DetectMotionTekNode(_id) n.setParameters(duration = _duration) n.execute() Parameters _id : Just an integer, denoting the id of the node. Must be unique. _duration : Amount of time to capture a video in which the motion detection will be performed. Low-level calls Motion detection API Affected Redis variables variables.cloud.detect_motion.detected \u2611 Detect QR code Node Detects QR codes from the camera. Code template: from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = DetectQrCodeTekNode(_id) n.execute() Parameters _id : Just an integer, denoting the id of the node. Must be unique. Low-level calls QR detection Affected Redis variables variables.cloud.qr.detected variables.cloud.qr.text Detect sentiment from text Node Detects sentiment, having a string as input Code template: from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = DetectSentimentFromTextTekNode(_id) n.setParameters(text = _text) n.execute() Parameters _id : Just an integer, denoting the id of the node. Must be unique. _text : The text whose sentiment will be detected Low-level calls Sentiment detection API Affected Redis variables variables.cloud.detect_sentiment.detected variables.cloud.detect_sentiment.detected_sentiment variables.cloud.detect_sentiment.detected_sentiment.sound \u2611 Detect sound Node Captures audio and detects sound in it. Code template: from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = DetectSoundTekNode(_id) n.setParameters(duration = _duration) n.execute() Parameters _id : Just an integer, denoting the id of the node. Must be unique. _duration : Amount of time to record the sound in which to detect noise Low-level calls Sound detection API Affected Redis variables variables.cloud.detect_sound.detected \u2611 Detect touch Node Detects touch using the tactile sensors. Code template: from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = DetectTouchTekNode(_id) n.setParameters(parts = _parts, duration = _duration) n.execute() Parameters _id : Just an integer, denoting the id of the node. Must be unique. _parts : List of buttons or parts for touch detection. Must be of type Tactile enum _duration : Amount of time for the detection Low-level calls RobotAPI.getButtonChanges Affected Redis variables variables.robot.buttons.touch_detected variables.robot.buttons.pressed_part variables.robot.buttons.F variables.robot.buttons.FL variables.robot.buttons.FR variables.robot.buttons.B variables.robot.buttons.BR variables.robot.buttons.BL variables.robot.buttons.L variables.robot.buttons.R variables.robot.buttons.G1 variables.robot.buttons.G2 variables.robot.buttons.G3 variables.robot.buttons.G4 \u2611 Dice Node Probabilistically chooses next node. Code template: from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = DiceTekNode(_id) n.setNextNodeProbabilistic(_n_id_1, _weight_1) n.setNextNodeProbabilistic(_n_id_2, _weight_2) n.execute() Parameters _id : Just an integer, denoting the id of the node. Must be unique. _n_id_# : Id of the next node, with probability _weight_# Low-level calls None Affected Redis variables None \u2611 Display emotion Node Displays an emotion using the screen and leds. Code template: from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = DisplayEmotionTekNode(_id) n.setParameters(emotion = _emotion) n.execute() Parameters _id : Just an integer, denoting the id of the node. Must be unique. _emotion : A variable of type Sentiments enum Low-level calls RobotAPI.ledsColorWipe Affected Redis variables None \u2611 Get weather Gets the weather using an online API. Code template: from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = GetWeatherTekNode(_id) n.setParameters(location = _location, country = _country, report = _report) n.execute() Parameters _id : Just an integer, denoting the id of the node. Must be unique. _location : A location (e.g. a city) _country : An ISO 3166 country code Low-level calls Weather detection API Affected Redis variables variables.cloud.weather variables.cloud.weather.description variables.cloud.weather.temperature variables.cloud.weather.humidity variables.cloud.weather.pressure Learn emotion Node Learn an emotion using the touch screen. Code template: from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = LearnEmotionTekNode(_id) n.setParameters(name = _name) n.execute() Parameters _id : Just an integer, denoting the id of the node. Must be unique. _name : Name of the emotion to be learned. Must be unique among emotions. Low-level calls None Affected Redis variables None Learn Motion Node Learns a motion via the user. Code template: from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = LearnMotionTekNode(_id) n.setParameters(name = _name) n.execute() Parameters _id : Just an integer, denoting the id of the node. Must be unique. _name : Name of the motion to be learned. Must be unique among motions. Low-level calls None Affected Redis variables None Listen Node Listens for X seconds and tries to perform Speech to Text recognition, using a predefined dictionary. Code template: from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = ListenTekNode(_id) n.setParameters(duration = _duration, vocabulary = _vocabulary) n.execute() Parameters _id : Just an integer, denoting the id of the node. Must be unique. _duration : Duration to listen to command _vocabulary : A list of strings to perform speech detection from Low-level calls Speech-2-Text API \u2611 Preemption Node Preempts a number of executors , based on a condition. Code template: from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = PreemptorTekNode(_id) n.setParameters(preempt_executors = _execs, condition = _cond) n.execute() Parameters _id : Just an integer, denoting the id of the node. Must be unique. _execs : List of executors to preempt _cond : If this condition is valid, the _execs will be preempted. Must be of type Condition \u2611 Record sound Node Records an audio clip using the microphone. Code template: from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = RecordSoundTekNode(_id) n.setParameters(name = _name, duration = _dura, part = _part) n.execute() Parameters _id : Just an integer, denoting the id of the node. Must be unique. _name : A string denoting a name for the recorded sound _duration : Duration of the recording _part : A Tactile to be pressed for the recording to stop. Add None if this is not desired. Low-level calls RobotAPI.recordSound Affected Redis variables sounds.NAME \u2611 Replay sound Node Replays a sound, captured with a RecordSoundTekNode. Code template: from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = ReplaySoundTekNode(_id) n.setParameters(name = _name, volume = _volume) n.execute() Parameters _id : Just an integer, denoting the id of the node. Must be unique. _name : The name of the recorded sound to be played Low-level calls RobotAPI.replaySound \u2611 Robot motion Node Sets the motion of the robot's chassis. Code template: from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = RobotMotionTekNode(_id) n.setParameters(distance = _distance, duration = _duration, direction = _direction, linear = _linear, rotational = _rotational, type = _type, speed = _speed) n.execute() Parameters _id : Just an integer, denoting the id of the node. Must be unique. _distance : The distance to travel _duration : Amount of time to move _direction : Of type Directions enum _linear : Linear velocity (float) _rotational : Rotational velocity (float) _type : Motion type of type MotionType _speed : Float number denoting the motion speed The above parameters should be set with care, using the following combinations _type = MotionType.FOLLOW_LINE : Set only _speed _type = MotionType.BASIC : Set _direction and _speed . Also set either _distance or _duration . _type = MotionType.SPEED_BASED : Set _linear and _rotational . Also set either _distance or _duration . Low-level calls RobotAPI.moveBody \u2611 Robot turn Node Performs rotational motion of the robot's chassis. Code template: from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = RobotTurnTekNode(_id) n.setParameters(type = _type, angle = _angle, direction = _direction, speed = _speed, duration = _duration) n.execute() Parameters _id : Just an integer, denoting the id of the node. Must be unique. _type : Motion type of type MotionType _angle : Angle to turn in rads _direction : Of type Directions enum _speed : Float number denoting the motion speed _duration : Amount of time to move The above parameters should be set with care, using the following combinations _type = MotionType.BASIC : Set only _direction _type = MotionType.ANGLE_BASED : Set _angle and _speed . _type = MotionType.TIME_BASED : Set _duration and _speed . Low-level calls RobotAPI.moveBody \u2611 Sleep Node Just waits for a specific amount of time. Code template: from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = SleepTekNode(_id) n.setParameters(duration = _duration) n.execute() Parameters _id : Just an integer, denoting the id of the node. Must be unique. _duration : Amount of time to sleep Low-level calls Sleep API \u2611 Start Node The start node. Must exist in a single instance in one application. Code template: from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = StartTekNode(_id) n.execute() Parameters _id : Just an integer, denoting the id of the node. Must be unique. \u2611 Stop Node The terminal node. Must exist in each accepting/terminating state of the FSM/FSA. Code template: from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = StopTekNode(_id) n.execute() Parameters _id : Just an integer, denoting the id of the node. Must be unique. \u2611 Talk Node Makes the robot dictate a list of strings. Code template: from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = TalkTekNode(_id) n.setParameters(texts = _texts, language = _language, volume = _volume) n.execute() Parameters _id : Just an integer, denoting the id of the node. Must be unique. _texts : A list of strings to be spoken _language : A language code of type Languages _volume : Volume from 0 to 100 Low-level calls RobotAPI.speak \u2611 Threads Node Implements a threading execution, taking as input the Node executors , being the threads. Code template: from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = ThreadsTekNode(_id) n.setParameters(executors = _execs) n.execute() Parameters _id : Just an integer, denoting the id of the node. Must be unique. _execs : Ids of the executors to be started in parallel \u2611 Transition Node Just an empty node. Used for Go-to implementation. Code template: from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = TransitionTekNode(_id) n.execute() Parameters _id : Just an integer, denoting the id of the node. Must be unique. Translate from audio Node Captures an audio clip and translates it. Code template: from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = TranslateFromAudioTekNode(_id) n.setParameters(recording_time = _rec_time, source_lang = _s_lang, target_lang = _t_lang) n.execute() Parameters _id : Just an integer, denoting the id of the node. Must be unique. _rec_time : Time to record _s_lang : Language of the recording, of type Languages _t_lang : Target language, of type Languages Low-level calls Translate API Translate from text Node Translates a text. Code template: from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = TranslateFromTextTekNode(_id) n.setParameters(text = _text, source_lang = _s_lang, target_lang = _t_lang) n.execute() Parameters _id : Just an integer, denoting the id of the node. Must be unique. _text : Text to be translated _s_lang : Language of the text, of type Languages _t_lang : Target language, of type Languages Low-level calls Translate API \u2611 Turn leds off Node Turns off all leds of the robot. Code template: from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = TurnLedsOffTekNode(_id) n.execute() Parameters _id : Just an integer, denoting the id of the node. Must be unique. Low-level calls RobotAPI.ledsColorWipe \u2611 Turn leds on Node Turns leds on, having as input color and intensity. Code template: from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = TurnLedsOnTekNode(_id) n.execute(color = _color, brightness = _bright) Parameters _id : Just an integer, denoting the id of the node. Must be unique. _color : A color of type Colors _bright : Brightness between [0, 100] Low-level calls RobotAPI.ledsColorWipe","title":"FSM-like applications"},{"location":"nodes/#node-based-app-creation","text":"The R4A API allows for high-level application creation, using an enhanced FSM-like structure, denoting nodes and transitions.","title":"Node-based app creation"},{"location":"nodes/#abstract-node-class","text":"The main element of the R4A FSM-like app creation is the Node . All possible nodes must inherit from the TekNode class, and implement the following methods (with bold the methods which MUST be implemented): setParameters() : This method sets the proper parameters for a node to correctly operate parametersChecks() : Implements sanity, type or value checks for input parameters preempt() : Dictates how the node stops when preempted setStartingCondition(condition) : The node will start when the condition is true setNextNode(id, condition) : Sets a next node to transition to, based on a condition execute() : Just executes the node and returns the next node, based on the conditions set internalExecute() : Here add the node's core code","title":"Abstract Node Class"},{"location":"nodes/#node-executor","text":"Nodes are being executed in a serialized fashion, using a Node executor, i.e. objects of the NodeExecutor class. This class contains the following methods: __init__(exe_id) : Contructor, taking a unique id as input addNode(id, node) : Adds a node in the execution list, either by id or by reference (node object) setStartingNode(id) : Denotes the node id to start the execution with execute() : Just executes the node executor. The nodes are executed, based on their setNextNode given ids. threadedExecute() : Just initiates the execution in a thread An example of a node executor follows: #!/usr/bin/python # -*- coding: utf-8 -*- import sys import os import logging from r4a_apis.utilities import * from r4a_apis.tek_nodes import * from r4a_apis.robot_api import RobotAPI from r4a_apis.cloud_api import CloudAPI from r4a_apis.generic_api import GenericAPI try: log = Logger(allow_cutelog = True, level = logging.INFO) TekNode.logger = log TekNode.robot_api = RobotAPI(logger = log) TekNode.cloud_api = CloudAPI(memory = TekNode.robot_api.memory, logger = log) TekNode.generic_api = GenericAPI(memory = TekNode.robot_api.memory, logger = log) Condition.memory = TekNode.robot_api.memory Condition.logger = log InputMessage.logger = log OutputMessage.logger = log TekException.logger = log NodeExecutor.logger = log log.debug('main', \"Hey, app is starting\") nodes = {} nodes[0] = StartTekNode(0) nodes[1] = RobotMotionTekNode(1) nodes[1].setParameters(distance = None, duration = 5.0, direction = Directions.FORWARDS, speed = 0.2, type = MotionType.BASIC) nodes[2] = RobotTurnTekNode(2) nodes[2].setParameters(type = MotionType.BASIC, direction = Directions.RIGHT) nodes[3] = CameraMotionTekNode(3) nodes[3].setParameters(direction = Directions.NEUTRAL, yaw = None, pitch = None) nodes[4] = TalkTekNode(4) nodes[4].setParameters(language = Languages.EL, texts = [\"\u0393\u03b5\u03b9\u03b1 \u03c3\u03bf\u03c5\"], volume = 100) nodes[5] = RecordSoundTekNode(5) nodes[5].setParameters(name = \"Sound\", duration = 5.0) nodes[6] = ReplaySoundTekNode(6) nodes[6].setParameters(name = \"Sound\", volume = 100) nodes[7] = TurnLedsOnTekNode(7) nodes[7].setParameters(brightness = 100, color = Colors.WHITE) nodes[8] = TurnLedsOffTekNode(8) nodes[9] = StopTekNode(9) # Transitions nodes[0].setNextNode(id = 1) nodes[1].setNextNode(id = 2) nodes[2].setNextNode(id = 3) nodes[3].setNextNode(id = 4) nodes[4].setNextNode(id = 5) nodes[5].setNextNode(id = 6) nodes[6].setNextNode(id = 7) nodes[7].setNextNode(id = 8) nodes[8].setNextNode(id = 9) # Main execution main_executor = NodeExecutor(exe_id = 0) for i in nodes: main_executor.addNode(id = i, node = nodes[i]) main_executor.setStartingNode(id = 0) # Go for it main_executor.execute() log.debug('main', \"App is done\") except TekException: pass Next, the individual Nodes shall be presented.","title":"Node executor"},{"location":"nodes/#teknodes","text":"","title":"TekNodes"},{"location":"nodes/#camera-motion-node","text":"Moves the pan-tilt servo motors on top of which is the camera.","title":"\u2611 Camera motion Node"},{"location":"nodes/#code-template","text":"from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = CameraMotionTekNode(_id) n.setParameters(yaw = _yaw, pitch = _pitch, direction = _direction) n.execute()","title":"Code template:"},{"location":"nodes/#parameters","text":"_id : Just an integer, denoting the id of the node. Must be unique. _yaw : Yaw angle in rads _pitch : Pitch angle in rads _direction : Direction of type DetectionType","title":"Parameters"},{"location":"nodes/#low-level-calls","text":"RobotAPI.movePanTilt","title":"Low-level calls"},{"location":"nodes/#affected-redis-variables","text":"None","title":"Affected Redis variables"},{"location":"nodes/#counter-node","text":"Implements a counter with a specific name. The first time this node's execute is called, the initial value is given. Each next time, it is increased by change_by .","title":"\u2611 Counter Node"},{"location":"nodes/#code-template_1","text":"from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = CounterTekNode(_id) n.setParameters(name = _name, set_value = _set_value, change_by = _change_by) n.execute()","title":"Code template:"},{"location":"nodes/#parameters_1","text":"_id : Just an integer, denoting the id of the node. Must be unique. _name : The name of the counter. Must be unique among the counters. _set_value : The initial value of the counter _change_by : The step to increase/decrease","title":"Parameters"},{"location":"nodes/#low-level-calls_1","text":"Counter API","title":"Low-level calls"},{"location":"nodes/#affected-redis-variables_1","text":"counters.NAME","title":"Affected Redis variables"},{"location":"nodes/#detect-age-node","text":"Detects age using the camera. It captures an image, performs face detection and if a face is found it tries to detect its age.","title":"\u2611 Detect age Node"},{"location":"nodes/#code-template_2","text":"from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = DetectAgeTekNode(_id) n.execute()","title":"Code template:"},{"location":"nodes/#parameters_2","text":"_id : Just an integer, denoting the id of the node. Must be unique.","title":"Parameters"},{"location":"nodes/#low-level-calls_2","text":"Age detection API","title":"Low-level calls"},{"location":"nodes/#affected-redis-variables_2","text":"variables.cloud.age variables.cloud.age.detected","title":"Affected Redis variables"},{"location":"nodes/#detect-barcode-node","text":"Detects a barcode using the camera.","title":"\u2611 Detect barcode Node"},{"location":"nodes/#code-template_3","text":"from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = DetectBarcodeTekNode(_id) n.execute()","title":"Code template:"},{"location":"nodes/#parameters_3","text":"_id : Just an integer, denoting the id of the node. Must be unique.","title":"Parameters"},{"location":"nodes/#low-level-calls_3","text":"QR/Barcode API","title":"Low-level calls"},{"location":"nodes/#affected-redis-variables_3","text":"variables.cloud.barcode.detected variables.cloud.barcode.text","title":"Affected Redis variables"},{"location":"nodes/#detect-dominant-color-node","text":"Captures an image and detects the dominant color in it.","title":"\u2611 Detect dominant color Node"},{"location":"nodes/#code-template_4","text":"from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = DetectDominantColorTekNode(_id) n.execute()","title":"Code template:"},{"location":"nodes/#parameters_4","text":"_id : Just an integer, denoting the id of the node. Must be unique.","title":"Parameters"},{"location":"nodes/#low-level-calls_4","text":"Dominant color API","title":"Low-level calls"},{"location":"nodes/#affected-redis-variables_4","text":"variables.cloud.detect_dominant_color.color variables.cloud.detect_dominant_color.raw","title":"Affected Redis variables"},{"location":"nodes/#detect-face-node","text":"Detects human faces from camera.","title":"\u2611 Detect face Node"},{"location":"nodes/#code-template_5","text":"from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = DetectFaceTekNode(_id) n.setParameters(duration = _duration) n.execute()","title":"Code template:"},{"location":"nodes/#parameters_5","text":"_id : Just an integer, denoting the id of the node. Must be unique. _duration : Amount of time to search for face","title":"Parameters"},{"location":"nodes/#low-level-calls_5","text":"Face detection API","title":"Low-level calls"},{"location":"nodes/#affected-redis-variables_5","text":"variables.cloud.detect_face.detected variables.cloud.detect_face.faces","title":"Affected Redis variables"},{"location":"nodes/#detect-gender-node","text":"Detects human gender from camera.","title":"\u2611 Detect gender Node"},{"location":"nodes/#code-template_6","text":"from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = DetectGenderTekNode(_id) n.execute()","title":"Code template:"},{"location":"nodes/#parameters_6","text":"_id : Just an integer, denoting the id of the node. Must be unique.","title":"Parameters"},{"location":"nodes/#low-level-calls_6","text":"Gender detection API","title":"Low-level calls"},{"location":"nodes/#affected-redis-variables_6","text":"variables.cloud.gender variables.cloud.gender.detected","title":"Affected Redis variables"},{"location":"nodes/#detect-language-from-audio-node","text":"Captures an audio and detects the spoken language.","title":"Detect language from audio Node"},{"location":"nodes/#code-template_7","text":"from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = DetectLanguageFromAudioTekNode(_id) n.setParameters(duration = _duration) n.execute()","title":"Code template:"},{"location":"nodes/#parameters_7","text":"_id : Just an integer, denoting the id of the node. Must be unique. _duration : Duration of the captured audio.","title":"Parameters"},{"location":"nodes/#low-level-calls_7","text":"Language detection","title":"Low-level calls"},{"location":"nodes/#affected-redis-variables_7","text":"variables.cloud.language_detection.audio","title":"Affected Redis variables"},{"location":"nodes/#detect-language-from-text-node","text":"Takes as input a string and outputs the language.","title":"Detect language from text Node"},{"location":"nodes/#code-template_8","text":"from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = DetectLanguageFromTextTekNode(_id) n.setParameters(text = _text) n.execute()","title":"Code template:"},{"location":"nodes/#parameters_8","text":"_id : Just an integer, denoting the id of the node. Must be unique. _text : The text for which language will be detected.","title":"Parameters"},{"location":"nodes/#low-level-calls_8","text":"Language detection","title":"Low-level calls"},{"location":"nodes/#affected-redis-variables_8","text":"variables.cloud.language_detection.text","title":"Affected Redis variables"},{"location":"nodes/#detect-motion-node","text":"Captures a series of frames and executes motion detection.","title":"Detect motion Node"},{"location":"nodes/#code-template_9","text":"from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = DetectMotionTekNode(_id) n.setParameters(duration = _duration) n.execute()","title":"Code template:"},{"location":"nodes/#parameters_9","text":"_id : Just an integer, denoting the id of the node. Must be unique. _duration : Amount of time to capture a video in which the motion detection will be performed.","title":"Parameters"},{"location":"nodes/#low-level-calls_9","text":"Motion detection API","title":"Low-level calls"},{"location":"nodes/#affected-redis-variables_9","text":"variables.cloud.detect_motion.detected","title":"Affected Redis variables"},{"location":"nodes/#detect-qr-code-node","text":"Detects QR codes from the camera.","title":"\u2611 Detect QR code Node"},{"location":"nodes/#code-template_10","text":"from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = DetectQrCodeTekNode(_id) n.execute()","title":"Code template:"},{"location":"nodes/#parameters_10","text":"_id : Just an integer, denoting the id of the node. Must be unique.","title":"Parameters"},{"location":"nodes/#low-level-calls_10","text":"QR detection","title":"Low-level calls"},{"location":"nodes/#affected-redis-variables_10","text":"variables.cloud.qr.detected variables.cloud.qr.text","title":"Affected Redis variables"},{"location":"nodes/#detect-sentiment-from-text-node","text":"Detects sentiment, having a string as input","title":"Detect sentiment from text Node"},{"location":"nodes/#code-template_11","text":"from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = DetectSentimentFromTextTekNode(_id) n.setParameters(text = _text) n.execute()","title":"Code template:"},{"location":"nodes/#parameters_11","text":"_id : Just an integer, denoting the id of the node. Must be unique. _text : The text whose sentiment will be detected","title":"Parameters"},{"location":"nodes/#low-level-calls_11","text":"Sentiment detection API","title":"Low-level calls"},{"location":"nodes/#affected-redis-variables_11","text":"variables.cloud.detect_sentiment.detected variables.cloud.detect_sentiment.detected_sentiment variables.cloud.detect_sentiment.detected_sentiment.sound","title":"Affected Redis variables"},{"location":"nodes/#detect-sound-node","text":"Captures audio and detects sound in it.","title":"\u2611 Detect sound Node"},{"location":"nodes/#code-template_12","text":"from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = DetectSoundTekNode(_id) n.setParameters(duration = _duration) n.execute()","title":"Code template:"},{"location":"nodes/#parameters_12","text":"_id : Just an integer, denoting the id of the node. Must be unique. _duration : Amount of time to record the sound in which to detect noise","title":"Parameters"},{"location":"nodes/#low-level-calls_12","text":"Sound detection API","title":"Low-level calls"},{"location":"nodes/#affected-redis-variables_12","text":"variables.cloud.detect_sound.detected","title":"Affected Redis variables"},{"location":"nodes/#detect-touch-node","text":"Detects touch using the tactile sensors.","title":"\u2611 Detect touch Node"},{"location":"nodes/#code-template_13","text":"from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = DetectTouchTekNode(_id) n.setParameters(parts = _parts, duration = _duration) n.execute()","title":"Code template:"},{"location":"nodes/#parameters_13","text":"_id : Just an integer, denoting the id of the node. Must be unique. _parts : List of buttons or parts for touch detection. Must be of type Tactile enum _duration : Amount of time for the detection","title":"Parameters"},{"location":"nodes/#low-level-calls_13","text":"RobotAPI.getButtonChanges","title":"Low-level calls"},{"location":"nodes/#affected-redis-variables_13","text":"variables.robot.buttons.touch_detected variables.robot.buttons.pressed_part variables.robot.buttons.F variables.robot.buttons.FL variables.robot.buttons.FR variables.robot.buttons.B variables.robot.buttons.BR variables.robot.buttons.BL variables.robot.buttons.L variables.robot.buttons.R variables.robot.buttons.G1 variables.robot.buttons.G2 variables.robot.buttons.G3 variables.robot.buttons.G4","title":"Affected Redis variables"},{"location":"nodes/#dice-node","text":"Probabilistically chooses next node.","title":"\u2611 Dice Node"},{"location":"nodes/#code-template_14","text":"from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = DiceTekNode(_id) n.setNextNodeProbabilistic(_n_id_1, _weight_1) n.setNextNodeProbabilistic(_n_id_2, _weight_2) n.execute()","title":"Code template:"},{"location":"nodes/#parameters_14","text":"_id : Just an integer, denoting the id of the node. Must be unique. _n_id_# : Id of the next node, with probability _weight_#","title":"Parameters"},{"location":"nodes/#low-level-calls_14","text":"None","title":"Low-level calls"},{"location":"nodes/#affected-redis-variables_14","text":"None","title":"Affected Redis variables"},{"location":"nodes/#display-emotion-node","text":"Displays an emotion using the screen and leds.","title":"\u2611 Display emotion Node"},{"location":"nodes/#code-template_15","text":"from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = DisplayEmotionTekNode(_id) n.setParameters(emotion = _emotion) n.execute()","title":"Code template:"},{"location":"nodes/#parameters_15","text":"_id : Just an integer, denoting the id of the node. Must be unique. _emotion : A variable of type Sentiments enum","title":"Parameters"},{"location":"nodes/#low-level-calls_15","text":"RobotAPI.ledsColorWipe","title":"Low-level calls"},{"location":"nodes/#affected-redis-variables_15","text":"None","title":"Affected Redis variables"},{"location":"nodes/#get-weather","text":"Gets the weather using an online API.","title":"\u2611 Get weather"},{"location":"nodes/#code-template_16","text":"from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = GetWeatherTekNode(_id) n.setParameters(location = _location, country = _country, report = _report) n.execute()","title":"Code template:"},{"location":"nodes/#parameters_16","text":"_id : Just an integer, denoting the id of the node. Must be unique. _location : A location (e.g. a city) _country : An ISO 3166 country code","title":"Parameters"},{"location":"nodes/#low-level-calls_16","text":"Weather detection API","title":"Low-level calls"},{"location":"nodes/#affected-redis-variables_16","text":"variables.cloud.weather variables.cloud.weather.description variables.cloud.weather.temperature variables.cloud.weather.humidity variables.cloud.weather.pressure","title":"Affected Redis variables"},{"location":"nodes/#learn-emotion-node","text":"Learn an emotion using the touch screen.","title":"Learn emotion Node"},{"location":"nodes/#code-template_17","text":"from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = LearnEmotionTekNode(_id) n.setParameters(name = _name) n.execute()","title":"Code template:"},{"location":"nodes/#parameters_17","text":"_id : Just an integer, denoting the id of the node. Must be unique. _name : Name of the emotion to be learned. Must be unique among emotions.","title":"Parameters"},{"location":"nodes/#low-level-calls_17","text":"None","title":"Low-level calls"},{"location":"nodes/#affected-redis-variables_17","text":"None","title":"Affected Redis variables"},{"location":"nodes/#learn-motion-node","text":"Learns a motion via the user.","title":"Learn Motion Node"},{"location":"nodes/#code-template_18","text":"from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = LearnMotionTekNode(_id) n.setParameters(name = _name) n.execute()","title":"Code template:"},{"location":"nodes/#parameters_18","text":"_id : Just an integer, denoting the id of the node. Must be unique. _name : Name of the motion to be learned. Must be unique among motions.","title":"Parameters"},{"location":"nodes/#low-level-calls_18","text":"None","title":"Low-level calls"},{"location":"nodes/#affected-redis-variables_18","text":"None","title":"Affected Redis variables"},{"location":"nodes/#listen-node","text":"Listens for X seconds and tries to perform Speech to Text recognition, using a predefined dictionary.","title":"Listen Node"},{"location":"nodes/#code-template_19","text":"from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = ListenTekNode(_id) n.setParameters(duration = _duration, vocabulary = _vocabulary) n.execute()","title":"Code template:"},{"location":"nodes/#parameters_19","text":"_id : Just an integer, denoting the id of the node. Must be unique. _duration : Duration to listen to command _vocabulary : A list of strings to perform speech detection from","title":"Parameters"},{"location":"nodes/#low-level-calls_19","text":"Speech-2-Text API","title":"Low-level calls"},{"location":"nodes/#preemption-node","text":"Preempts a number of executors , based on a condition.","title":"\u2611 Preemption Node"},{"location":"nodes/#code-template_20","text":"from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = PreemptorTekNode(_id) n.setParameters(preempt_executors = _execs, condition = _cond) n.execute()","title":"Code template:"},{"location":"nodes/#parameters_20","text":"_id : Just an integer, denoting the id of the node. Must be unique. _execs : List of executors to preempt _cond : If this condition is valid, the _execs will be preempted. Must be of type Condition","title":"Parameters"},{"location":"nodes/#record-sound-node","text":"Records an audio clip using the microphone.","title":"\u2611 Record sound Node"},{"location":"nodes/#code-template_21","text":"from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = RecordSoundTekNode(_id) n.setParameters(name = _name, duration = _dura, part = _part) n.execute()","title":"Code template:"},{"location":"nodes/#parameters_21","text":"_id : Just an integer, denoting the id of the node. Must be unique. _name : A string denoting a name for the recorded sound _duration : Duration of the recording _part : A Tactile to be pressed for the recording to stop. Add None if this is not desired.","title":"Parameters"},{"location":"nodes/#low-level-calls_20","text":"RobotAPI.recordSound","title":"Low-level calls"},{"location":"nodes/#affected-redis-variables_19","text":"sounds.NAME","title":"Affected Redis variables"},{"location":"nodes/#replay-sound-node","text":"Replays a sound, captured with a RecordSoundTekNode.","title":"\u2611 Replay sound Node"},{"location":"nodes/#code-template_22","text":"from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = ReplaySoundTekNode(_id) n.setParameters(name = _name, volume = _volume) n.execute()","title":"Code template:"},{"location":"nodes/#parameters_22","text":"_id : Just an integer, denoting the id of the node. Must be unique. _name : The name of the recorded sound to be played","title":"Parameters"},{"location":"nodes/#low-level-calls_21","text":"RobotAPI.replaySound","title":"Low-level calls"},{"location":"nodes/#robot-motion-node","text":"Sets the motion of the robot's chassis.","title":"\u2611 Robot motion Node"},{"location":"nodes/#code-template_23","text":"from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = RobotMotionTekNode(_id) n.setParameters(distance = _distance, duration = _duration, direction = _direction, linear = _linear, rotational = _rotational, type = _type, speed = _speed) n.execute()","title":"Code template:"},{"location":"nodes/#parameters_23","text":"_id : Just an integer, denoting the id of the node. Must be unique. _distance : The distance to travel _duration : Amount of time to move _direction : Of type Directions enum _linear : Linear velocity (float) _rotational : Rotational velocity (float) _type : Motion type of type MotionType _speed : Float number denoting the motion speed The above parameters should be set with care, using the following combinations _type = MotionType.FOLLOW_LINE : Set only _speed _type = MotionType.BASIC : Set _direction and _speed . Also set either _distance or _duration . _type = MotionType.SPEED_BASED : Set _linear and _rotational . Also set either _distance or _duration .","title":"Parameters"},{"location":"nodes/#low-level-calls_22","text":"RobotAPI.moveBody","title":"Low-level calls"},{"location":"nodes/#robot-turn-node","text":"Performs rotational motion of the robot's chassis.","title":"\u2611 Robot turn Node"},{"location":"nodes/#code-template_24","text":"from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = RobotTurnTekNode(_id) n.setParameters(type = _type, angle = _angle, direction = _direction, speed = _speed, duration = _duration) n.execute()","title":"Code template:"},{"location":"nodes/#parameters_24","text":"_id : Just an integer, denoting the id of the node. Must be unique. _type : Motion type of type MotionType _angle : Angle to turn in rads _direction : Of type Directions enum _speed : Float number denoting the motion speed _duration : Amount of time to move The above parameters should be set with care, using the following combinations _type = MotionType.BASIC : Set only _direction _type = MotionType.ANGLE_BASED : Set _angle and _speed . _type = MotionType.TIME_BASED : Set _duration and _speed .","title":"Parameters"},{"location":"nodes/#low-level-calls_23","text":"RobotAPI.moveBody","title":"Low-level calls"},{"location":"nodes/#sleep-node","text":"Just waits for a specific amount of time.","title":"\u2611 Sleep Node"},{"location":"nodes/#code-template_25","text":"from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = SleepTekNode(_id) n.setParameters(duration = _duration) n.execute()","title":"Code template:"},{"location":"nodes/#parameters_25","text":"_id : Just an integer, denoting the id of the node. Must be unique. _duration : Amount of time to sleep","title":"Parameters"},{"location":"nodes/#low-level-calls_24","text":"Sleep API","title":"Low-level calls"},{"location":"nodes/#start-node","text":"The start node. Must exist in a single instance in one application.","title":"\u2611 Start Node"},{"location":"nodes/#code-template_26","text":"from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = StartTekNode(_id) n.execute()","title":"Code template:"},{"location":"nodes/#parameters_26","text":"_id : Just an integer, denoting the id of the node. Must be unique.","title":"Parameters"},{"location":"nodes/#stop-node","text":"The terminal node. Must exist in each accepting/terminating state of the FSM/FSA.","title":"\u2611 Stop Node"},{"location":"nodes/#code-template_27","text":"from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = StopTekNode(_id) n.execute()","title":"Code template:"},{"location":"nodes/#parameters_27","text":"_id : Just an integer, denoting the id of the node. Must be unique.","title":"Parameters"},{"location":"nodes/#talk-node","text":"Makes the robot dictate a list of strings.","title":"\u2611 Talk Node"},{"location":"nodes/#code-template_28","text":"from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = TalkTekNode(_id) n.setParameters(texts = _texts, language = _language, volume = _volume) n.execute()","title":"Code template:"},{"location":"nodes/#parameters_28","text":"_id : Just an integer, denoting the id of the node. Must be unique. _texts : A list of strings to be spoken _language : A language code of type Languages _volume : Volume from 0 to 100","title":"Parameters"},{"location":"nodes/#low-level-calls_25","text":"RobotAPI.speak","title":"Low-level calls"},{"location":"nodes/#threads-node","text":"Implements a threading execution, taking as input the Node executors , being the threads.","title":"\u2611 Threads Node"},{"location":"nodes/#code-template_29","text":"from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = ThreadsTekNode(_id) n.setParameters(executors = _execs) n.execute()","title":"Code template:"},{"location":"nodes/#parameters_29","text":"_id : Just an integer, denoting the id of the node. Must be unique. _execs : Ids of the executors to be started in parallel","title":"Parameters"},{"location":"nodes/#transition-node","text":"Just an empty node. Used for Go-to implementation.","title":"\u2611 Transition Node"},{"location":"nodes/#code-template_30","text":"from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = TransitionTekNode(_id) n.execute()","title":"Code template:"},{"location":"nodes/#parameters_30","text":"_id : Just an integer, denoting the id of the node. Must be unique.","title":"Parameters"},{"location":"nodes/#translate-from-audio-node","text":"Captures an audio clip and translates it.","title":"Translate from audio Node"},{"location":"nodes/#code-template_31","text":"from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = TranslateFromAudioTekNode(_id) n.setParameters(recording_time = _rec_time, source_lang = _s_lang, target_lang = _t_lang) n.execute()","title":"Code template:"},{"location":"nodes/#parameters_31","text":"_id : Just an integer, denoting the id of the node. Must be unique. _rec_time : Time to record _s_lang : Language of the recording, of type Languages _t_lang : Target language, of type Languages","title":"Parameters"},{"location":"nodes/#low-level-calls_26","text":"Translate API","title":"Low-level calls"},{"location":"nodes/#translate-from-text-node","text":"Translates a text.","title":"Translate from text Node"},{"location":"nodes/#code-template_32","text":"from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = TranslateFromTextTekNode(_id) n.setParameters(text = _text, source_lang = _s_lang, target_lang = _t_lang) n.execute()","title":"Code template:"},{"location":"nodes/#parameters_32","text":"_id : Just an integer, denoting the id of the node. Must be unique. _text : Text to be translated _s_lang : Language of the text, of type Languages _t_lang : Target language, of type Languages","title":"Parameters"},{"location":"nodes/#low-level-calls_27","text":"Translate API","title":"Low-level calls"},{"location":"nodes/#turn-leds-off-node","text":"Turns off all leds of the robot.","title":"\u2611 Turn leds off Node"},{"location":"nodes/#code-template_33","text":"from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = TurnLedsOffTekNode(_id) n.execute()","title":"Code template:"},{"location":"nodes/#parameters_33","text":"_id : Just an integer, denoting the id of the node. Must be unique.","title":"Parameters"},{"location":"nodes/#low-level-calls_28","text":"RobotAPI.ledsColorWipe","title":"Low-level calls"},{"location":"nodes/#turn-leds-on-node","text":"Turns leds on, having as input color and intensity.","title":"\u2611 Turn leds on Node"},{"location":"nodes/#code-template_34","text":"from r4a_apis.utilities import * from r4a_apis.tek_nodes import * n = TurnLedsOnTekNode(_id) n.execute(color = _color, brightness = _bright)","title":"Code template:"},{"location":"nodes/#parameters_34","text":"_id : Just an integer, denoting the id of the node. Must be unique. _color : A color of type Colors _bright : Brightness between [0, 100]","title":"Parameters"},{"location":"nodes/#low-level-calls_29","text":"RobotAPI.ledsColorWipe","title":"Low-level calls"},{"location":"pantilt/","text":"Pan-tilt API RobotAPI . getPanTilt Gets Pan/Tilt angles from memory. Input parameters An InputMessage , containing in data : deviceId : The id of a Devices.PAN_TILT device fromIndex : From what index the data will be retrieved toIndex : To what index the data will be retrieved Output An OutputMessage , containing in data : measurements: deviceId, timestamp, yaw, pitch RobotAPI . movePanTilt Sets angles for the pan/tilt system Input parameters An InputMessage , containing in data : deviceId : The id of a Devices.PAN_TILT device yaw : The desired yaw angle pitch : The desired pitch angle Output Physical: The pan-tilt mechanism moves to the desired angles.","title":"Pan-tilt API"},{"location":"pantilt/#pan-tilt-api","text":"","title":"Pan-tilt API"},{"location":"pantilt/#robotapigetpantilt","text":"Gets Pan/Tilt angles from memory.","title":"RobotAPI.getPanTilt"},{"location":"pantilt/#input-parameters","text":"An InputMessage , containing in data : deviceId : The id of a Devices.PAN_TILT device fromIndex : From what index the data will be retrieved toIndex : To what index the data will be retrieved","title":"Input parameters"},{"location":"pantilt/#output","text":"An OutputMessage , containing in data : measurements: deviceId, timestamp, yaw, pitch","title":"Output"},{"location":"pantilt/#robotapimovepantilt","text":"Sets angles for the pan/tilt system","title":"RobotAPI.movePanTilt"},{"location":"pantilt/#input-parameters_1","text":"An InputMessage , containing in data : deviceId : The id of a Devices.PAN_TILT device yaw : The desired yaw angle pitch : The desired pitch angle","title":"Input parameters"},{"location":"pantilt/#output_1","text":"Physical: The pan-tilt mechanism moves to the desired angles.","title":"Output"},{"location":"resources/","text":"Enabling resources In order to use a resource, you must enable it. The easier way to do this is via the devicesObj object, that exists in a RobotAPI object. Specifically there is a function called enableDevicesType , that takes as input a Device and activates all respective devices. For example, if we were to enable all microphones, we would write: import utilities import robot_api r = robot_api.RobotAPI() r.devicesObj.enableDevicesType(Devices.MICROPHONE)","title":"Enabling resources"},{"location":"resources/#enabling-resources","text":"In order to use a resource, you must enable it. The easier way to do this is via the devicesObj object, that exists in a RobotAPI object. Specifically there is a function called enableDevicesType , that takes as input a Device and activates all respective devices. For example, if we were to enable all microphones, we would write: import utilities import robot_api r = robot_api.RobotAPI() r.devicesObj.enableDevicesType(Devices.MICROPHONE)","title":"Enabling resources"},{"location":"robotapi/","text":"The RobotAPI Robot API offers services / calls, with which you can manipulate the robot/device. As explained here , all calls get an InputMessage as input and an OutputMessage as output. The contents of this section are: Enabling resources Speakers API Microphone API Camera API Touch screen API LEDs API Buttons API Environmental API Encoders API Line follower API Time-of-flight API Sonars API Infrared API Pan-tilt API Body motion API IMU API","title":"General"},{"location":"robotapi/#the-robotapi","text":"Robot API offers services / calls, with which you can manipulate the robot/device. As explained here , all calls get an InputMessage as input and an OutputMessage as output. The contents of this section are: Enabling resources Speakers API Microphone API Camera API Touch screen API LEDs API Buttons API Environmental API Encoders API Line follower API Time-of-flight API Sonars API Infrared API Pan-tilt API Body motion API IMU API","title":"The RobotAPI"},{"location":"sonars/","text":"Sonars API RobotAPI . getSonarMeasurement Gets Sonar sensors distance measurements from memory. Input parameters An InputMessage , containing in data : deviceId : The id of a Devices.SONAR device fromIndex : From what index the data will be retrieved toIndex : To what index the data will be retrieved Output An OutputMessage , containing in data : measurements: deviceId, timestamp, value","title":"Sonars API"},{"location":"sonars/#sonars-api","text":"","title":"Sonars API"},{"location":"sonars/#robotapigetsonarmeasurement","text":"Gets Sonar sensors distance measurements from memory.","title":"RobotAPI.getSonarMeasurement"},{"location":"sonars/#input-parameters","text":"An InputMessage , containing in data : deviceId : The id of a Devices.SONAR device fromIndex : From what index the data will be retrieved toIndex : To what index the data will be retrieved","title":"Input parameters"},{"location":"sonars/#output","text":"An OutputMessage , containing in data : measurements: deviceId, timestamp, value","title":"Output"},{"location":"speakers/","text":"Speakers API RobotAPI . speak A text-to-speech algorithm is used, in order for the device to \"speak\" in different languages. Input arguments texts : A list of arguments. These may be strings or TekVariables volume : The volume from 0 to 100 language : A Language Output / Variables This call has no output and does not change any TekVariables. Examples import robot_api import utilities rapi = robot_api.RobotAPI() out = rapi.speak(utilities.InputMessage({ 'texts': ['the number', 'is', utilities.TekVariables.SLEEP_DURATION], 'volume': 100, 'language': utilities.Languages.EN })) RobotAPI . replaySound This call reproduces a sound from the speakers. The sound can either be a wav file, or a base64-encoded string. Input arguments is_file : True if we want to play a file, false if we have a raw base64 string string : Either the absolute path of the file, or the base64 string. volume : The volume from 0 to 100 Output / Variables This call has no output and does not change any TekVariables . Examples import robot_api import utilities rapi = robot_api.RobotAPI() out = rapi.replaySound(utilities.InputMessage({ 'is_file': True, 'string': '/tmp/tmp.wav', 'volume': 100 })) RobotAPI . getSound Retrieves a soud file from memory, using a specific speaker. Input arguments deviceId : The id of a Devices.SPEAKERS device fromIndex : From what index the data will be retrieved toIndex : To what index the data will be retrieved Output / Variables Returns an OutputMessage , of the following datframe: measurements: [ deviceId timestamp is_file file volume ]","title":"Speakers API"},{"location":"speakers/#speakers-api","text":"","title":"Speakers API"},{"location":"speakers/#robotapispeak","text":"A text-to-speech algorithm is used, in order for the device to \"speak\" in different languages.","title":"RobotAPI.speak"},{"location":"speakers/#input-arguments","text":"texts : A list of arguments. These may be strings or TekVariables volume : The volume from 0 to 100 language : A Language","title":"Input arguments"},{"location":"speakers/#output-variables","text":"This call has no output and does not change any TekVariables.","title":"Output / Variables"},{"location":"speakers/#examples","text":"import robot_api import utilities rapi = robot_api.RobotAPI() out = rapi.speak(utilities.InputMessage({ 'texts': ['the number', 'is', utilities.TekVariables.SLEEP_DURATION], 'volume': 100, 'language': utilities.Languages.EN }))","title":"Examples"},{"location":"speakers/#robotapireplaysound","text":"This call reproduces a sound from the speakers. The sound can either be a wav file, or a base64-encoded string.","title":"RobotAPI.replaySound"},{"location":"speakers/#input-arguments_1","text":"is_file : True if we want to play a file, false if we have a raw base64 string string : Either the absolute path of the file, or the base64 string. volume : The volume from 0 to 100","title":"Input arguments"},{"location":"speakers/#output-variables_1","text":"This call has no output and does not change any TekVariables .","title":"Output / Variables"},{"location":"speakers/#examples_1","text":"import robot_api import utilities rapi = robot_api.RobotAPI() out = rapi.replaySound(utilities.InputMessage({ 'is_file': True, 'string': '/tmp/tmp.wav', 'volume': 100 }))","title":"Examples"},{"location":"speakers/#robotapigetsound","text":"Retrieves a soud file from memory, using a specific speaker.","title":"RobotAPI.getSound"},{"location":"speakers/#input-arguments_2","text":"deviceId : The id of a Devices.SPEAKERS device fromIndex : From what index the data will be retrieved toIndex : To what index the data will be retrieved","title":"Input arguments"},{"location":"speakers/#output-variables_2","text":"Returns an OutputMessage , of the following datframe: measurements: [ deviceId timestamp is_file file volume ]","title":"Output / Variables"},{"location":"tof/","text":"Time-of-flight API RobotAPI . getToFMeasurement Gets Time-Of-Flight sensors distance measurements from memory. Input parameters An InputMessage , containing in data : deviceId : The id of a Devices.TOF device fromIndex : From what index the data will be retrieved toIndex : To what index the data will be retrieved Output An OutputMessage , containing in data : measurements: deviceId, timestamp, value","title":"Time-of-flight API"},{"location":"tof/#time-of-flight-api","text":"","title":"Time-of-flight API"},{"location":"tof/#robotapigettofmeasurement","text":"Gets Time-Of-Flight sensors distance measurements from memory.","title":"RobotAPI.getToFMeasurement"},{"location":"tof/#input-parameters","text":"An InputMessage , containing in data : deviceId : The id of a Devices.TOF device fromIndex : From what index the data will be retrieved toIndex : To what index the data will be retrieved","title":"Input parameters"},{"location":"tof/#output","text":"An OutputMessage , containing in data : measurements: deviceId, timestamp, value","title":"Output"},{"location":"touchscreen/","text":"Touch screen API RobotAPI . showImage Shows an image in touch screen Input arguments image : The image as base64 string width : The width of the captured image height : The height of the captured image duration : How many seconds the image will be shown touch : True if touches are accepted. Output / Variables Returns an OutputMessage containing the following data: { 'reaction_time': The reaction time - time between the display and the touch, 'selected': None } Examples import robot_api import utilities rapi = robot_api.RobotAPI() out = rapi.captureImage(utilities.InputMessage({ 'width': 800, 'height': 480, 'save_file_url': None })) out.print() out = rapi.showImage(utilities.InputMessage({ 'image': out.data['image'], 'width': out.data['width'], 'height': out.data['height'], 'duration': 10, 'touch': True })) out.print() RobotAPI . showOptions Shows up to 4 options in the touch screen and waits for a touch. Input arguments options : A list of strings duration : For how much time the options will wait for touch Output / Variables Returns an OutputMessage containing the following data: { 'reaction_time': The reaction time - time between the display and the touch, 'selected': The option selected (as string) } Examples An InputMessage as such: import robot_api import utilities rapi = robot_api.RobotAPI() out = rapi.showOptions(utilities.InputMessage({ 'options': ['Option 1', 'Option 2'], 'duration': 5 })) out.print() RobotAPI . showColor Input arguments color : duration : For how much time the color will wait for touch Output / Variables { 'reaction_time': The reaction time - time between the display and the touch, 'selected': The option selected (as string) } Examples import robot_api import utilities rapi = robot_api.RobotAPI() out = rapi.showColor(utilities.InputMessage({ 'color': utilities.Colors.GREEN.value, 'duration': 5 })) out.print()","title":"Touch screen API"},{"location":"touchscreen/#touch-screen-api","text":"","title":"Touch screen API"},{"location":"touchscreen/#robotapishowimage","text":"Shows an image in touch screen","title":"RobotAPI.showImage"},{"location":"touchscreen/#input-arguments","text":"image : The image as base64 string width : The width of the captured image height : The height of the captured image duration : How many seconds the image will be shown touch : True if touches are accepted.","title":"Input arguments"},{"location":"touchscreen/#output-variables","text":"Returns an OutputMessage containing the following data: { 'reaction_time': The reaction time - time between the display and the touch, 'selected': None }","title":"Output / Variables"},{"location":"touchscreen/#examples","text":"import robot_api import utilities rapi = robot_api.RobotAPI() out = rapi.captureImage(utilities.InputMessage({ 'width': 800, 'height': 480, 'save_file_url': None })) out.print() out = rapi.showImage(utilities.InputMessage({ 'image': out.data['image'], 'width': out.data['width'], 'height': out.data['height'], 'duration': 10, 'touch': True })) out.print()","title":"Examples"},{"location":"touchscreen/#robotapishowoptions","text":"Shows up to 4 options in the touch screen and waits for a touch.","title":"RobotAPI.showOptions"},{"location":"touchscreen/#input-arguments_1","text":"options : A list of strings duration : For how much time the options will wait for touch","title":"Input arguments"},{"location":"touchscreen/#output-variables_1","text":"Returns an OutputMessage containing the following data: { 'reaction_time': The reaction time - time between the display and the touch, 'selected': The option selected (as string) }","title":"Output / Variables"},{"location":"touchscreen/#examples_1","text":"An InputMessage as such: import robot_api import utilities rapi = robot_api.RobotAPI() out = rapi.showOptions(utilities.InputMessage({ 'options': ['Option 1', 'Option 2'], 'duration': 5 })) out.print()","title":"Examples"},{"location":"touchscreen/#robotapishowcolor","text":"","title":"RobotAPI.showColor"},{"location":"touchscreen/#input-arguments_2","text":"color : duration : For how much time the color will wait for touch","title":"Input arguments"},{"location":"touchscreen/#output-variables_2","text":"{ 'reaction_time': The reaction time - time between the display and the touch, 'selected': The option selected (as string) }","title":"Output / Variables"},{"location":"touchscreen/#examples_2","text":"import robot_api import utilities rapi = robot_api.RobotAPI() out = rapi.showColor(utilities.InputMessage({ 'color': utilities.Colors.GREEN.value, 'duration': 5 })) out.print()","title":"Examples"}]}