{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome! Welcome to R4A APIs! From here you can write applications that use a device's hardware, cloud services and generic functionalities. This is possible via the three distinct APIs (Robot, Cloud and Generic). Furthermore, you can write higher-level apps (FSM-like) using the TekNodes module. In this documentation you may find: Utilities: Various stuff, useful for writing applications. These are: Exceptions : How to capture exceptions from services/API calls. Messages : How to give input and take output from services/API calls. Memory : How to store and retrieve variables/data from device memory Conditions : How to create conditions that use variables or constants Enumerations : What variables and enumerations are available Robot API : Calls to manipulate Robots and Devices Cloud API : Calls to get information from cloud services Generic API : Generic functionality like delays etc. FSM-like applications : How to write applications using an FSM-like way Examples : Various examples Have a nice reading ;)","title":"Home"},{"location":"#welcome","text":"Welcome to R4A APIs! From here you can write applications that use a device's hardware, cloud services and generic functionalities. This is possible via the three distinct APIs (Robot, Cloud and Generic). Furthermore, you can write higher-level apps (FSM-like) using the TekNodes module. In this documentation you may find: Utilities: Various stuff, useful for writing applications. These are: Exceptions : How to capture exceptions from services/API calls. Messages : How to give input and take output from services/API calls. Memory : How to store and retrieve variables/data from device memory Conditions : How to create conditions that use variables or constants Enumerations : What variables and enumerations are available Robot API : Calls to manipulate Robots and Devices Cloud API : Calls to get information from cloud services Generic API : Generic functionality like delays etc. FSM-like applications : How to write applications using an FSM-like way Examples : Various examples Have a nice reading ;)","title":"Welcome!"},{"location":"buttons/","text":"Buttons API RobotAPI . getButtonChanges","title":"Buttons API"},{"location":"buttons/#buttons-api","text":"","title":"Buttons API"},{"location":"buttons/#robotapigetbuttonchanges","text":"","title":"RobotAPI.getButtonChanges"},{"location":"camera/","text":"Camera API RobotAPI . captureImage This call captures an image from the camera. Input arguments width : Desired width of captured image height : Desired height of captured image save_file_url : An absolute path for the image to be saved. If None , the image is not saved. Output / Variables The call returns an OutputMessage with the following data: deviceId : the id of the device, timestamp : the timestamp of the capture, image : the image as base 64 string, width : the width of the captured image, height : the height of the captured image, format : usually rgb , per_rows : True if stored by rows or by columns Examples import robot_api import utilities rapi = robot_api.RobotAPI() out = rapi.captureImage(utilities.InputMessage({ 'width': 800, 'height': 480, 'save_file_url': '/tmp/file.jpg' })) out.print() RobotAPI . getImages Retrieves images from memory. Input arguments fromIndex : The most recent index toIndex : The oldest index Output / Variables An OutputMessage as such: { 'measurements': [ { 'deviceId': ID, 'timestamp': 0, 'image': \"as base64 string format\", 'width': 0, 'height': 0, 'format': 'rgb', 'per_rows': True # If stored by rows or by columns }, ... ] } Examples import robot_api import utilities rapi = robot_api.RobotAPI() out = rapi.getImages(utilities.InputMessage({ 'fromIndex': 0, 'toIndex': 0 }))","title":"Camera API"},{"location":"camera/#camera-api","text":"","title":"Camera API"},{"location":"camera/#robotapicaptureimage","text":"This call captures an image from the camera.","title":"RobotAPI.captureImage"},{"location":"camera/#input-arguments","text":"width : Desired width of captured image height : Desired height of captured image save_file_url : An absolute path for the image to be saved. If None , the image is not saved.","title":"Input arguments"},{"location":"camera/#output-variables","text":"The call returns an OutputMessage with the following data: deviceId : the id of the device, timestamp : the timestamp of the capture, image : the image as base 64 string, width : the width of the captured image, height : the height of the captured image, format : usually rgb , per_rows : True if stored by rows or by columns","title":"Output / Variables"},{"location":"camera/#examples","text":"import robot_api import utilities rapi = robot_api.RobotAPI() out = rapi.captureImage(utilities.InputMessage({ 'width': 800, 'height': 480, 'save_file_url': '/tmp/file.jpg' })) out.print()","title":"Examples"},{"location":"camera/#robotapigetimages","text":"Retrieves images from memory.","title":"RobotAPI.getImages"},{"location":"camera/#input-arguments_1","text":"fromIndex : The most recent index toIndex : The oldest index","title":"Input arguments"},{"location":"camera/#output-variables_1","text":"An OutputMessage as such: { 'measurements': [ { 'deviceId': ID, 'timestamp': 0, 'image': \"as base64 string format\", 'width': 0, 'height': 0, 'format': 'rgb', 'per_rows': True # If stored by rows or by columns }, ... ] }","title":"Output / Variables"},{"location":"camera/#examples_1","text":"import robot_api import utilities rapi = robot_api.RobotAPI() out = rapi.getImages(utilities.InputMessage({ 'fromIndex': 0, 'toIndex': 0 }))","title":"Examples"},{"location":"cloudapi/","text":"Under construction...","title":"Cloud API"},{"location":"conditions/","text":"Under construction...","title":"Conditions"},{"location":"encoders/","text":"Encoders API RobotAPI . getEncoderMeasurement fromIndex toindex","title":"Encoders API"},{"location":"encoders/#encoders-api","text":"","title":"Encoders API"},{"location":"encoders/#robotapigetencodermeasurement","text":"fromIndex toindex","title":"RobotAPI.getEncoderMeasurement"},{"location":"enums/","text":"Enumerations and Variables R4A APIs contain a lot of variables, as well as enumerations, to handle specific values. Their description follows. All of these are called as such: If the name of the class is Class and the member is member , you can get the specific item by Class.member . Devices enum Holds the different device types (sensors / effectors) that R4A API enables. The possible items are: Devices.SONAR Devices.IR Devices.TOF Devices.ENV Devices.IMU Devices.MICROPHONE Devices.SPEAKERS Devices.CAMERA Devices.MOTION Devices.PAN_TILT Devices.LED Devices.LINE_FOLLOWER Devices.SCREEN Devices.TOUCH_SCREEN Devices.ENCODER Devices.BUTTON Devices.UNKNOWN Devices enum offers the getTypeFromString static function that takes as input one string and returns the type. An example follows: from utilities import Devices str = \"SONAR\" item = Devices.getTypeFromString(str) print(item) The result is <Devices.SONAR: sonar > . DevicePlacement enum Holds the different placements of the devices that may have on the robot. The possible places follow. For the next items, F stands for Front, L for Left, R for Right, B for Back and G for Generic. DevicePlacement.F DevicePlacement.FL DevicePlacement.FR DevicePlacement.B DevicePlacement.BL DevicePlacement.BR DevicePlacement.R DevicePlacement.L DevicePlacement.G1 DevicePlacement.G2 DevicePlacement.G3 DevicePlacement.G4 DevicePlacement.FRONT DevicePlacement.CENTER DevicePlacement.RIGHT DevicePlacement.LEFT DevicePlacement.BACK DevicePlacement.UNDER DevicePlacement.PAN_TILT DevicePlacement.UNKNOWN Directions enum Directions hold the different directions to be used either from sensors or effectors. The different options are: Directions.FORWARDS Directions.BACKWARDS Directions.LEFT Directions.RIGHT Directions.UP Directions.DOWN Directions.NEUTRAL DetectionType enum This is used in order to specify input type for specific algorithms. The options here are: DetectionType.IMAGE DetectionType.AUDIO MotionType enum Holds the possible motion types of the robot or of specific parts of it. The options are: MotionType.BASIC MotionType.SPEED_BASED MotionType.FOLLOW_LINE MotionType.ANGLE_BASED MotionType.TIME_BASED Languages enum Holds the different languages R4A API supports. For now we have: Languages.EL Languages.EN Sentiments enum Holds the different sentiments used by the algorithms. These are: Sentiments.HAPPY Sentiments.SAD Sentiments.CRYING Sentiments.NEUTRAL Sentiments.DELIGHTED Colors enum Holds the different colors supported by the R4A API. There are: Colors.RED Colors.WHITE Colors.GREEN Colors.BLUE Colors.BLACK Colors.YELLOW Colors.MAGENTA Colors.CYAN Colors.UNKNOWN Sex enum Holds the different sexes. These are: Sex.MALE Sex.FEMALE Resolutions enum Holds the different resolutions the camera supports. These are: Resolutions.R_800_480 Resolutions.R_640_480 Format enum Holds the different formats an image may have. These are: Format.JPG Format.PNG Sonars enum Holds the different sonar placements (specific to TekTrain project). These are: Sonars.FL Sonars.FR Sonars.BR Sonars.BL Sonars.R Sonars.L Tofs enum Holds the different Time of Flight sensor placements (specific to TekTrain project). These are: Tofs.F Irs enum Holds the different IR sensor placements (specific to TekTrain project). These are: Irs.F Irs.B Irs.R Irs.L Tactile enum Holds the different tactile (buttons) positions (specific to TekTrain project). These are: Tactile.F Tactile.FL Tactile.FR Tactile.B Tactile.BL Tactile.BR Tactile.R Tactile.L Tactile.G1 Tactile.G2 Tactile.G3 Tactile.G4 TekVariables enum Apart from the above enumeration, there is a large enumeration that holds all the variables that are stored in memory . All data is stored in Redis and the keys the variables are stored in exist next to the variables in the list below. These variables are: Robot motion related TekVariables.MOTION_DISTANCE_THRES = variables.motion.distance_thres TekVariables.MOTION_DURATION_THRES = variables.motion.duration_thres TekVariables.MOTION_LINEAR = variables.motion.linear TekVariables.MOTION_ROTATIONAL = variables.motion.rotational TekVariables.MOTION_DIRECTION = variables.motion.direction TekVariables.MOTION_SPEED = variables.motion.speed TekVariables.MOTION_TYPE = variables.motion.type Robot turn related TekVariables.MOTION_TURN_TYPE = variables.motion_turn.type TekVariables.MOTION_TURN_ANGLE = variables.motion_turn.angle TekVariables.MOTION_TURN_DIRECTION = variables.motion_turn.direction TekVariables.MOTION_TURN_SPEED = variables.motion_turn.speed TekVariables.MOTION_TURN_DURATION = variables.motion_turn.duration Sleep related TekVariables.SLEEP_DURATION = variables.sleep.duration Talk related TekVariables.TALK_TEXTS = variables.talk.texts TekVariables.TALK_LANGUAGE = variables.talk.language TekVariables.TALK_VOLUME = variables.talk.volume LEDs related TekVariables.LEDS_COLOR = variables.leds.color TekVariables.LEDS_BRIGHTNESS = variables.leds.brightness Detect touch related TekVariables.DETECT_TOUCH_PARTS = variables.detect_touch.parts TekVariables.DETECT_TOUCH_DURATION = variables.detect_touch.duration TekVariables.DETECT_TOUCH_DETECTED = variables.detect_touch.detected TekVariables.DETECT_TOUCH_F = variables.detect_touch.f TekVariables.DETECT_TOUCH_FL = variables.detect_touch.fl TekVariables.DETECT_TOUCH_FR = variables.detect_touch.fr TekVariables.DETECT_TOUCH_B = variables.detect_touch.b TekVariables.DETECT_TOUCH_BR = variables.detect_touch.br TekVariables.DETECT_TOUCH_BL = variables.detect_touch.bl TekVariables.DETECT_TOUCH_L = variables.detect_touch.l TekVariables.DETECT_TOUCH_R = variables.detect_touch.r TekVariables.DETECT_TOUCH_G1 = variables.detect_touch.g1 TekVariables.DETECT_TOUCH_G2 = variables.detect_touch.g2 TekVariables.DETECT_TOUCH_G3 = variables.detect_touch.g3 TekVariables.DETECT_TOUCH_G4 = variables.detect_touch.g4 TekVariables.DETECT_TOUCH_PRESSED_PART = variables.detect_touch.pressed_part Camera motion related TekVariables.CAMERA_MOTION_DIRECTION = variables.camera_motion.direction TekVariables.CAMERA_MOTION_YAW = variables.camera_motion.yaw TekVariables.CAMERA_MOTION_PITCH = variables.camera_motion.pitch Record sound related TekVariables.RECORD_SOUND_NAME = variables.record_sound.name TekVariables.RECORD_SOUND_DURATION = variables.record_sound.duration TekVariables.RECORD_SOUND_PART = variables.record_sound.part Replay sound related TekVariables.REPLAY_SOUND_NAME = variables.replay_sound.name TekVariables.REPLAY_SOUND_VOLUME = variables.replay_sound.volume Display emotion related TekVariables.DISPLAY_EMOTION_EMOTION = variables.display_emotion.emotion Weather report related: TekVariables.WEATHER_REPORT = variables.cloud.weather_report Detect face related TekVariables.DETECT_FACE_DURATION = variables.detect_face.duration TekVariables.DETECT_FACE_DETECTED = variables.detect_face.detected TekVariables.DETECT_FACE_DETECTED_FACES = variables.detect_face.faces TekVariables.FACE_DETECTION_NFACES = variables.cloud.face_detection.number TekVariables.FACE_DETECTION_COORDS = variables.cloud.face_detection.coords Detect age/gender related TekVariables.AGE_DETECTION = variables.cloud.age_detection TekVariables.GENDER_DETECTION = variables.cloud.gender_detection OCR detection related TekVariables.OCR_DETECTION = variables.cloud.ocr_detection QR/Barcode detection related TekVariables.QR_DETECTION = variables.cloud.qr_detection TekVariables.BARCODE_DETECTION = variables.cloud.barcode_detection Detect sentiment related TekVariables.DETECT_SENTIMENT_TYPE = variables.detect_sentiment.type TekVariables.DETECT_SENTIMENT_DURATION = variables.detect_sentiment.duration TekVariables.DETECT_SENTIMENT_DETECTED = variables.detect_sentiment.detected TekVariables.DETECT_SENTIMENT_DETECTED_SENTIMENT = variables.detect_sentiment.detected_sentiment TekVariables.DETECT_SENTIMENT_DETECTED_SENTIMENT_IMAGE = variables.detect_sentiment.detected_sentiment.image TekVariables.DETECT_SENTIMENT_DETECTED_SENTIMENT_SOUND = variables.detect_sentiment.detected_sentiment.sound TekVariables.DETECT_SENTIMENT_DETECTED_SENTIMENT_TEXT = variables.detect_sentiment.detected_sentiment.text Detect sound related TekVariables.DETECT_SOUND_DURATION = variables.detect_sound.duration TekVariables.DETECT_SOUND_DETECTED = variables.detect_sound.detected TekVariables.SOUND_DETECTION = variables.cloud.sound_detection Detect motion related TekVariables.DETECT_MOTION_DURATION = variables.detect_motion.duration TekVariables.DETECT_MOTION_DETECTED = variables.detect_motion.detected Detect dominant color related TekVariables.DETECT_DOMINANT_COLOR_DETECTED_COLOR = variables.detect_dominant_color.color TekVariables.DOMINANT_COLOR_RAW = variables.cloud.dominant_color.raw TekVariables.DOMINANT_COLOR = variables.cloud.dominant_color.parsed TekVariables.MOTION_DETECTION = variables.cloud.motion_detection Speech to text related TekVariables.SPEECH_TO_TEXT = variables.cloud.speech_to_text HW related TekVariables.HW_BUTTON_PRESS = variables.hw.button_press TekVariables.HW_CAMERA_IMAGE = variables.hw.camera_image TekVariables.HW_ENCODER = variables.hw.encoder TekVariables.HW_ENV_TEMPERATURE = variables.hw.env.temperature TekVariables.HW_ENV_HUMIDITY = variables.hw.env.humidity TekVariables.HW_ENV_PRESSURE = variables.hw.env.pressure TekVariables.HW_ENV_GAS = variables.hw.env.gas TekVariables.HW_ACCELERATION_X = variables.hw.imu.acceleration.x TekVariables.HW_ACCELERATION_Y = variables.hw.imu.acceleration.y TekVariables.HW_ACCELERATION_Z = variables.hw.imu.acceleration.z TekVariables.HW_COMPASS_YAW = variables.hw.imu.compass.yaw TekVariables.HW_COMPASS_PITCH = variables.hw.imu.compass.pitch TekVariables.HW_COMPASS_ROLL = variables.hw.imu.compass.roll TekVariables.HW_GYROSCOPE_YAW = variables.hw.imu.gyro.yaw TekVariables.HW_GYROSCOPE_PITCH = variables.hw.imu.gyro.pitch TekVariables.HW_GYROSCOPE_ROLL = variables.hw.imu.gyro.roll TekVariables.HW_IR = variables.hw.ir TekVariables.HW_SONAR = variables.hw.sonar TekVariables.HW_TOF = variables.hw.tof TekVariables.HW_LEDS_SET = variables.hw.leds.set TekVariables.HW_LEDS_WIPE = variables.hw.leds.wipe","title":"Enumerations"},{"location":"enums/#enumerations-and-variables","text":"R4A APIs contain a lot of variables, as well as enumerations, to handle specific values. Their description follows. All of these are called as such: If the name of the class is Class and the member is member , you can get the specific item by Class.member .","title":"Enumerations and Variables"},{"location":"enums/#devices-enum","text":"Holds the different device types (sensors / effectors) that R4A API enables. The possible items are: Devices.SONAR Devices.IR Devices.TOF Devices.ENV Devices.IMU Devices.MICROPHONE Devices.SPEAKERS Devices.CAMERA Devices.MOTION Devices.PAN_TILT Devices.LED Devices.LINE_FOLLOWER Devices.SCREEN Devices.TOUCH_SCREEN Devices.ENCODER Devices.BUTTON Devices.UNKNOWN Devices enum offers the getTypeFromString static function that takes as input one string and returns the type. An example follows: from utilities import Devices str = \"SONAR\" item = Devices.getTypeFromString(str) print(item) The result is <Devices.SONAR: sonar > .","title":"Devices enum"},{"location":"enums/#deviceplacement-enum","text":"Holds the different placements of the devices that may have on the robot. The possible places follow. For the next items, F stands for Front, L for Left, R for Right, B for Back and G for Generic. DevicePlacement.F DevicePlacement.FL DevicePlacement.FR DevicePlacement.B DevicePlacement.BL DevicePlacement.BR DevicePlacement.R DevicePlacement.L DevicePlacement.G1 DevicePlacement.G2 DevicePlacement.G3 DevicePlacement.G4 DevicePlacement.FRONT DevicePlacement.CENTER DevicePlacement.RIGHT DevicePlacement.LEFT DevicePlacement.BACK DevicePlacement.UNDER DevicePlacement.PAN_TILT DevicePlacement.UNKNOWN","title":"DevicePlacement enum"},{"location":"enums/#directions-enum","text":"Directions hold the different directions to be used either from sensors or effectors. The different options are: Directions.FORWARDS Directions.BACKWARDS Directions.LEFT Directions.RIGHT Directions.UP Directions.DOWN Directions.NEUTRAL","title":"Directions enum"},{"location":"enums/#detectiontype-enum","text":"This is used in order to specify input type for specific algorithms. The options here are: DetectionType.IMAGE DetectionType.AUDIO","title":"DetectionType enum"},{"location":"enums/#motiontype-enum","text":"Holds the possible motion types of the robot or of specific parts of it. The options are: MotionType.BASIC MotionType.SPEED_BASED MotionType.FOLLOW_LINE MotionType.ANGLE_BASED MotionType.TIME_BASED","title":"MotionType enum"},{"location":"enums/#languages-enum","text":"Holds the different languages R4A API supports. For now we have: Languages.EL Languages.EN","title":"Languages enum"},{"location":"enums/#sentiments-enum","text":"Holds the different sentiments used by the algorithms. These are: Sentiments.HAPPY Sentiments.SAD Sentiments.CRYING Sentiments.NEUTRAL Sentiments.DELIGHTED","title":"Sentiments enum"},{"location":"enums/#colors-enum","text":"Holds the different colors supported by the R4A API. There are: Colors.RED Colors.WHITE Colors.GREEN Colors.BLUE Colors.BLACK Colors.YELLOW Colors.MAGENTA Colors.CYAN Colors.UNKNOWN","title":"Colors enum"},{"location":"enums/#sex-enum","text":"Holds the different sexes. These are: Sex.MALE Sex.FEMALE","title":"Sex enum"},{"location":"enums/#resolutions-enum","text":"Holds the different resolutions the camera supports. These are: Resolutions.R_800_480 Resolutions.R_640_480","title":"Resolutions enum"},{"location":"enums/#format-enum","text":"Holds the different formats an image may have. These are: Format.JPG Format.PNG","title":"Format enum"},{"location":"enums/#sonars-enum","text":"Holds the different sonar placements (specific to TekTrain project). These are: Sonars.FL Sonars.FR Sonars.BR Sonars.BL Sonars.R Sonars.L","title":"Sonars enum"},{"location":"enums/#tofs-enum","text":"Holds the different Time of Flight sensor placements (specific to TekTrain project). These are: Tofs.F","title":"Tofs enum"},{"location":"enums/#irs-enum","text":"Holds the different IR sensor placements (specific to TekTrain project). These are: Irs.F Irs.B Irs.R Irs.L","title":"Irs enum"},{"location":"enums/#tactile-enum","text":"Holds the different tactile (buttons) positions (specific to TekTrain project). These are: Tactile.F Tactile.FL Tactile.FR Tactile.B Tactile.BL Tactile.BR Tactile.R Tactile.L Tactile.G1 Tactile.G2 Tactile.G3 Tactile.G4","title":"Tactile enum"},{"location":"enums/#tekvariables-enum","text":"Apart from the above enumeration, there is a large enumeration that holds all the variables that are stored in memory . All data is stored in Redis and the keys the variables are stored in exist next to the variables in the list below. These variables are: Robot motion related TekVariables.MOTION_DISTANCE_THRES = variables.motion.distance_thres TekVariables.MOTION_DURATION_THRES = variables.motion.duration_thres TekVariables.MOTION_LINEAR = variables.motion.linear TekVariables.MOTION_ROTATIONAL = variables.motion.rotational TekVariables.MOTION_DIRECTION = variables.motion.direction TekVariables.MOTION_SPEED = variables.motion.speed TekVariables.MOTION_TYPE = variables.motion.type Robot turn related TekVariables.MOTION_TURN_TYPE = variables.motion_turn.type TekVariables.MOTION_TURN_ANGLE = variables.motion_turn.angle TekVariables.MOTION_TURN_DIRECTION = variables.motion_turn.direction TekVariables.MOTION_TURN_SPEED = variables.motion_turn.speed TekVariables.MOTION_TURN_DURATION = variables.motion_turn.duration Sleep related TekVariables.SLEEP_DURATION = variables.sleep.duration Talk related TekVariables.TALK_TEXTS = variables.talk.texts TekVariables.TALK_LANGUAGE = variables.talk.language TekVariables.TALK_VOLUME = variables.talk.volume LEDs related TekVariables.LEDS_COLOR = variables.leds.color TekVariables.LEDS_BRIGHTNESS = variables.leds.brightness Detect touch related TekVariables.DETECT_TOUCH_PARTS = variables.detect_touch.parts TekVariables.DETECT_TOUCH_DURATION = variables.detect_touch.duration TekVariables.DETECT_TOUCH_DETECTED = variables.detect_touch.detected TekVariables.DETECT_TOUCH_F = variables.detect_touch.f TekVariables.DETECT_TOUCH_FL = variables.detect_touch.fl TekVariables.DETECT_TOUCH_FR = variables.detect_touch.fr TekVariables.DETECT_TOUCH_B = variables.detect_touch.b TekVariables.DETECT_TOUCH_BR = variables.detect_touch.br TekVariables.DETECT_TOUCH_BL = variables.detect_touch.bl TekVariables.DETECT_TOUCH_L = variables.detect_touch.l TekVariables.DETECT_TOUCH_R = variables.detect_touch.r TekVariables.DETECT_TOUCH_G1 = variables.detect_touch.g1 TekVariables.DETECT_TOUCH_G2 = variables.detect_touch.g2 TekVariables.DETECT_TOUCH_G3 = variables.detect_touch.g3 TekVariables.DETECT_TOUCH_G4 = variables.detect_touch.g4 TekVariables.DETECT_TOUCH_PRESSED_PART = variables.detect_touch.pressed_part Camera motion related TekVariables.CAMERA_MOTION_DIRECTION = variables.camera_motion.direction TekVariables.CAMERA_MOTION_YAW = variables.camera_motion.yaw TekVariables.CAMERA_MOTION_PITCH = variables.camera_motion.pitch Record sound related TekVariables.RECORD_SOUND_NAME = variables.record_sound.name TekVariables.RECORD_SOUND_DURATION = variables.record_sound.duration TekVariables.RECORD_SOUND_PART = variables.record_sound.part Replay sound related TekVariables.REPLAY_SOUND_NAME = variables.replay_sound.name TekVariables.REPLAY_SOUND_VOLUME = variables.replay_sound.volume Display emotion related TekVariables.DISPLAY_EMOTION_EMOTION = variables.display_emotion.emotion Weather report related: TekVariables.WEATHER_REPORT = variables.cloud.weather_report Detect face related TekVariables.DETECT_FACE_DURATION = variables.detect_face.duration TekVariables.DETECT_FACE_DETECTED = variables.detect_face.detected TekVariables.DETECT_FACE_DETECTED_FACES = variables.detect_face.faces TekVariables.FACE_DETECTION_NFACES = variables.cloud.face_detection.number TekVariables.FACE_DETECTION_COORDS = variables.cloud.face_detection.coords Detect age/gender related TekVariables.AGE_DETECTION = variables.cloud.age_detection TekVariables.GENDER_DETECTION = variables.cloud.gender_detection OCR detection related TekVariables.OCR_DETECTION = variables.cloud.ocr_detection QR/Barcode detection related TekVariables.QR_DETECTION = variables.cloud.qr_detection TekVariables.BARCODE_DETECTION = variables.cloud.barcode_detection Detect sentiment related TekVariables.DETECT_SENTIMENT_TYPE = variables.detect_sentiment.type TekVariables.DETECT_SENTIMENT_DURATION = variables.detect_sentiment.duration TekVariables.DETECT_SENTIMENT_DETECTED = variables.detect_sentiment.detected TekVariables.DETECT_SENTIMENT_DETECTED_SENTIMENT = variables.detect_sentiment.detected_sentiment TekVariables.DETECT_SENTIMENT_DETECTED_SENTIMENT_IMAGE = variables.detect_sentiment.detected_sentiment.image TekVariables.DETECT_SENTIMENT_DETECTED_SENTIMENT_SOUND = variables.detect_sentiment.detected_sentiment.sound TekVariables.DETECT_SENTIMENT_DETECTED_SENTIMENT_TEXT = variables.detect_sentiment.detected_sentiment.text Detect sound related TekVariables.DETECT_SOUND_DURATION = variables.detect_sound.duration TekVariables.DETECT_SOUND_DETECTED = variables.detect_sound.detected TekVariables.SOUND_DETECTION = variables.cloud.sound_detection Detect motion related TekVariables.DETECT_MOTION_DURATION = variables.detect_motion.duration TekVariables.DETECT_MOTION_DETECTED = variables.detect_motion.detected Detect dominant color related TekVariables.DETECT_DOMINANT_COLOR_DETECTED_COLOR = variables.detect_dominant_color.color TekVariables.DOMINANT_COLOR_RAW = variables.cloud.dominant_color.raw TekVariables.DOMINANT_COLOR = variables.cloud.dominant_color.parsed TekVariables.MOTION_DETECTION = variables.cloud.motion_detection Speech to text related TekVariables.SPEECH_TO_TEXT = variables.cloud.speech_to_text HW related TekVariables.HW_BUTTON_PRESS = variables.hw.button_press TekVariables.HW_CAMERA_IMAGE = variables.hw.camera_image TekVariables.HW_ENCODER = variables.hw.encoder TekVariables.HW_ENV_TEMPERATURE = variables.hw.env.temperature TekVariables.HW_ENV_HUMIDITY = variables.hw.env.humidity TekVariables.HW_ENV_PRESSURE = variables.hw.env.pressure TekVariables.HW_ENV_GAS = variables.hw.env.gas TekVariables.HW_ACCELERATION_X = variables.hw.imu.acceleration.x TekVariables.HW_ACCELERATION_Y = variables.hw.imu.acceleration.y TekVariables.HW_ACCELERATION_Z = variables.hw.imu.acceleration.z TekVariables.HW_COMPASS_YAW = variables.hw.imu.compass.yaw TekVariables.HW_COMPASS_PITCH = variables.hw.imu.compass.pitch TekVariables.HW_COMPASS_ROLL = variables.hw.imu.compass.roll TekVariables.HW_GYROSCOPE_YAW = variables.hw.imu.gyro.yaw TekVariables.HW_GYROSCOPE_PITCH = variables.hw.imu.gyro.pitch TekVariables.HW_GYROSCOPE_ROLL = variables.hw.imu.gyro.roll TekVariables.HW_IR = variables.hw.ir TekVariables.HW_SONAR = variables.hw.sonar TekVariables.HW_TOF = variables.hw.tof TekVariables.HW_LEDS_SET = variables.hw.leds.set TekVariables.HW_LEDS_WIPE = variables.hw.leds.wipe","title":"TekVariables enum"},{"location":"env/","text":"Environmental sensor API RobotAPI . getTemperatureMeasurement fromIndex toindex RobotAPI . getHumidityMeasurement fromIndex toindex RobotAPI . getPressureMeasurement fromIndex toindex RobotAPI . getGasMeasurement fromIndex toindex","title":"Environmental API"},{"location":"env/#environmental-sensor-api","text":"","title":"Environmental sensor API"},{"location":"env/#robotapigettemperaturemeasurement","text":"fromIndex toindex","title":"RobotAPI.getTemperatureMeasurement"},{"location":"env/#robotapigethumiditymeasurement","text":"fromIndex toindex","title":"RobotAPI.getHumidityMeasurement"},{"location":"env/#robotapigetpressuremeasurement","text":"fromIndex toindex","title":"RobotAPI.getPressureMeasurement"},{"location":"env/#robotapigetgasmeasurement","text":"fromIndex toindex","title":"RobotAPI.getGasMeasurement"},{"location":"examples/","text":"Under construction...","title":"Examples"},{"location":"exceptions/","text":"The TekException class We also have custom exceptions that handle errors that occur in the R4A API. These are TekException objects that exist in the utilities module. In order to raise an exception you can write: from utilities import TekException raise TekException(\"String that explains the error\") In order to catch TekExceptions you can write something like this: try: pass # Code here except TekException: pass # Catches only TekExceptions except Exception: pass # Catches all other exceptions Each time a TekException is raised, a message is printed in console, containing information about which function raised the exception, in what line and what is the error message.","title":"Exceptions"},{"location":"exceptions/#the-tekexception-class","text":"We also have custom exceptions that handle errors that occur in the R4A API. These are TekException objects that exist in the utilities module. In order to raise an exception you can write: from utilities import TekException raise TekException(\"String that explains the error\") In order to catch TekExceptions you can write something like this: try: pass # Code here except TekException: pass # Catches only TekExceptions except Exception: pass # Catches all other exceptions Each time a TekException is raised, a message is printed in console, containing information about which function raised the exception, in what line and what is the error message.","title":"The TekException class"},{"location":"genericapi/","text":"Under construction...","title":"Generic API"},{"location":"imu/","text":"IMU API RobotAPI . getImuMeasurement fromIndex toindex","title":"IMU API"},{"location":"imu/#imu-api","text":"","title":"IMU API"},{"location":"imu/#robotapigetimumeasurement","text":"fromIndex toindex","title":"RobotAPI.getImuMeasurement"},{"location":"irs/","text":"IRs API RobotAPI . getIrMeasurement fromIndex toindex","title":"Infrared API"},{"location":"irs/#irs-api","text":"","title":"IRs API"},{"location":"irs/#robotapigetirmeasurement","text":"fromIndex toindex","title":"RobotAPI.getIrMeasurement"},{"location":"leds/","text":"LEDs API RobotAPI . lightLeds RobotAPI . ledsColorWipe RobotAPI . getLeds fromIndex toindex","title":"LEDs API"},{"location":"leds/#leds-api","text":"","title":"LEDs API"},{"location":"leds/#robotapilightleds","text":"","title":"RobotAPI.lightLeds"},{"location":"leds/#robotapiledscolorwipe","text":"","title":"RobotAPI.ledsColorWipe"},{"location":"leds/#robotapigetleds","text":"fromIndex toindex","title":"RobotAPI.getLeds"},{"location":"linefollower/","text":"Line follower API RobotAPI . getLineFollowerMeasurement fromIndex toindex","title":"Line follower API"},{"location":"linefollower/#line-follower-api","text":"","title":"Line follower API"},{"location":"linefollower/#robotapigetlinefollowermeasurement","text":"fromIndex toindex","title":"RobotAPI.getLineFollowerMeasurement"},{"location":"memory/","text":"The Memory In order to locally store a) all information generated from the sensors of the device, b) all input information from the app's calls and c) whatever the user that creates apps wants, we have created a key/value storage, using Redis . The memory object is initialized when a RobotAPI object is created and can be found as such: import robot_api r_api = robot_api.RobotAPI() memory = r_api.memory All data are written under a key , which which you can retrieve the data. Also each key denotes a topic in memory, which holds a queue of 10 items. So when you write a piece of data, it is written in place 0 and the item in place -9 is destroyed. Robot memory offers the following functionalities: Memory.listGet listGet retrieves data from memory using a key. - Input arguments key : A string denoting the key that identifies the data frm : The most recent index of the desired data to : The oldest index of the desired - Output Output is a list containing the data, along with the timestamp of the storage. - Example from robot_api import RobotAPI robot_api = RobotAPI() robot_api.memory.setKey(key = 'test', value = 1) robot_api.memory.setKey(key = 'test', value = 2) # Asking for the last two values o = robot_api.memory.listGet(key = 'test', frm = 0, to = -1) print(o) The output is [{'data': 2, 'timestamp': 1575364271.5788426}, {'data': 1, 'timestamp': 1575364271.5521088}] Memory.setKey This call either sets a new key or writes in an already existent key. - Input arguments key : A string denoting the key that identifies the data value : The value to be written. This value should be JSON serializable - Example from robot_api import RobotAPI robot_api = RobotAPI() robot_api.memory.setKey(key = 'test', value = 1) robot_api.memory.setKey(key = 'test', value = 2) Memory.getKey This call retrieves the last piece of data from memory using a key. - Input arguments key : A string denoting the key that identifies the data - Output Output is a list of size 1, along with the timestamp of the storage. - Example from robot_api import RobotAPI robot_api = RobotAPI() robot_api.memory.setKey(key = 'test', value = 1) robot_api.memory.setKey(key = 'test', value = 2) o = robot_api.memory.getKey(key = 'test') print(o) The output is: [{'data': 2, 'timestamp': 1575365240.3306623}] Memory.setVariable This call sets a TekVariable . - Input arguments variable : The TekVariable identifying the data value : The value to be written. This value should be JSON serializable - Example from utilities import TekVariables from robot_api import RobotAPI robot_api = RobotAPI() robot_api.memory.setVariable(variable = TekVariables.SLEEP_DURATION, value = 1) Memory.getVariable This call gets a TekVariable from the memory. - Input arguments variable : The TekVariable identifying the data - Output Output is a list of size 1, along with the timestamp of the storage. - Example from utilities import TekVariables from robot_api import RobotAPI robot_api = RobotAPI() robot_api.memory.setVariable(variable = TekVariables.SLEEP_DURATION, value = 1) o = robot_api.memory.getVariable(variable = TekVariables.SLEEP_DURATION) The output is: [{'data': 1, 'timestamp': 1575366048.6832085}]","title":"Memory"},{"location":"memory/#the-memory","text":"In order to locally store a) all information generated from the sensors of the device, b) all input information from the app's calls and c) whatever the user that creates apps wants, we have created a key/value storage, using Redis . The memory object is initialized when a RobotAPI object is created and can be found as such: import robot_api r_api = robot_api.RobotAPI() memory = r_api.memory All data are written under a key , which which you can retrieve the data. Also each key denotes a topic in memory, which holds a queue of 10 items. So when you write a piece of data, it is written in place 0 and the item in place -9 is destroyed. Robot memory offers the following functionalities:","title":"The Memory"},{"location":"memory/#memorylistget","text":"listGet retrieves data from memory using a key.","title":"Memory.listGet"},{"location":"memory/#-input-arguments","text":"key : A string denoting the key that identifies the data frm : The most recent index of the desired data to : The oldest index of the desired","title":"- Input arguments"},{"location":"memory/#-output","text":"Output is a list containing the data, along with the timestamp of the storage.","title":"- Output"},{"location":"memory/#-example","text":"from robot_api import RobotAPI robot_api = RobotAPI() robot_api.memory.setKey(key = 'test', value = 1) robot_api.memory.setKey(key = 'test', value = 2) # Asking for the last two values o = robot_api.memory.listGet(key = 'test', frm = 0, to = -1) print(o) The output is [{'data': 2, 'timestamp': 1575364271.5788426}, {'data': 1, 'timestamp': 1575364271.5521088}]","title":"- Example"},{"location":"memory/#memorysetkey","text":"This call either sets a new key or writes in an already existent key.","title":"Memory.setKey"},{"location":"memory/#-input-arguments_1","text":"key : A string denoting the key that identifies the data value : The value to be written. This value should be JSON serializable","title":"- Input arguments"},{"location":"memory/#-example_1","text":"from robot_api import RobotAPI robot_api = RobotAPI() robot_api.memory.setKey(key = 'test', value = 1) robot_api.memory.setKey(key = 'test', value = 2)","title":"- Example"},{"location":"memory/#memorygetkey","text":"This call retrieves the last piece of data from memory using a key.","title":"Memory.getKey"},{"location":"memory/#-input-arguments_2","text":"key : A string denoting the key that identifies the data","title":"- Input arguments"},{"location":"memory/#-output_1","text":"Output is a list of size 1, along with the timestamp of the storage.","title":"- Output"},{"location":"memory/#-example_2","text":"from robot_api import RobotAPI robot_api = RobotAPI() robot_api.memory.setKey(key = 'test', value = 1) robot_api.memory.setKey(key = 'test', value = 2) o = robot_api.memory.getKey(key = 'test') print(o) The output is: [{'data': 2, 'timestamp': 1575365240.3306623}]","title":"- Example"},{"location":"memory/#memorysetvariable","text":"This call sets a TekVariable .","title":"Memory.setVariable"},{"location":"memory/#-input-arguments_3","text":"variable : The TekVariable identifying the data value : The value to be written. This value should be JSON serializable","title":"- Input arguments"},{"location":"memory/#-example_3","text":"from utilities import TekVariables from robot_api import RobotAPI robot_api = RobotAPI() robot_api.memory.setVariable(variable = TekVariables.SLEEP_DURATION, value = 1)","title":"- Example"},{"location":"memory/#memorygetvariable","text":"This call gets a TekVariable from the memory.","title":"Memory.getVariable"},{"location":"memory/#-input-arguments_4","text":"variable : The TekVariable identifying the data","title":"- Input arguments"},{"location":"memory/#-output_2","text":"Output is a list of size 1, along with the timestamp of the storage.","title":"- Output"},{"location":"memory/#-example_4","text":"from utilities import TekVariables from robot_api import RobotAPI robot_api = RobotAPI() robot_api.memory.setVariable(variable = TekVariables.SLEEP_DURATION, value = 1) o = robot_api.memory.getVariable(variable = TekVariables.SLEEP_DURATION) The output is: [{'data': 1, 'timestamp': 1575366048.6832085}]","title":"- Example"},{"location":"messages/","text":"Input and Output messages There are two classes to handle input and output, which can be found in the utilities module. These are InputMessage and OutputMessage . InputMessage class You can create an input message as such: from utilities import InputMessage i = InputMessage() Every input message contains the following: timestamp : Contains the timestamp of the message's creation data : The data. This usually is a Python dictionary. print() : Function to print the input message An example follows: from utilities import InputMessage i = InputMessage({'duration': 3}) i.data['another'] = 2 i.print() The output in console is: Input message: [1575288958.9064102] Data: {'duration': 3, 'another': 2} OutputMessage class Every call of the Robot, Cloud or Generic API returns an OutputMessage . Each output message contains: timestamp : Contains the timestamp of the message's creation sequence : A unique number that characterizes the message errors : A list of possible errors logs : A list of logs. Usually contains trace-back information. data : The data that the message contains print() : Prints the output message An example code that utilizes an output message is the following: from utilities import Devices, InputMessage from robot_api import RobotAPI rapi = RobotAPI() rapi.devicesObj.enableDevicesType(Devices.TOUCH_SCREEN) out = rapi.showOptions(InputMessage({ 'options': ['Option 1', 'Option 2'], 'duration': 5 })) out.print() This snippet initializes a touch screen, shows 2 options and waits for 5 seconds for the user to select one. The output is: Output message: [1575290784.5641167] #5 {'reaction_time': 0.9212639331817627, 'selected': 'Option 1'} Errors: Logs: [1575290784.5652816] setOptions @ RobotAPITouchScreenController [1575290784.5658484] showOptions @ RobotAPI","title":"Messages"},{"location":"messages/#input-and-output-messages","text":"There are two classes to handle input and output, which can be found in the utilities module. These are InputMessage and OutputMessage .","title":"Input and Output messages"},{"location":"messages/#inputmessage-class","text":"You can create an input message as such: from utilities import InputMessage i = InputMessage() Every input message contains the following: timestamp : Contains the timestamp of the message's creation data : The data. This usually is a Python dictionary. print() : Function to print the input message An example follows: from utilities import InputMessage i = InputMessage({'duration': 3}) i.data['another'] = 2 i.print() The output in console is: Input message: [1575288958.9064102] Data: {'duration': 3, 'another': 2}","title":"InputMessage class"},{"location":"messages/#outputmessage-class","text":"Every call of the Robot, Cloud or Generic API returns an OutputMessage . Each output message contains: timestamp : Contains the timestamp of the message's creation sequence : A unique number that characterizes the message errors : A list of possible errors logs : A list of logs. Usually contains trace-back information. data : The data that the message contains print() : Prints the output message An example code that utilizes an output message is the following: from utilities import Devices, InputMessage from robot_api import RobotAPI rapi = RobotAPI() rapi.devicesObj.enableDevicesType(Devices.TOUCH_SCREEN) out = rapi.showOptions(InputMessage({ 'options': ['Option 1', 'Option 2'], 'duration': 5 })) out.print() This snippet initializes a touch screen, shows 2 options and waits for 5 seconds for the user to select one. The output is: Output message: [1575290784.5641167] #5 {'reaction_time': 0.9212639331817627, 'selected': 'Option 1'} Errors: Logs: [1575290784.5652816] setOptions @ RobotAPITouchScreenController [1575290784.5658484] showOptions @ RobotAPI","title":"OutputMessage class"},{"location":"microphone/","text":"Microphone API RobotAPI . recordSound This call records a sound from a microphone. Input arguments duration : How many seconds the recording will be name : A name to store the sound (can be later used to retrieve it) save_file_url : Absolute path to store the sound as a wav. If None , the sound is not locally stored. Output / Variables This call returns an OutputMessage , containing the following data: { 'record': The base64 encoded sound file } In does not change any TekVariables . Examples import robot_api import utilities rapi = robot_api.RobotAPI() out = rapi.recordSound(utilities.InputMessage({ 'name': 'test_sound_1', 'duration': 3, 'save_file_url': '/tmp/tmp.wav' })) sound_str = out.data['record']","title":"Microphone API"},{"location":"microphone/#microphone-api","text":"","title":"Microphone API"},{"location":"microphone/#robotapirecordsound","text":"This call records a sound from a microphone.","title":"RobotAPI.recordSound"},{"location":"microphone/#input-arguments","text":"duration : How many seconds the recording will be name : A name to store the sound (can be later used to retrieve it) save_file_url : Absolute path to store the sound as a wav. If None , the sound is not locally stored.","title":"Input arguments"},{"location":"microphone/#output-variables","text":"This call returns an OutputMessage , containing the following data: { 'record': The base64 encoded sound file } In does not change any TekVariables .","title":"Output / Variables"},{"location":"microphone/#examples","text":"import robot_api import utilities rapi = robot_api.RobotAPI() out = rapi.recordSound(utilities.InputMessage({ 'name': 'test_sound_1', 'duration': 3, 'save_file_url': '/tmp/tmp.wav' })) sound_str = out.data['record']","title":"Examples"},{"location":"motion/","text":"Body motion API RobotAPI . moveBody linearVelocity rotationalVelocity RobotAPI . getBodyVelocities fromIndex toindex","title":"Body motion API"},{"location":"motion/#body-motion-api","text":"","title":"Body motion API"},{"location":"motion/#robotapimovebody","text":"linearVelocity rotationalVelocity","title":"RobotAPI.moveBody"},{"location":"motion/#robotapigetbodyvelocities","text":"fromIndex toindex","title":"RobotAPI.getBodyVelocities"},{"location":"nodes/","text":"Under construction...","title":"FSM-like applications"},{"location":"pantilt/","text":"Pan-tilt API RobotAPI . getPanTilt fromIndex toindex RobotAPI . movePanTilt yaw pitch","title":"Pan-tilt API"},{"location":"pantilt/#pan-tilt-api","text":"","title":"Pan-tilt API"},{"location":"pantilt/#robotapigetpantilt","text":"fromIndex toindex","title":"RobotAPI.getPanTilt"},{"location":"pantilt/#robotapimovepantilt","text":"yaw pitch","title":"RobotAPI.movePanTilt"},{"location":"resources/","text":"Enabling resources In order to use a resource, you must enable it. The easier way to do this is via the devicesObj object, that exists in a RobotAPI object. Specifically there is a function called enableDevicesType , that takes as input a Device and activates all respective devices. For example, if we were to enable all microphones, we would write: import utilities import robot_api r = robot_api.RobotAPI() r.devicesObj.enableDevicesType(Devices.MICROPHONE)","title":"Enabling resources"},{"location":"resources/#enabling-resources","text":"In order to use a resource, you must enable it. The easier way to do this is via the devicesObj object, that exists in a RobotAPI object. Specifically there is a function called enableDevicesType , that takes as input a Device and activates all respective devices. For example, if we were to enable all microphones, we would write: import utilities import robot_api r = robot_api.RobotAPI() r.devicesObj.enableDevicesType(Devices.MICROPHONE)","title":"Enabling resources"},{"location":"robotapi/","text":"The RobotAPI Robot API offers services / calls, with which you can manipulate the robot/device. As explained here , all calls get an InputMessage as input and an OutputMessage as output. The contents of this section are: Enabling resources Speakers API Microphone API Camera API Touch screen API LEDs API Buttons API Environmental API Encoders API Line follower API Time-of-flight API Sonars API Infrared API Pan-tilt API Body motion API IMU API","title":"General"},{"location":"robotapi/#the-robotapi","text":"Robot API offers services / calls, with which you can manipulate the robot/device. As explained here , all calls get an InputMessage as input and an OutputMessage as output. The contents of this section are: Enabling resources Speakers API Microphone API Camera API Touch screen API LEDs API Buttons API Environmental API Encoders API Line follower API Time-of-flight API Sonars API Infrared API Pan-tilt API Body motion API IMU API","title":"The RobotAPI"},{"location":"sonars/","text":"Sonars API RobotAPI . getSonarMeasurement fromIndex toindex","title":"Sonars API"},{"location":"sonars/#sonars-api","text":"","title":"Sonars API"},{"location":"sonars/#robotapigetsonarmeasurement","text":"fromIndex toindex","title":"RobotAPI.getSonarMeasurement"},{"location":"speakers/","text":"Speakers API RobotAPI . speak A text-to-speech algorithm is used, in order for the device to \"speak\" in different languages. Input arguments texts : A list of arguments. These may be strings or TekVariables volume : The volume from 0 to 100 language : A Language Output / Variables This call has no output and does not change any TekVariables. Examples \u2611 import robot_api import utilities rapi = robot_api.RobotAPI() out = rapi.speak(utilities.InputMessage({ 'texts': ['the number', 'is', utilities.TekVariables.SLEEP_DURATION], 'volume': 100, 'language': utilities.Languages.EN })) RobotAPI . replaySound This call reproduces a sound from the speakers. The sound can either be a wav file, or a base64-encoded string. Input arguments is_file : True if we want to play a file, false if we have a raw base64 string string : Either the absolute path of the file, or the base64 string. volume : The volume from 0 to 100 Output / Variables This call has no output and does not change any TekVariables . Examples import robot_api import utilities rapi = robot_api.RobotAPI() out = rapi.replaySound(utilities.InputMessage({ 'is_file': True, 'string': '/tmp/tmp.wav', 'volume': 100 }))","title":"Speakers API"},{"location":"speakers/#speakers-api","text":"","title":"Speakers API"},{"location":"speakers/#robotapispeak","text":"A text-to-speech algorithm is used, in order for the device to \"speak\" in different languages.","title":"RobotAPI.speak"},{"location":"speakers/#input-arguments","text":"texts : A list of arguments. These may be strings or TekVariables volume : The volume from 0 to 100 language : A Language","title":"Input arguments"},{"location":"speakers/#output-variables","text":"This call has no output and does not change any TekVariables.","title":"Output / Variables"},{"location":"speakers/#examples","text":"import robot_api import utilities rapi = robot_api.RobotAPI() out = rapi.speak(utilities.InputMessage({ 'texts': ['the number', 'is', utilities.TekVariables.SLEEP_DURATION], 'volume': 100, 'language': utilities.Languages.EN }))","title":"Examples \u2611"},{"location":"speakers/#robotapireplaysound","text":"This call reproduces a sound from the speakers. The sound can either be a wav file, or a base64-encoded string.","title":"RobotAPI.replaySound"},{"location":"speakers/#input-arguments_1","text":"is_file : True if we want to play a file, false if we have a raw base64 string string : Either the absolute path of the file, or the base64 string. volume : The volume from 0 to 100","title":"Input arguments"},{"location":"speakers/#output-variables_1","text":"This call has no output and does not change any TekVariables .","title":"Output / Variables"},{"location":"speakers/#examples_1","text":"import robot_api import utilities rapi = robot_api.RobotAPI() out = rapi.replaySound(utilities.InputMessage({ 'is_file': True, 'string': '/tmp/tmp.wav', 'volume': 100 }))","title":"Examples"},{"location":"tof/","text":"Time-of-flight API RobotAPI . getToFMeasurement fromIndex toindex","title":"Time-of-flight API"},{"location":"tof/#time-of-flight-api","text":"","title":"Time-of-flight API"},{"location":"tof/#robotapigettofmeasurement","text":"fromIndex toindex","title":"RobotAPI.getToFMeasurement"},{"location":"touchscreen/","text":"Touch screen API RobotAPI . showImage Shows an image in touch screen Input arguments image : The image as base64 string width : The width of the captured image height : The height of the captured image duration : How many seconds the image will be shown touch : True if touches are accepted. Output / Variables Returns an OutputMessage containing the following data: { 'reaction_time': The reaction time - time between the display and the touch, 'selected': None } Examples import robot_api import utilities rapi = robot_api.RobotAPI() out = rapi.captureImage(utilities.InputMessage({ 'width': 800, 'height': 480, 'save_file_url': None })) out.print() out = rapi.showImage(utilities.InputMessage({ 'image': out.data['image'], 'width': out.data['width'], 'height': out.data['height'], 'duration': 10, 'touch': True })) out.print() RobotAPI . showOptions Shows up to 4 options in the touch screen and waits for a touch. Input arguments options : A list of strings duration : For how much time the options will wait for touch Output / Variables Returns an OutputMessage containing the following data: { 'reaction_time': The reaction time - time between the display and the touch, 'selected': The option selected (as string) } Examples An InputMessage as such: import robot_api import utilities rapi = robot_api.RobotAPI() out = rapi.showOptions(utilities.InputMessage({ 'options': ['Option 1', 'Option 2'], 'duration': 5 })) out.print() RobotAPI . showColor Input arguments color : duration : For how much time the color will wait for touch Output / Variables { 'reaction_time': The reaction time - time between the display and the touch, 'selected': The option selected (as string) } Examples import robot_api import utilities rapi = robot_api.RobotAPI() out = rapi.showColor(utilities.InputMessage({ 'color': utilities.Colors.GREEN.value, 'duration': 5 })) out.print()","title":"Touch screen API"},{"location":"touchscreen/#touch-screen-api","text":"","title":"Touch screen API"},{"location":"touchscreen/#robotapishowimage","text":"Shows an image in touch screen","title":"RobotAPI.showImage"},{"location":"touchscreen/#input-arguments","text":"image : The image as base64 string width : The width of the captured image height : The height of the captured image duration : How many seconds the image will be shown touch : True if touches are accepted.","title":"Input arguments"},{"location":"touchscreen/#output-variables","text":"Returns an OutputMessage containing the following data: { 'reaction_time': The reaction time - time between the display and the touch, 'selected': None }","title":"Output / Variables"},{"location":"touchscreen/#examples","text":"import robot_api import utilities rapi = robot_api.RobotAPI() out = rapi.captureImage(utilities.InputMessage({ 'width': 800, 'height': 480, 'save_file_url': None })) out.print() out = rapi.showImage(utilities.InputMessage({ 'image': out.data['image'], 'width': out.data['width'], 'height': out.data['height'], 'duration': 10, 'touch': True })) out.print()","title":"Examples"},{"location":"touchscreen/#robotapishowoptions","text":"Shows up to 4 options in the touch screen and waits for a touch.","title":"RobotAPI.showOptions"},{"location":"touchscreen/#input-arguments_1","text":"options : A list of strings duration : For how much time the options will wait for touch","title":"Input arguments"},{"location":"touchscreen/#output-variables_1","text":"Returns an OutputMessage containing the following data: { 'reaction_time': The reaction time - time between the display and the touch, 'selected': The option selected (as string) }","title":"Output / Variables"},{"location":"touchscreen/#examples_1","text":"An InputMessage as such: import robot_api import utilities rapi = robot_api.RobotAPI() out = rapi.showOptions(utilities.InputMessage({ 'options': ['Option 1', 'Option 2'], 'duration': 5 })) out.print()","title":"Examples"},{"location":"touchscreen/#robotapishowcolor","text":"","title":"RobotAPI.showColor"},{"location":"touchscreen/#input-arguments_2","text":"color : duration : For how much time the color will wait for touch","title":"Input arguments"},{"location":"touchscreen/#output-variables_2","text":"{ 'reaction_time': The reaction time - time between the display and the touch, 'selected': The option selected (as string) }","title":"Output / Variables"},{"location":"touchscreen/#examples_2","text":"import robot_api import utilities rapi = robot_api.RobotAPI() out = rapi.showColor(utilities.InputMessage({ 'color': utilities.Colors.GREEN.value, 'duration': 5 })) out.print()","title":"Examples"}]}